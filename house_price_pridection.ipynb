{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "house price pridection.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMqecpu8bU0jkEYtjVV3HdE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lonecoder007/practice_projects/blob/master/house_price_pridection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n070DnWN95zC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmCnmKE_Eqhh",
        "colab_type": "text"
      },
      "source": [
        "# **Data** **Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lifl6vrE-j9X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train=pd.read_csv('Train_Data.csv')\n",
        "test=pd.read_csv('Test_Data.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tf29gLTf-pAr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0126e8e4-3b99-4599-955d-8af0c4d8756b"
      },
      "source": [
        "print(\"Number of data points in train data:{0} and Number of features in train data:{1}\".format(train.shape[0],train.shape[1]))\n",
        "print(\"Number of data points in test data:{0} and Number of features in test data:{1}\".format(test.shape[0],test.shape[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of data points in train data:1100 and Number of features in train data:81\n",
            "Number of data points in test data:360 and Number of features in test data:80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tisxmedE-305",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "9cbbf6cc-4ace-47b4-b3aa-33ccf01d6e69"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>Alley</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>LotConfig</th>\n",
              "      <th>LandSlope</th>\n",
              "      <th>Neighborhood</th>\n",
              "      <th>Condition1</th>\n",
              "      <th>Condition2</th>\n",
              "      <th>BldgType</th>\n",
              "      <th>HouseStyle</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>RoofStyle</th>\n",
              "      <th>RoofMatl</th>\n",
              "      <th>Exterior1st</th>\n",
              "      <th>Exterior2nd</th>\n",
              "      <th>MasVnrType</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>ExterQual</th>\n",
              "      <th>ExterCond</th>\n",
              "      <th>Foundation</th>\n",
              "      <th>BsmtQual</th>\n",
              "      <th>BsmtCond</th>\n",
              "      <th>BsmtExposure</th>\n",
              "      <th>BsmtFinType1</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtFinType2</th>\n",
              "      <th>BsmtFinSF2</th>\n",
              "      <th>BsmtUnfSF</th>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <th>Heating</th>\n",
              "      <th>...</th>\n",
              "      <th>CentralAir</th>\n",
              "      <th>Electrical</th>\n",
              "      <th>1stFlrSF</th>\n",
              "      <th>2ndFlrSF</th>\n",
              "      <th>LowQualFinSF</th>\n",
              "      <th>GrLivArea</th>\n",
              "      <th>BsmtFullBath</th>\n",
              "      <th>BsmtHalfBath</th>\n",
              "      <th>FullBath</th>\n",
              "      <th>HalfBath</th>\n",
              "      <th>BedroomAbvGr</th>\n",
              "      <th>KitchenAbvGr</th>\n",
              "      <th>KitchenQual</th>\n",
              "      <th>TotRmsAbvGrd</th>\n",
              "      <th>Functional</th>\n",
              "      <th>Fireplaces</th>\n",
              "      <th>FireplaceQu</th>\n",
              "      <th>GarageType</th>\n",
              "      <th>GarageYrBlt</th>\n",
              "      <th>GarageFinish</th>\n",
              "      <th>GarageCars</th>\n",
              "      <th>GarageArea</th>\n",
              "      <th>GarageQual</th>\n",
              "      <th>GarageCond</th>\n",
              "      <th>PavedDrive</th>\n",
              "      <th>WoodDeckSF</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>3SsnPorch</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>PoolQC</th>\n",
              "      <th>Fence</th>\n",
              "      <th>MiscFeature</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>65.0</td>\n",
              "      <td>8450</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>CollgCr</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2003</td>\n",
              "      <td>2003</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>196.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>No</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>706</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>856</td>\n",
              "      <td>GasA</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>856</td>\n",
              "      <td>854</td>\n",
              "      <td>0</td>\n",
              "      <td>1710</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>8</td>\n",
              "      <td>Typ</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>2003.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2</td>\n",
              "      <td>548</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>61</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9600</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>FR2</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>Veenker</td>\n",
              "      <td>Feedr</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>1Story</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>1976</td>\n",
              "      <td>1976</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>MetalSd</td>\n",
              "      <td>MetalSd</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>CBlock</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>Gd</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>978</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>284</td>\n",
              "      <td>1262</td>\n",
              "      <td>GasA</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>1262</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1262</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>6</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>1976.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2</td>\n",
              "      <td>460</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>298</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>181500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>68.0</td>\n",
              "      <td>11250</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>CollgCr</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2001</td>\n",
              "      <td>2002</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>162.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>Mn</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>486</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>434</td>\n",
              "      <td>920</td>\n",
              "      <td>GasA</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>920</td>\n",
              "      <td>866</td>\n",
              "      <td>0</td>\n",
              "      <td>1786</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>6</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>2001.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2</td>\n",
              "      <td>608</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>223500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>70</td>\n",
              "      <td>RL</td>\n",
              "      <td>60.0</td>\n",
              "      <td>9550</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Corner</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>Crawfor</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>1915</td>\n",
              "      <td>1970</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>Wd Sdng</td>\n",
              "      <td>Wd Shng</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>BrkTil</td>\n",
              "      <td>TA</td>\n",
              "      <td>Gd</td>\n",
              "      <td>No</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>216</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>540</td>\n",
              "      <td>756</td>\n",
              "      <td>GasA</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>961</td>\n",
              "      <td>756</td>\n",
              "      <td>0</td>\n",
              "      <td>1717</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>7</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>Detchd</td>\n",
              "      <td>1998.0</td>\n",
              "      <td>Unf</td>\n",
              "      <td>3</td>\n",
              "      <td>642</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>272</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Abnorml</td>\n",
              "      <td>140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>84.0</td>\n",
              "      <td>14260</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>FR2</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>NoRidge</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>350.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>Av</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>655</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>490</td>\n",
              "      <td>1145</td>\n",
              "      <td>GasA</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>1145</td>\n",
              "      <td>1053</td>\n",
              "      <td>0</td>\n",
              "      <td>2198</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>9</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>3</td>\n",
              "      <td>836</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>192</td>\n",
              "      <td>84</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>250000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 81 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  MSSubClass MSZoning  ...  SaleType  SaleCondition SalePrice\n",
              "0   1          60       RL  ...        WD         Normal    208500\n",
              "1   2          20       RL  ...        WD         Normal    181500\n",
              "2   3          60       RL  ...        WD         Normal    223500\n",
              "3   4          70       RL  ...        WD        Abnorml    140000\n",
              "4   5          60       RL  ...        WD         Normal    250000\n",
              "\n",
              "[5 rows x 81 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdkWIU93-6R-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "78d10739-3231-4ca5-b42a-c2240e54161f"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>Alley</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>LotConfig</th>\n",
              "      <th>LandSlope</th>\n",
              "      <th>Neighborhood</th>\n",
              "      <th>Condition1</th>\n",
              "      <th>Condition2</th>\n",
              "      <th>BldgType</th>\n",
              "      <th>HouseStyle</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>RoofStyle</th>\n",
              "      <th>RoofMatl</th>\n",
              "      <th>Exterior1st</th>\n",
              "      <th>Exterior2nd</th>\n",
              "      <th>MasVnrType</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>ExterQual</th>\n",
              "      <th>ExterCond</th>\n",
              "      <th>Foundation</th>\n",
              "      <th>BsmtQual</th>\n",
              "      <th>BsmtCond</th>\n",
              "      <th>BsmtExposure</th>\n",
              "      <th>BsmtFinType1</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtFinType2</th>\n",
              "      <th>BsmtFinSF2</th>\n",
              "      <th>BsmtUnfSF</th>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <th>Heating</th>\n",
              "      <th>HeatingQC</th>\n",
              "      <th>CentralAir</th>\n",
              "      <th>Electrical</th>\n",
              "      <th>1stFlrSF</th>\n",
              "      <th>2ndFlrSF</th>\n",
              "      <th>LowQualFinSF</th>\n",
              "      <th>GrLivArea</th>\n",
              "      <th>BsmtFullBath</th>\n",
              "      <th>BsmtHalfBath</th>\n",
              "      <th>FullBath</th>\n",
              "      <th>HalfBath</th>\n",
              "      <th>BedroomAbvGr</th>\n",
              "      <th>KitchenAbvGr</th>\n",
              "      <th>KitchenQual</th>\n",
              "      <th>TotRmsAbvGrd</th>\n",
              "      <th>Functional</th>\n",
              "      <th>Fireplaces</th>\n",
              "      <th>FireplaceQu</th>\n",
              "      <th>GarageType</th>\n",
              "      <th>GarageYrBlt</th>\n",
              "      <th>GarageFinish</th>\n",
              "      <th>GarageCars</th>\n",
              "      <th>GarageArea</th>\n",
              "      <th>GarageQual</th>\n",
              "      <th>GarageCond</th>\n",
              "      <th>PavedDrive</th>\n",
              "      <th>WoodDeckSF</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>3SsnPorch</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>PoolQC</th>\n",
              "      <th>Fence</th>\n",
              "      <th>MiscFeature</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1101</td>\n",
              "      <td>30</td>\n",
              "      <td>RL</td>\n",
              "      <td>60.0</td>\n",
              "      <td>8400</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Bnk</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>SWISU</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>1Story</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1920</td>\n",
              "      <td>1950</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>Wd Sdng</td>\n",
              "      <td>Wd Sdng</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>CBlock</td>\n",
              "      <td>TA</td>\n",
              "      <td>Fa</td>\n",
              "      <td>No</td>\n",
              "      <td>Rec</td>\n",
              "      <td>290</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>290</td>\n",
              "      <td>GasA</td>\n",
              "      <td>TA</td>\n",
              "      <td>N</td>\n",
              "      <td>FuseF</td>\n",
              "      <td>438</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>438</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Fa</td>\n",
              "      <td>3</td>\n",
              "      <td>Typ</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Detchd</td>\n",
              "      <td>1930.0</td>\n",
              "      <td>Unf</td>\n",
              "      <td>1</td>\n",
              "      <td>246</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2009</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1102</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>61.0</td>\n",
              "      <td>9758</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>NAmes</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>1Story</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>1971</td>\n",
              "      <td>1971</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>HdBoard</td>\n",
              "      <td>MetalSd</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>CBlock</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>No</td>\n",
              "      <td>BLQ</td>\n",
              "      <td>412</td>\n",
              "      <td>LwQ</td>\n",
              "      <td>287</td>\n",
              "      <td>251</td>\n",
              "      <td>950</td>\n",
              "      <td>GasA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>950</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>950</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>5</td>\n",
              "      <td>Typ</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Detchd</td>\n",
              "      <td>1981.0</td>\n",
              "      <td>Unf</td>\n",
              "      <td>1</td>\n",
              "      <td>280</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1103</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>70.0</td>\n",
              "      <td>7000</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>NAmes</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>1Story</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>1960</td>\n",
              "      <td>2002</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>Wd Sdng</td>\n",
              "      <td>Wd Sdng</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>45.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>CBlock</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>No</td>\n",
              "      <td>Rec</td>\n",
              "      <td>588</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>422</td>\n",
              "      <td>1010</td>\n",
              "      <td>GasA</td>\n",
              "      <td>Ex</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>1134</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1134</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>6</td>\n",
              "      <td>Typ</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>1960.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>1</td>\n",
              "      <td>254</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>MnWw</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Family</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1104</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>79.0</td>\n",
              "      <td>8910</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Corner</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>NAmes</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>1Story</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>1959</td>\n",
              "      <td>1959</td>\n",
              "      <td>Hip</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>CBlock</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Mn</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>655</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>655</td>\n",
              "      <td>GasA</td>\n",
              "      <td>Ex</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>1194</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1194</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>6</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>Fa</td>\n",
              "      <td>BuiltIn</td>\n",
              "      <td>1954.0</td>\n",
              "      <td>Fin</td>\n",
              "      <td>2</td>\n",
              "      <td>539</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>192</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1105</td>\n",
              "      <td>160</td>\n",
              "      <td>RM</td>\n",
              "      <td>24.0</td>\n",
              "      <td>2016</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>BrDale</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>TwnhsE</td>\n",
              "      <td>2Story</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>1970</td>\n",
              "      <td>1970</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>HdBoard</td>\n",
              "      <td>HdBoard</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>304.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>CBlock</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>No</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>630</td>\n",
              "      <td>630</td>\n",
              "      <td>GasA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>630</td>\n",
              "      <td>672</td>\n",
              "      <td>0</td>\n",
              "      <td>1302</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>6</td>\n",
              "      <td>Typ</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Detchd</td>\n",
              "      <td>1970.0</td>\n",
              "      <td>Unf</td>\n",
              "      <td>2</td>\n",
              "      <td>440</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Id  MSSubClass MSZoning  ...  YrSold  SaleType SaleCondition\n",
              "0  1101          30       RL  ...    2009        WD        Normal\n",
              "1  1102          20       RL  ...    2007        WD        Normal\n",
              "2  1103          20       RL  ...    2007        WD        Family\n",
              "3  1104          20       RL  ...    2006        WD        Normal\n",
              "4  1105         160       RM  ...    2007        WD        Normal\n",
              "\n",
              "[5 rows x 80 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72hHULeM-8fj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target=train['SalePrice']\n",
        "train.drop('SalePrice',axis=1,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7ANU5Tc_DAJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataframe=pd.concat([train,test])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OV3yn6Ao_GCX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "576dca1e-3dc1-4e28-e736-99af6e148e33"
      },
      "source": [
        "dataframe.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1460 entries, 0 to 359\n",
            "Data columns (total 80 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   Id             1460 non-null   int64  \n",
            " 1   MSSubClass     1460 non-null   int64  \n",
            " 2   MSZoning       1460 non-null   object \n",
            " 3   LotFrontage    1201 non-null   float64\n",
            " 4   LotArea        1460 non-null   int64  \n",
            " 5   Street         1460 non-null   object \n",
            " 6   Alley          91 non-null     object \n",
            " 7   LotShape       1460 non-null   object \n",
            " 8   LandContour    1460 non-null   object \n",
            " 9   Utilities      1460 non-null   object \n",
            " 10  LotConfig      1460 non-null   object \n",
            " 11  LandSlope      1460 non-null   object \n",
            " 12  Neighborhood   1460 non-null   object \n",
            " 13  Condition1     1460 non-null   object \n",
            " 14  Condition2     1460 non-null   object \n",
            " 15  BldgType       1460 non-null   object \n",
            " 16  HouseStyle     1460 non-null   object \n",
            " 17  OverallQual    1460 non-null   int64  \n",
            " 18  OverallCond    1460 non-null   int64  \n",
            " 19  YearBuilt      1460 non-null   int64  \n",
            " 20  YearRemodAdd   1460 non-null   int64  \n",
            " 21  RoofStyle      1460 non-null   object \n",
            " 22  RoofMatl       1460 non-null   object \n",
            " 23  Exterior1st    1460 non-null   object \n",
            " 24  Exterior2nd    1460 non-null   object \n",
            " 25  MasVnrType     1452 non-null   object \n",
            " 26  MasVnrArea     1452 non-null   float64\n",
            " 27  ExterQual      1460 non-null   object \n",
            " 28  ExterCond      1460 non-null   object \n",
            " 29  Foundation     1460 non-null   object \n",
            " 30  BsmtQual       1423 non-null   object \n",
            " 31  BsmtCond       1423 non-null   object \n",
            " 32  BsmtExposure   1422 non-null   object \n",
            " 33  BsmtFinType1   1423 non-null   object \n",
            " 34  BsmtFinSF1     1460 non-null   int64  \n",
            " 35  BsmtFinType2   1422 non-null   object \n",
            " 36  BsmtFinSF2     1460 non-null   int64  \n",
            " 37  BsmtUnfSF      1460 non-null   int64  \n",
            " 38  TotalBsmtSF    1460 non-null   int64  \n",
            " 39  Heating        1460 non-null   object \n",
            " 40  HeatingQC      1460 non-null   object \n",
            " 41  CentralAir     1460 non-null   object \n",
            " 42  Electrical     1459 non-null   object \n",
            " 43  1stFlrSF       1460 non-null   int64  \n",
            " 44  2ndFlrSF       1460 non-null   int64  \n",
            " 45  LowQualFinSF   1460 non-null   int64  \n",
            " 46  GrLivArea      1460 non-null   int64  \n",
            " 47  BsmtFullBath   1460 non-null   int64  \n",
            " 48  BsmtHalfBath   1460 non-null   int64  \n",
            " 49  FullBath       1460 non-null   int64  \n",
            " 50  HalfBath       1460 non-null   int64  \n",
            " 51  BedroomAbvGr   1460 non-null   int64  \n",
            " 52  KitchenAbvGr   1460 non-null   int64  \n",
            " 53  KitchenQual    1460 non-null   object \n",
            " 54  TotRmsAbvGrd   1460 non-null   int64  \n",
            " 55  Functional     1460 non-null   object \n",
            " 56  Fireplaces     1460 non-null   int64  \n",
            " 57  FireplaceQu    770 non-null    object \n",
            " 58  GarageType     1379 non-null   object \n",
            " 59  GarageYrBlt    1379 non-null   float64\n",
            " 60  GarageFinish   1379 non-null   object \n",
            " 61  GarageCars     1460 non-null   int64  \n",
            " 62  GarageArea     1460 non-null   int64  \n",
            " 63  GarageQual     1379 non-null   object \n",
            " 64  GarageCond     1379 non-null   object \n",
            " 65  PavedDrive     1460 non-null   object \n",
            " 66  WoodDeckSF     1460 non-null   int64  \n",
            " 67  OpenPorchSF    1460 non-null   int64  \n",
            " 68  EnclosedPorch  1460 non-null   int64  \n",
            " 69  3SsnPorch      1460 non-null   int64  \n",
            " 70  ScreenPorch    1460 non-null   int64  \n",
            " 71  PoolArea       1460 non-null   int64  \n",
            " 72  PoolQC         7 non-null      object \n",
            " 73  Fence          281 non-null    object \n",
            " 74  MiscFeature    54 non-null     object \n",
            " 75  MiscVal        1460 non-null   int64  \n",
            " 76  MoSold         1460 non-null   int64  \n",
            " 77  YrSold         1460 non-null   int64  \n",
            " 78  SaleType       1460 non-null   object \n",
            " 79  SaleCondition  1460 non-null   object \n",
            "dtypes: float64(3), int64(34), object(43)\n",
            "memory usage: 923.9+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Msy7z1YM_IK4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "aef85bbf-50b3-4687-9cd9-27030c0f1f5b"
      },
      "source": [
        "dataframe.columns[dataframe.isnull().any()].tolist()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['LotFrontage',\n",
              " 'Alley',\n",
              " 'MasVnrType',\n",
              " 'MasVnrArea',\n",
              " 'BsmtQual',\n",
              " 'BsmtCond',\n",
              " 'BsmtExposure',\n",
              " 'BsmtFinType1',\n",
              " 'BsmtFinType2',\n",
              " 'Electrical',\n",
              " 'FireplaceQu',\n",
              " 'GarageType',\n",
              " 'GarageYrBlt',\n",
              " 'GarageFinish',\n",
              " 'GarageQual',\n",
              " 'GarageCond',\n",
              " 'PoolQC',\n",
              " 'Fence',\n",
              " 'MiscFeature']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tvf9fnKFUZl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytbcC3H2_NHb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataframe['LotFrontage'].fillna(value=dataframe['LotFrontage'].mean(),inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LU_T5duv_QOd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "64e1451a-4b52-446f-dcf3-172de58b835b"
      },
      "source": [
        "print(dataframe['LotFrontage'].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1460,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIqPVoQQ_S6h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "287c7514-8bd6-4322-ba27-5c24d4798343"
      },
      "source": [
        "print(dataframe['MasVnrType'].value_counts())\n",
        "print(dataframe['MasVnrType'].count())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None       864\n",
            "BrkFace    445\n",
            "Stone      128\n",
            "BrkCmn      15\n",
            "Name: MasVnrType, dtype: int64\n",
            "1452\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZQ13ula_VRW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataframe['MasVnrType'].fillna(value='None',inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_zBvf5t_djD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "71e7d713-676e-4bf3-9c45-d2ec170d4ab6"
      },
      "source": [
        "dataframe['MasVnrType'].count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1460"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRFmoGdk_fnD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "66571c45-a551-4931-db4e-9b10f8de816c"
      },
      "source": [
        "print(dataframe['MasVnrArea'].value_counts())\n",
        "print(dataframe['MasVnrArea'].count())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0      861\n",
            "72.0       8\n",
            "180.0      8\n",
            "108.0      8\n",
            "120.0      7\n",
            "        ... \n",
            "651.0      1\n",
            "337.0      1\n",
            "415.0      1\n",
            "293.0      1\n",
            "621.0      1\n",
            "Name: MasVnrArea, Length: 327, dtype: int64\n",
            "1452\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6yOc2Au_h87",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0516a0e2-14ae-4a27-ddcc-4108518bb16b"
      },
      "source": [
        "dataframe['MasVnrArea'].fillna(value=0.0,inplace=True)\n",
        "print(dataframe['MasVnrArea'].count())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1460\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RguK_e36_k0_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "5046f428-3668-4867-c9b8-ba6cd4f7ecd9"
      },
      "source": [
        "print(dataframe['Electrical'].value_counts())\n",
        "print(dataframe['Electrical'].count())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SBrkr    1334\n",
            "FuseA      94\n",
            "FuseF      27\n",
            "FuseP       3\n",
            "Mix         1\n",
            "Name: Electrical, dtype: int64\n",
            "1459\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgyCNqBu_oyn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4310ddc6-29e9-4860-bebd-fb482c986a8f"
      },
      "source": [
        "dataframe['Electrical'].fillna(value='SBrkr',inplace=True)\n",
        "print(dataframe['Electrical'].count())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1460\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMTX9U-3_uTl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "b4055e92-c911-47de-c092-bea9ad48b49f"
      },
      "source": [
        "print(dataframe['GarageYrBlt'].value_counts())\n",
        "print(dataframe['GarageYrBlt'].count())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2005.0    65\n",
            "2006.0    59\n",
            "2004.0    53\n",
            "2003.0    50\n",
            "2007.0    49\n",
            "          ..\n",
            "1908.0     1\n",
            "1927.0     1\n",
            "1933.0     1\n",
            "1900.0     1\n",
            "1906.0     1\n",
            "Name: GarageYrBlt, Length: 97, dtype: int64\n",
            "1379\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fh1J2a0F_yxy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataframe['GarageYrBlt'].fillna(value=dataframe['GarageYrBlt'].mean(),inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7oKw0ieADLK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b5bac0be-a874-4373-be13-18165d044ff1"
      },
      "source": [
        "dataframe['GarageYrBlt'].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1460,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWvLMbbOAMt1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "5f7903a0-4761-42a8-a2a8-197f82c0978b"
      },
      "source": [
        "miss_col=dataframe.columns[dataframe.isnull().any()].tolist()\n",
        "miss_col"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Alley',\n",
              " 'BsmtQual',\n",
              " 'BsmtCond',\n",
              " 'BsmtExposure',\n",
              " 'BsmtFinType1',\n",
              " 'BsmtFinType2',\n",
              " 'FireplaceQu',\n",
              " 'GarageType',\n",
              " 'GarageFinish',\n",
              " 'GarageQual',\n",
              " 'GarageCond',\n",
              " 'PoolQC',\n",
              " 'Fence',\n",
              " 'MiscFeature']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyJ5WLwtAO27",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for col in miss_col:\n",
        "    dataframe[col].fillna(value='NA',inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SuIrgCxAUie",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "56f73693-ea98-47db-ad44-14d803c4ac8a"
      },
      "source": [
        "dataframe.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1460 entries, 0 to 359\n",
            "Data columns (total 80 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   Id             1460 non-null   int64  \n",
            " 1   MSSubClass     1460 non-null   int64  \n",
            " 2   MSZoning       1460 non-null   object \n",
            " 3   LotFrontage    1460 non-null   float64\n",
            " 4   LotArea        1460 non-null   int64  \n",
            " 5   Street         1460 non-null   object \n",
            " 6   Alley          1460 non-null   object \n",
            " 7   LotShape       1460 non-null   object \n",
            " 8   LandContour    1460 non-null   object \n",
            " 9   Utilities      1460 non-null   object \n",
            " 10  LotConfig      1460 non-null   object \n",
            " 11  LandSlope      1460 non-null   object \n",
            " 12  Neighborhood   1460 non-null   object \n",
            " 13  Condition1     1460 non-null   object \n",
            " 14  Condition2     1460 non-null   object \n",
            " 15  BldgType       1460 non-null   object \n",
            " 16  HouseStyle     1460 non-null   object \n",
            " 17  OverallQual    1460 non-null   int64  \n",
            " 18  OverallCond    1460 non-null   int64  \n",
            " 19  YearBuilt      1460 non-null   int64  \n",
            " 20  YearRemodAdd   1460 non-null   int64  \n",
            " 21  RoofStyle      1460 non-null   object \n",
            " 22  RoofMatl       1460 non-null   object \n",
            " 23  Exterior1st    1460 non-null   object \n",
            " 24  Exterior2nd    1460 non-null   object \n",
            " 25  MasVnrType     1460 non-null   object \n",
            " 26  MasVnrArea     1460 non-null   float64\n",
            " 27  ExterQual      1460 non-null   object \n",
            " 28  ExterCond      1460 non-null   object \n",
            " 29  Foundation     1460 non-null   object \n",
            " 30  BsmtQual       1460 non-null   object \n",
            " 31  BsmtCond       1460 non-null   object \n",
            " 32  BsmtExposure   1460 non-null   object \n",
            " 33  BsmtFinType1   1460 non-null   object \n",
            " 34  BsmtFinSF1     1460 non-null   int64  \n",
            " 35  BsmtFinType2   1460 non-null   object \n",
            " 36  BsmtFinSF2     1460 non-null   int64  \n",
            " 37  BsmtUnfSF      1460 non-null   int64  \n",
            " 38  TotalBsmtSF    1460 non-null   int64  \n",
            " 39  Heating        1460 non-null   object \n",
            " 40  HeatingQC      1460 non-null   object \n",
            " 41  CentralAir     1460 non-null   object \n",
            " 42  Electrical     1460 non-null   object \n",
            " 43  1stFlrSF       1460 non-null   int64  \n",
            " 44  2ndFlrSF       1460 non-null   int64  \n",
            " 45  LowQualFinSF   1460 non-null   int64  \n",
            " 46  GrLivArea      1460 non-null   int64  \n",
            " 47  BsmtFullBath   1460 non-null   int64  \n",
            " 48  BsmtHalfBath   1460 non-null   int64  \n",
            " 49  FullBath       1460 non-null   int64  \n",
            " 50  HalfBath       1460 non-null   int64  \n",
            " 51  BedroomAbvGr   1460 non-null   int64  \n",
            " 52  KitchenAbvGr   1460 non-null   int64  \n",
            " 53  KitchenQual    1460 non-null   object \n",
            " 54  TotRmsAbvGrd   1460 non-null   int64  \n",
            " 55  Functional     1460 non-null   object \n",
            " 56  Fireplaces     1460 non-null   int64  \n",
            " 57  FireplaceQu    1460 non-null   object \n",
            " 58  GarageType     1460 non-null   object \n",
            " 59  GarageYrBlt    1460 non-null   float64\n",
            " 60  GarageFinish   1460 non-null   object \n",
            " 61  GarageCars     1460 non-null   int64  \n",
            " 62  GarageArea     1460 non-null   int64  \n",
            " 63  GarageQual     1460 non-null   object \n",
            " 64  GarageCond     1460 non-null   object \n",
            " 65  PavedDrive     1460 non-null   object \n",
            " 66  WoodDeckSF     1460 non-null   int64  \n",
            " 67  OpenPorchSF    1460 non-null   int64  \n",
            " 68  EnclosedPorch  1460 non-null   int64  \n",
            " 69  3SsnPorch      1460 non-null   int64  \n",
            " 70  ScreenPorch    1460 non-null   int64  \n",
            " 71  PoolArea       1460 non-null   int64  \n",
            " 72  PoolQC         1460 non-null   object \n",
            " 73  Fence          1460 non-null   object \n",
            " 74  MiscFeature    1460 non-null   object \n",
            " 75  MiscVal        1460 non-null   int64  \n",
            " 76  MoSold         1460 non-null   int64  \n",
            " 77  YrSold         1460 non-null   int64  \n",
            " 78  SaleType       1460 non-null   object \n",
            " 79  SaleCondition  1460 non-null   object \n",
            "dtypes: float64(3), int64(34), object(43)\n",
            "memory usage: 923.9+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5_GgoWpAXk1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataframe.drop(columns=['Id'],inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H06XuJzNAb6H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5d8c0e7d-c1b1-4ec3-ab73-56fbb1113432"
      },
      "source": [
        "dataframe.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1460, 79)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34ffB2DpAfFO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "9f664676-3121-414c-f6bf-f04314572e41"
      },
      "source": [
        "col=dataframe.columns[dataframe.dtypes=='O']\n",
        "col"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities',\n",
              "       'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2',\n",
              "       'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st',\n",
              "       'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation',\n",
              "       'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n",
              "       'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual',\n",
              "       'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual',\n",
              "       'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature',\n",
              "       'SaleType', 'SaleCondition'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lened7FhAidr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNV7sOHOAqfd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "le=LabelEncoder()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqBmIYI5AuLK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataframe[col]=dataframe[col].apply(le.fit_transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9C0YvdmRAwh_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "outputId": "555d6b6e-8fb3-48a1-83d6-0f44dae0bd68"
      },
      "source": [
        "dataframe.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>Alley</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>LotConfig</th>\n",
              "      <th>LandSlope</th>\n",
              "      <th>Neighborhood</th>\n",
              "      <th>Condition1</th>\n",
              "      <th>Condition2</th>\n",
              "      <th>BldgType</th>\n",
              "      <th>HouseStyle</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>RoofStyle</th>\n",
              "      <th>RoofMatl</th>\n",
              "      <th>Exterior1st</th>\n",
              "      <th>Exterior2nd</th>\n",
              "      <th>MasVnrType</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>ExterQual</th>\n",
              "      <th>ExterCond</th>\n",
              "      <th>Foundation</th>\n",
              "      <th>BsmtQual</th>\n",
              "      <th>BsmtCond</th>\n",
              "      <th>BsmtExposure</th>\n",
              "      <th>BsmtFinType1</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtFinType2</th>\n",
              "      <th>BsmtFinSF2</th>\n",
              "      <th>BsmtUnfSF</th>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <th>Heating</th>\n",
              "      <th>HeatingQC</th>\n",
              "      <th>CentralAir</th>\n",
              "      <th>Electrical</th>\n",
              "      <th>1stFlrSF</th>\n",
              "      <th>2ndFlrSF</th>\n",
              "      <th>LowQualFinSF</th>\n",
              "      <th>GrLivArea</th>\n",
              "      <th>BsmtFullBath</th>\n",
              "      <th>BsmtHalfBath</th>\n",
              "      <th>FullBath</th>\n",
              "      <th>HalfBath</th>\n",
              "      <th>BedroomAbvGr</th>\n",
              "      <th>KitchenAbvGr</th>\n",
              "      <th>KitchenQual</th>\n",
              "      <th>TotRmsAbvGrd</th>\n",
              "      <th>Functional</th>\n",
              "      <th>Fireplaces</th>\n",
              "      <th>FireplaceQu</th>\n",
              "      <th>GarageType</th>\n",
              "      <th>GarageYrBlt</th>\n",
              "      <th>GarageFinish</th>\n",
              "      <th>GarageCars</th>\n",
              "      <th>GarageArea</th>\n",
              "      <th>GarageQual</th>\n",
              "      <th>GarageCond</th>\n",
              "      <th>PavedDrive</th>\n",
              "      <th>WoodDeckSF</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>3SsnPorch</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>PoolQC</th>\n",
              "      <th>Fence</th>\n",
              "      <th>MiscFeature</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>60</td>\n",
              "      <td>3</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>8450</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2003</td>\n",
              "      <td>2003</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>196.0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>706</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>856</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>856</td>\n",
              "      <td>854</td>\n",
              "      <td>0</td>\n",
              "      <td>1710</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2003.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>548</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>61</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20</td>\n",
              "      <td>3</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>9600</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>1976</td>\n",
              "      <td>1976</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>978</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>284</td>\n",
              "      <td>1262</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1262</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1262</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1976.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>460</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>298</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2007</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>60</td>\n",
              "      <td>3</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>11250</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2001</td>\n",
              "      <td>2002</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>162.0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>486</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>434</td>\n",
              "      <td>920</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>920</td>\n",
              "      <td>866</td>\n",
              "      <td>0</td>\n",
              "      <td>1786</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>2001.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>608</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2008</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>70</td>\n",
              "      <td>3</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>9550</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>1915</td>\n",
              "      <td>1970</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>15</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>216</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>540</td>\n",
              "      <td>756</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>961</td>\n",
              "      <td>756</td>\n",
              "      <td>0</td>\n",
              "      <td>1717</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1998.0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>642</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>272</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2006</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60</td>\n",
              "      <td>3</td>\n",
              "      <td>84.000000</td>\n",
              "      <td>14260</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>350.0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>655</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>490</td>\n",
              "      <td>1145</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1145</td>\n",
              "      <td>1053</td>\n",
              "      <td>0</td>\n",
              "      <td>2198</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>836</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>192</td>\n",
              "      <td>84</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>2008</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>50</td>\n",
              "      <td>3</td>\n",
              "      <td>85.000000</td>\n",
              "      <td>14115</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>1993</td>\n",
              "      <td>1995</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>732</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>64</td>\n",
              "      <td>796</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>796</td>\n",
              "      <td>566</td>\n",
              "      <td>0</td>\n",
              "      <td>1362</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1993.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>480</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>40</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>320</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>700</td>\n",
              "      <td>10</td>\n",
              "      <td>2009</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>20</td>\n",
              "      <td>3</td>\n",
              "      <td>75.000000</td>\n",
              "      <td>10084</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>2004</td>\n",
              "      <td>2005</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>13</td>\n",
              "      <td>3</td>\n",
              "      <td>186.0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1369</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>317</td>\n",
              "      <td>1686</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1694</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1694</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2004.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>636</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>255</td>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>2007</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>60</td>\n",
              "      <td>3</td>\n",
              "      <td>70.049958</td>\n",
              "      <td>10382</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>1973</td>\n",
              "      <td>1973</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>240.0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>859</td>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>216</td>\n",
              "      <td>1107</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1107</td>\n",
              "      <td>983</td>\n",
              "      <td>0</td>\n",
              "      <td>2090</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1973.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>484</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>235</td>\n",
              "      <td>204</td>\n",
              "      <td>228</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>350</td>\n",
              "      <td>11</td>\n",
              "      <td>2009</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>50</td>\n",
              "      <td>4</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>6120</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>1931</td>\n",
              "      <td>1950</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>15</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>952</td>\n",
              "      <td>952</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1022</td>\n",
              "      <td>752</td>\n",
              "      <td>0</td>\n",
              "      <td>1774</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>1931.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>468</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>90</td>\n",
              "      <td>0</td>\n",
              "      <td>205</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2008</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>190</td>\n",
              "      <td>3</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>7420</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>1939</td>\n",
              "      <td>1950</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>851</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>140</td>\n",
              "      <td>991</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1077</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1077</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1939.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>205</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2008</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   MSSubClass  MSZoning  LotFrontage  ...  YrSold  SaleType  SaleCondition\n",
              "0          60         3    65.000000  ...    2008         8              4\n",
              "1          20         3    80.000000  ...    2007         8              4\n",
              "2          60         3    68.000000  ...    2008         8              4\n",
              "3          70         3    60.000000  ...    2006         8              0\n",
              "4          60         3    84.000000  ...    2008         8              4\n",
              "5          50         3    85.000000  ...    2009         8              4\n",
              "6          20         3    75.000000  ...    2007         8              4\n",
              "7          60         3    70.049958  ...    2009         8              4\n",
              "8          50         4    51.000000  ...    2008         8              0\n",
              "9         190         3    50.000000  ...    2008         8              4\n",
              "\n",
              "[10 rows x 79 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcSeO-iaAzev",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train=dataframe[:1100]\n",
        "x_test=dataframe[1100:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdUW6UWxA2xl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "669107f1-b4dd-4fb3-9f87-cedbb55308d1"
      },
      "source": [
        "print(x_train.shape,x_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1100, 79) (360, 79)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxeviN0-A5Bb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "5c3ecd0b-8b49-4424-e6e0-820d0cea6931"
      },
      "source": [
        "print(target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0       208500\n",
            "1       181500\n",
            "2       223500\n",
            "3       140000\n",
            "4       250000\n",
            "         ...  \n",
            "1095    176432\n",
            "1096    127000\n",
            "1097    170000\n",
            "1098    128000\n",
            "1099    157000\n",
            "Name: SalePrice, Length: 1100, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDz-JCsVA8Kh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5349b006-c418-4724-e3d8-58a9f8d82b05"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQHXD88wA-7C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=Sequential()\n",
        "model.add(Dense(800,activation='relu',input_shape=(79,)))\n",
        "model.add(Dense(300,activation='relu'))\n",
        "model.add(Dense(200,activation='relu'))\n",
        "model.add(Dense(100,activation='relu'))\n",
        "model.add(Dense(50,activation='relu'))\n",
        "model.add(Dense(20,activation='relu'))\n",
        "model.add(Dense(1,activation='linear'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4G1kNyUpBGLb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "7731f943-8053-4d35-afa6-c2b18939d13c"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 800)               64000     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 300)               240300    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 200)               60200     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 100)               20100     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 50)                5050      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 20)                1020      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 21        \n",
            "=================================================================\n",
            "Total params: 390,691\n",
            "Trainable params: 390,691\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvpB_aDLBJzk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',loss='mse',metrics=['mae'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_xF1HZkBOCQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6d893440-ec99-4ddc-8209-a7bbd08da4d3"
      },
      "source": [
        "hist=model.fit(x_train,target,batch_size=128,epochs=1000,validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 880 samples, validate on 220 samples\n",
            "Epoch 1/1000\n",
            "880/880 [==============================] - 2s 2ms/step - loss: 40015737278.8364 - mae: 182893.8906 - val_loss: 35048055379.7818 - val_mae: 172569.5312\n",
            "Epoch 2/1000\n",
            "880/880 [==============================] - 0s 42us/step - loss: 38720835732.9455 - mae: 179641.7500 - val_loss: 32606941519.1273 - val_mae: 165683.0938\n",
            "Epoch 3/1000\n",
            "880/880 [==============================] - 0s 42us/step - loss: 32844053932.2182 - mae: 163527.3281 - val_loss: 21943957094.4000 - val_mae: 131278.4062\n",
            "Epoch 4/1000\n",
            "880/880 [==============================] - 0s 42us/step - loss: 17289611096.4364 - mae: 100942.0938 - val_loss: 4344589665.7455 - val_mae: 45004.5391\n",
            "Epoch 5/1000\n",
            "880/880 [==============================] - 0s 43us/step - loss: 16007304731.9273 - mae: 58792.3164 - val_loss: 4236729204.3636 - val_mae: 43083.1602\n",
            "Epoch 6/1000\n",
            "880/880 [==============================] - 0s 42us/step - loss: 8495926793.3091 - mae: 54856.3672 - val_loss: 5167885069.9636 - val_mae: 48189.2969\n",
            "Epoch 7/1000\n",
            "880/880 [==============================] - 0s 44us/step - loss: 7149371606.1091 - mae: 51911.2617 - val_loss: 3503318230.1091 - val_mae: 38935.2109\n",
            "Epoch 8/1000\n",
            "880/880 [==============================] - 0s 43us/step - loss: 5318796157.6727 - mae: 46730.1836 - val_loss: 3357814988.8000 - val_mae: 42315.1289\n",
            "Epoch 9/1000\n",
            "880/880 [==============================] - 0s 42us/step - loss: 4379460980.3636 - mae: 45976.9648 - val_loss: 3136452822.1091 - val_mae: 38646.8047\n",
            "Epoch 10/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 4071153189.2364 - mae: 42925.1406 - val_loss: 3066989000.1455 - val_mae: 38408.4805\n",
            "Epoch 11/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 3646436561.4545 - mae: 43951.3906 - val_loss: 3184667824.8727 - val_mae: 41717.5664\n",
            "Epoch 12/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 3471183895.2727 - mae: 43160.7383 - val_loss: 2925936612.0727 - val_mae: 37761.5586\n",
            "Epoch 13/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 3326479881.3091 - mae: 41425.1367 - val_loss: 2866215451.9273 - val_mae: 37855.2461\n",
            "Epoch 14/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 3164291113.8909 - mae: 40764.0195 - val_loss: 2794597306.1818 - val_mae: 37576.3828\n",
            "Epoch 15/1000\n",
            "880/880 [==============================] - 0s 39us/step - loss: 3025454284.8000 - mae: 39827.1836 - val_loss: 2689826597.2364 - val_mae: 36585.0391\n",
            "Epoch 16/1000\n",
            "880/880 [==============================] - 0s 44us/step - loss: 2886529070.5455 - mae: 38514.3359 - val_loss: 2588915712.0000 - val_mae: 35703.2227\n",
            "Epoch 17/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 2756655732.3636 - mae: 37986.9102 - val_loss: 2494165089.7455 - val_mae: 35091.9336\n",
            "Epoch 18/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 2604726846.8364 - mae: 36343.6641 - val_loss: 2373606567.5636 - val_mae: 33937.8516\n",
            "Epoch 19/1000\n",
            "880/880 [==============================] - 0s 37us/step - loss: 2467733355.0545 - mae: 35012.1758 - val_loss: 2305350912.0000 - val_mae: 33923.3359\n",
            "Epoch 20/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 2330257473.1636 - mae: 34497.7148 - val_loss: 2129451422.2545 - val_mae: 31487.1680\n",
            "Epoch 21/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 2202407258.7636 - mae: 32070.9141 - val_loss: 2137034130.6182 - val_mae: 32675.9668\n",
            "Epoch 22/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 2072874630.9818 - mae: 31859.2344 - val_loss: 1931723959.8545 - val_mae: 29691.6914\n",
            "Epoch 23/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 1929049092.6545 - mae: 29609.2383 - val_loss: 1887547382.6909 - val_mae: 29598.0723\n",
            "Epoch 24/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1875451636.3636 - mae: 29049.1445 - val_loss: 1804957076.9455 - val_mae: 28581.9141\n",
            "Epoch 25/1000\n",
            "880/880 [==============================] - 0s 39us/step - loss: 1806305647.7091 - mae: 28868.4355 - val_loss: 1730412816.2909 - val_mae: 27808.6504\n",
            "Epoch 26/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 1704685798.4000 - mae: 27338.5098 - val_loss: 1752458160.8727 - val_mae: 28266.9961\n",
            "Epoch 27/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 1659738893.9636 - mae: 26958.2402 - val_loss: 1674521951.4182 - val_mae: 27683.6719\n",
            "Epoch 28/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 1634698707.7818 - mae: 26661.6270 - val_loss: 1669039937.1636 - val_mae: 27812.9805\n",
            "Epoch 29/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 1625105186.9091 - mae: 26571.8926 - val_loss: 1666191013.2364 - val_mae: 27863.2051\n",
            "Epoch 30/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 1624516473.0182 - mae: 26522.7266 - val_loss: 1639881029.8182 - val_mae: 27886.0723\n",
            "Epoch 31/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 1607667853.9636 - mae: 26447.0957 - val_loss: 1652118686.2545 - val_mae: 27877.0195\n",
            "Epoch 32/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 1589326585.0182 - mae: 26464.2598 - val_loss: 1664622896.8727 - val_mae: 27880.4082\n",
            "Epoch 33/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 1587745446.4000 - mae: 26276.5957 - val_loss: 1670345990.9818 - val_mae: 27853.7363\n",
            "Epoch 34/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 1608611155.7818 - mae: 26231.7363 - val_loss: 1634819635.2000 - val_mae: 27986.5410\n",
            "Epoch 35/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 1653482295.8545 - mae: 27179.8320 - val_loss: 1897005810.0364 - val_mae: 30125.1758\n",
            "Epoch 36/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 1679885086.2545 - mae: 26806.5000 - val_loss: 1630172234.4727 - val_mae: 27870.7949\n",
            "Epoch 37/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 1564452219.3455 - mae: 26122.8359 - val_loss: 1699302839.8545 - val_mae: 27960.9180\n",
            "Epoch 38/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 1570171308.2182 - mae: 26113.9668 - val_loss: 1624837089.7455 - val_mae: 27623.2207\n",
            "Epoch 39/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 1551191945.3091 - mae: 25901.5312 - val_loss: 1700569672.1455 - val_mae: 27968.8555\n",
            "Epoch 40/1000\n",
            "880/880 [==============================] - 0s 38us/step - loss: 1566770404.0727 - mae: 25868.1641 - val_loss: 1624359593.8909 - val_mae: 27495.7773\n",
            "Epoch 41/1000\n",
            "880/880 [==============================] - 0s 37us/step - loss: 1546181555.2000 - mae: 25711.6270 - val_loss: 1616768477.0909 - val_mae: 27519.8105\n",
            "Epoch 42/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1534026565.8182 - mae: 25705.4551 - val_loss: 1680479946.4727 - val_mae: 27774.2910\n",
            "Epoch 43/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 1534146513.4545 - mae: 25790.2539 - val_loss: 1607468590.5455 - val_mae: 27585.3496\n",
            "Epoch 44/1000\n",
            "880/880 [==============================] - 0s 43us/step - loss: 1545261481.8909 - mae: 25959.4082 - val_loss: 1734433275.3455 - val_mae: 28342.7461\n",
            "Epoch 45/1000\n",
            "880/880 [==============================] - 0s 46us/step - loss: 1567365513.3091 - mae: 25944.0957 - val_loss: 1616285498.1818 - val_mae: 27731.5039\n",
            "Epoch 46/1000\n",
            "880/880 [==============================] - 0s 37us/step - loss: 1550508073.8909 - mae: 25748.8203 - val_loss: 1623908328.7273 - val_mae: 27438.7637\n",
            "Epoch 47/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 1529662803.7818 - mae: 25757.2051 - val_loss: 1632747124.3636 - val_mae: 27403.7598\n",
            "Epoch 48/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1543710550.1091 - mae: 25698.5391 - val_loss: 1598770811.3455 - val_mae: 27434.9746\n",
            "Epoch 49/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 1526689775.7091 - mae: 25653.2324 - val_loss: 1662922177.1636 - val_mae: 27625.3047\n",
            "Epoch 50/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1505215734.6909 - mae: 25342.2949 - val_loss: 1596966825.8909 - val_mae: 27353.1426\n",
            "Epoch 51/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1505551732.3636 - mae: 25363.5371 - val_loss: 1653884073.8909 - val_mae: 27567.6289\n",
            "Epoch 52/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 1524278332.5091 - mae: 25605.1016 - val_loss: 1591411065.0182 - val_mae: 27316.1445\n",
            "Epoch 53/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 1499088421.2364 - mae: 25194.8105 - val_loss: 1622581839.1273 - val_mae: 27279.6055\n",
            "Epoch 54/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 1497927081.8909 - mae: 25119.8574 - val_loss: 1606546988.2182 - val_mae: 27187.5918\n",
            "Epoch 55/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 1491881980.5091 - mae: 25106.9219 - val_loss: 1626620946.6182 - val_mae: 27281.4492\n",
            "Epoch 56/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 1499391443.7818 - mae: 25216.9316 - val_loss: 1648646942.2545 - val_mae: 27488.7070\n",
            "Epoch 57/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1502977892.0727 - mae: 25218.1621 - val_loss: 1592462010.1818 - val_mae: 27308.3730\n",
            "Epoch 58/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1528355395.4909 - mae: 25553.2734 - val_loss: 1586787940.0727 - val_mae: 27166.8926\n",
            "Epoch 59/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 1487504525.9636 - mae: 25096.0742 - val_loss: 1627560415.4182 - val_mae: 27331.5234\n",
            "Epoch 60/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 1481370198.1091 - mae: 25041.8496 - val_loss: 1591271356.5091 - val_mae: 27324.3945\n",
            "Epoch 61/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1489006848.0000 - mae: 25457.2461 - val_loss: 1663500306.6182 - val_mae: 27702.1621\n",
            "Epoch 62/1000\n",
            "880/880 [==============================] - 0s 37us/step - loss: 1473565975.2727 - mae: 25063.4453 - val_loss: 1586400330.4727 - val_mae: 27238.0059\n",
            "Epoch 63/1000\n",
            "880/880 [==============================] - 0s 37us/step - loss: 1535566664.1455 - mae: 25568.3164 - val_loss: 1581106506.4727 - val_mae: 27125.5547\n",
            "Epoch 64/1000\n",
            "880/880 [==============================] - 0s 37us/step - loss: 1498023954.6182 - mae: 25281.1953 - val_loss: 1630201362.6182 - val_mae: 27364.1406\n",
            "Epoch 65/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 1471018912.5818 - mae: 25007.7090 - val_loss: 1583463768.4364 - val_mae: 26913.7949\n",
            "Epoch 66/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 1471934945.7455 - mae: 24946.5508 - val_loss: 1574846142.8364 - val_mae: 26965.3301\n",
            "Epoch 67/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 1471041231.1273 - mae: 25364.7324 - val_loss: 1734697755.9273 - val_mae: 28475.0117\n",
            "Epoch 68/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1498083814.4000 - mae: 25348.0859 - val_loss: 1574856662.1091 - val_mae: 26935.3086\n",
            "Epoch 69/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 1462054304.5818 - mae: 25007.0059 - val_loss: 1596646935.2727 - val_mae: 27007.1094\n",
            "Epoch 70/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1517064208.2909 - mae: 25692.7969 - val_loss: 1747772192.5818 - val_mae: 28670.0859\n",
            "Epoch 71/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 1519473954.9091 - mae: 25733.1934 - val_loss: 1572828683.6364 - val_mae: 26907.8945\n",
            "Epoch 72/1000\n",
            "880/880 [==============================] - 0s 42us/step - loss: 1537475849.3091 - mae: 25469.9141 - val_loss: 1582172201.8909 - val_mae: 27070.8906\n",
            "Epoch 73/1000\n",
            "880/880 [==============================] - 0s 44us/step - loss: 1482519882.4727 - mae: 25570.6953 - val_loss: 1718013928.7273 - val_mae: 28355.8770\n",
            "Epoch 74/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 1456357110.6909 - mae: 24965.7227 - val_loss: 1578092206.5455 - val_mae: 27030.6816\n",
            "Epoch 75/1000\n",
            "880/880 [==============================] - 0s 45us/step - loss: 1475502948.0727 - mae: 24744.3496 - val_loss: 1576325634.3273 - val_mae: 26837.6426\n",
            "Epoch 76/1000\n",
            "880/880 [==============================] - 0s 40us/step - loss: 1463668791.8545 - mae: 24743.5586 - val_loss: 1573341682.0364 - val_mae: 26804.2070\n",
            "Epoch 77/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1498680560.8727 - mae: 25252.1289 - val_loss: 1717299893.5273 - val_mae: 28307.2227\n",
            "Epoch 78/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 1531739336.1455 - mae: 25829.7871 - val_loss: 1570051600.2909 - val_mae: 26820.5586\n",
            "Epoch 79/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 1452114262.1091 - mae: 25118.6191 - val_loss: 1599635625.8909 - val_mae: 26961.8809\n",
            "Epoch 80/1000\n",
            "880/880 [==============================] - 0s 37us/step - loss: 1438626513.4545 - mae: 24707.9492 - val_loss: 1583921261.3818 - val_mae: 26855.3730\n",
            "Epoch 81/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 1446226425.0182 - mae: 24735.0918 - val_loss: 1574199063.2727 - val_mae: 26735.0938\n",
            "Epoch 82/1000\n",
            "880/880 [==============================] - 0s 37us/step - loss: 1457571919.1273 - mae: 24942.8086 - val_loss: 1575864347.9273 - val_mae: 26980.5195\n",
            "Epoch 83/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1478381896.1455 - mae: 25140.4883 - val_loss: 1611197295.7091 - val_mae: 27154.5840\n",
            "Epoch 84/1000\n",
            "880/880 [==============================] - 0s 39us/step - loss: 1513230000.8727 - mae: 25489.4023 - val_loss: 1717384569.0182 - val_mae: 28321.2227\n",
            "Epoch 85/1000\n",
            "880/880 [==============================] - 0s 37us/step - loss: 1490035483.9273 - mae: 26073.1934 - val_loss: 1658618430.8364 - val_mae: 28211.2910\n",
            "Epoch 86/1000\n",
            "880/880 [==============================] - 0s 43us/step - loss: 1567384834.3273 - mae: 25747.7305 - val_loss: 1653903364.6545 - val_mae: 27606.5176\n",
            "Epoch 87/1000\n",
            "880/880 [==============================] - 0s 42us/step - loss: 1444105541.8182 - mae: 24853.2637 - val_loss: 1560327275.0545 - val_mae: 26630.9551\n",
            "Epoch 88/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 1454208493.3818 - mae: 25068.3008 - val_loss: 1614261659.9273 - val_mae: 27575.6250\n",
            "Epoch 89/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 1512777627.9273 - mae: 25498.5117 - val_loss: 1653295050.4727 - val_mae: 27569.3770\n",
            "Epoch 90/1000\n",
            "880/880 [==============================] - 0s 43us/step - loss: 1414526797.9636 - mae: 24570.7207 - val_loss: 1551213686.6909 - val_mae: 26448.7617\n",
            "Epoch 91/1000\n",
            "880/880 [==============================] - 0s 39us/step - loss: 1409292678.9818 - mae: 24257.1855 - val_loss: 1564503305.3091 - val_mae: 26581.4082\n",
            "Epoch 92/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 1409105503.4182 - mae: 24325.1152 - val_loss: 1545178342.4000 - val_mae: 26380.2168\n",
            "Epoch 93/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 1459746322.6182 - mae: 24671.8281 - val_loss: 1568808364.2182 - val_mae: 26694.4824\n",
            "Epoch 94/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 1501013478.4000 - mae: 25377.0742 - val_loss: 1758844157.6727 - val_mae: 28891.8438\n",
            "Epoch 95/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 1487837716.9455 - mae: 25486.5605 - val_loss: 1556898024.7273 - val_mae: 26656.6777\n",
            "Epoch 96/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 1432403479.2727 - mae: 24651.7793 - val_loss: 1551921475.4909 - val_mae: 26494.0449\n",
            "Epoch 97/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 1473639368.1455 - mae: 24699.5195 - val_loss: 1663457915.3455 - val_mae: 27729.9941\n",
            "Epoch 98/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 1396521616.2909 - mae: 24704.9902 - val_loss: 1557308213.5273 - val_mae: 26596.0859\n",
            "Epoch 99/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 1387436329.8909 - mae: 24445.5703 - val_loss: 1675754319.1273 - val_mae: 27800.3809\n",
            "Epoch 100/1000\n",
            "880/880 [==============================] - 0s 37us/step - loss: 1422571813.2364 - mae: 24506.9707 - val_loss: 1540701707.6364 - val_mae: 26262.5293\n",
            "Epoch 101/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 1408184494.5455 - mae: 24240.0527 - val_loss: 1534923627.0545 - val_mae: 26221.3945\n",
            "Epoch 102/1000\n",
            "880/880 [==============================] - 0s 37us/step - loss: 1399825295.1273 - mae: 24333.0430 - val_loss: 1599740462.5455 - val_mae: 26951.7871\n",
            "Epoch 103/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 1404017408.0000 - mae: 24278.3477 - val_loss: 1586112237.3818 - val_mae: 26817.6836\n",
            "Epoch 104/1000\n",
            "880/880 [==============================] - 0s 41us/step - loss: 1416847520.5818 - mae: 24234.9824 - val_loss: 1539402707.7818 - val_mae: 26284.1953\n",
            "Epoch 105/1000\n",
            "880/880 [==============================] - 0s 41us/step - loss: 1416470951.5636 - mae: 24414.6074 - val_loss: 1532708096.0000 - val_mae: 26261.2500\n",
            "Epoch 106/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 1377105135.7091 - mae: 24108.3438 - val_loss: 1574343919.7091 - val_mae: 26702.1406\n",
            "Epoch 107/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 1382169597.6727 - mae: 23991.6523 - val_loss: 1573228914.0364 - val_mae: 26662.4023\n",
            "Epoch 108/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1379536069.8182 - mae: 24059.5703 - val_loss: 1531805863.5636 - val_mae: 26271.5098\n",
            "Epoch 109/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 1435786891.6364 - mae: 24484.8926 - val_loss: 1533936274.6182 - val_mae: 26242.9277\n",
            "Epoch 110/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 1376242310.9818 - mae: 24327.1133 - val_loss: 1534348504.4364 - val_mae: 26313.7129\n",
            "Epoch 111/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1419813843.7818 - mae: 24694.0859 - val_loss: 1781924908.2182 - val_mae: 29195.7812\n",
            "Epoch 112/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 1449368286.2545 - mae: 25334.8574 - val_loss: 1518124397.3818 - val_mae: 26049.4004\n",
            "Epoch 113/1000\n",
            "880/880 [==============================] - 0s 37us/step - loss: 1372980268.2182 - mae: 24054.4609 - val_loss: 1523242014.2545 - val_mae: 26080.5000\n",
            "Epoch 114/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 1356257381.2364 - mae: 23861.8242 - val_loss: 1556342500.0727 - val_mae: 26473.0410\n",
            "Epoch 115/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 1360807044.6545 - mae: 23857.8867 - val_loss: 1568776091.9273 - val_mae: 26610.9551\n",
            "Epoch 116/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 1360611826.0364 - mae: 23857.8906 - val_loss: 1516357080.4364 - val_mae: 26037.8223\n",
            "Epoch 117/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 1369334723.4909 - mae: 23981.3320 - val_loss: 1517200228.0727 - val_mae: 26127.2051\n",
            "Epoch 118/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 1381783023.7091 - mae: 24443.2324 - val_loss: 1577855627.6364 - val_mae: 26703.3027\n",
            "Epoch 119/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 1393817434.7636 - mae: 24469.4121 - val_loss: 1586062736.2909 - val_mae: 26817.1094\n",
            "Epoch 120/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 1380044106.4727 - mae: 24058.8594 - val_loss: 1579615690.4727 - val_mae: 26721.7812\n",
            "Epoch 121/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 1385232377.0182 - mae: 24329.6445 - val_loss: 1512300932.6545 - val_mae: 26003.9453\n",
            "Epoch 122/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 1462195517.6727 - mae: 24943.0781 - val_loss: 1634874749.6727 - val_mae: 27849.1250\n",
            "Epoch 123/1000\n",
            "880/880 [==============================] - 0s 41us/step - loss: 1516726590.8364 - mae: 26608.1504 - val_loss: 2109236866.3273 - val_mae: 33177.3281\n",
            "Epoch 124/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1573657402.1818 - mae: 26980.3691 - val_loss: 1541564816.2909 - val_mae: 26415.2266\n",
            "Epoch 125/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 1498278516.3636 - mae: 26158.1641 - val_loss: 1551441480.1455 - val_mae: 26573.2324\n",
            "Epoch 126/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 1409639188.9455 - mae: 24951.6797 - val_loss: 1761764442.7636 - val_mae: 28930.1309\n",
            "Epoch 127/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 1404497729.1636 - mae: 25098.6152 - val_loss: 1505174523.3455 - val_mae: 25850.4863\n",
            "Epoch 128/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1402476348.5091 - mae: 24207.4434 - val_loss: 1517759520.5818 - val_mae: 26085.1504\n",
            "Epoch 129/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 1370518374.4000 - mae: 24250.3633 - val_loss: 1686081163.6364 - val_mae: 27979.7324\n",
            "Epoch 130/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1406905451.0545 - mae: 24328.6016 - val_loss: 1538511522.9091 - val_mae: 26172.1680\n",
            "Epoch 131/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 1352968564.3636 - mae: 23705.1660 - val_loss: 1515933756.5091 - val_mae: 25856.6758\n",
            "Epoch 132/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1329729903.7091 - mae: 23628.6230 - val_loss: 1556269184.0000 - val_mae: 26409.0918\n",
            "Epoch 133/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 1332330938.1818 - mae: 23660.0391 - val_loss: 1497899033.6000 - val_mae: 25769.3184\n",
            "Epoch 134/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 1376528130.3273 - mae: 24313.3145 - val_loss: 1565306084.0727 - val_mae: 26537.8242\n",
            "Epoch 135/1000\n",
            "880/880 [==============================] - 0s 41us/step - loss: 1329265908.3636 - mae: 23728.8184 - val_loss: 1494894678.1091 - val_mae: 25706.4492\n",
            "Epoch 136/1000\n",
            "880/880 [==============================] - 0s 43us/step - loss: 1342164151.8545 - mae: 23995.5293 - val_loss: 1504164161.1636 - val_mae: 25943.9590\n",
            "Epoch 137/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 1370163871.4182 - mae: 24458.2656 - val_loss: 1684874349.3818 - val_mae: 27983.9863\n",
            "Epoch 138/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 1407200698.1818 - mae: 24594.1953 - val_loss: 1497783738.1818 - val_mae: 25700.7188\n",
            "Epoch 139/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 1359001581.3818 - mae: 24288.9141 - val_loss: 1490197580.8000 - val_mae: 25771.9707\n",
            "Epoch 140/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 1320101692.5091 - mae: 23753.9258 - val_loss: 1588737056.5818 - val_mae: 26863.9531\n",
            "Epoch 141/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 1309242663.5636 - mae: 23677.9355 - val_loss: 1512469524.9455 - val_mae: 26144.1953\n",
            "Epoch 142/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1356310234.7636 - mae: 23998.9941 - val_loss: 1503242635.6364 - val_mae: 25754.8496\n",
            "Epoch 143/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 1299074822.9818 - mae: 23353.4199 - val_loss: 1494245466.7636 - val_mae: 25670.3301\n",
            "Epoch 144/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 1300100042.4727 - mae: 23311.9668 - val_loss: 1486487165.6727 - val_mae: 25580.3887\n",
            "Epoch 145/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 1302600189.6727 - mae: 23403.2305 - val_loss: 1532158152.1455 - val_mae: 26122.0957\n",
            "Epoch 146/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 1304656039.5636 - mae: 23330.3359 - val_loss: 1496634831.1273 - val_mae: 25665.6406\n",
            "Epoch 147/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 1331683625.8909 - mae: 23773.5938 - val_loss: 1513684342.6909 - val_mae: 26246.4453\n",
            "Epoch 148/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1314869325.9636 - mae: 23635.6816 - val_loss: 1523290633.3091 - val_mae: 26041.6543\n",
            "Epoch 149/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1296218109.6727 - mae: 23442.1133 - val_loss: 1505028491.6364 - val_mae: 25769.4180\n",
            "Epoch 150/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 1289536274.6182 - mae: 23583.5371 - val_loss: 1488552173.3818 - val_mae: 25820.7637\n",
            "Epoch 151/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1332849573.2364 - mae: 24103.2051 - val_loss: 1645834777.6000 - val_mae: 27544.9023\n",
            "Epoch 152/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1270113428.9455 - mae: 23608.1719 - val_loss: 1492936582.9818 - val_mae: 25951.3223\n",
            "Epoch 153/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1327217426.6182 - mae: 23913.8359 - val_loss: 1534941463.2727 - val_mae: 26194.2871\n",
            "Epoch 154/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 1323946428.5091 - mae: 23632.2441 - val_loss: 1505669171.2000 - val_mae: 25765.1797\n",
            "Epoch 155/1000\n",
            "880/880 [==============================] - 0s 39us/step - loss: 1295158130.0364 - mae: 23231.0371 - val_loss: 1467134189.3818 - val_mae: 25338.0000\n",
            "Epoch 156/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 1299946900.9455 - mae: 23276.6777 - val_loss: 1460105160.1455 - val_mae: 25324.4395\n",
            "Epoch 157/1000\n",
            "880/880 [==============================] - 0s 38us/step - loss: 1329842476.2182 - mae: 23649.2246 - val_loss: 1550757268.9455 - val_mae: 26423.9629\n",
            "Epoch 158/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 1307917571.4909 - mae: 23266.2188 - val_loss: 1533108994.3273 - val_mae: 26146.1855\n",
            "Epoch 159/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 1272096688.8727 - mae: 23124.0586 - val_loss: 1458613978.7636 - val_mae: 25254.0176\n",
            "Epoch 160/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1275979161.6000 - mae: 23055.3848 - val_loss: 1457799451.9273 - val_mae: 25233.7051\n",
            "Epoch 161/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 1266761418.4727 - mae: 23049.3438 - val_loss: 1470121367.2727 - val_mae: 25361.1445\n",
            "Epoch 162/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 1268103619.4909 - mae: 23302.3613 - val_loss: 1452591353.0182 - val_mae: 25313.3945\n",
            "Epoch 163/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 1293920998.4000 - mae: 23419.5742 - val_loss: 1450493095.5636 - val_mae: 25175.1445\n",
            "Epoch 164/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 1279906013.0909 - mae: 23282.1621 - val_loss: 1525108601.0182 - val_mae: 26100.2734\n",
            "Epoch 165/1000\n",
            "880/880 [==============================] - 0s 38us/step - loss: 1265097069.3818 - mae: 22985.6777 - val_loss: 1458802890.4727 - val_mae: 25232.5449\n",
            "Epoch 166/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 1264847145.8909 - mae: 22967.9434 - val_loss: 1473091630.5455 - val_mae: 25716.2539\n",
            "Epoch 167/1000\n",
            "880/880 [==============================] - 0s 45us/step - loss: 1358550076.5091 - mae: 23946.2090 - val_loss: 1457035506.0364 - val_mae: 25222.1836\n",
            "Epoch 168/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1316876640.5818 - mae: 24032.2695 - val_loss: 1590000090.7636 - val_mae: 26871.5820\n",
            "Epoch 169/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 1279782134.6909 - mae: 23224.8340 - val_loss: 1452010777.6000 - val_mae: 25126.9746\n",
            "Epoch 170/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 1261005477.2364 - mae: 23098.4434 - val_loss: 1454630870.1091 - val_mae: 25463.3770\n",
            "Epoch 171/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 1301945837.3818 - mae: 23504.7949 - val_loss: 1437742610.6182 - val_mae: 25059.9395\n",
            "Epoch 172/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1257229001.3091 - mae: 23052.1211 - val_loss: 1475937954.9091 - val_mae: 25505.4004\n",
            "Epoch 173/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 1266960437.5273 - mae: 23107.7656 - val_loss: 1455502729.3091 - val_mae: 25215.2559\n",
            "Epoch 174/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 1242741746.0364 - mae: 22809.0957 - val_loss: 1452566581.5273 - val_mae: 25195.1953\n",
            "Epoch 175/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1251039218.0364 - mae: 23128.1270 - val_loss: 1448735855.7091 - val_mae: 25476.7402\n",
            "Epoch 176/1000\n",
            "880/880 [==============================] - 0s 39us/step - loss: 1285676372.9455 - mae: 23208.3691 - val_loss: 1429748100.6545 - val_mae: 24925.2598\n",
            "Epoch 177/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 1274948445.0909 - mae: 23437.9453 - val_loss: 1469277149.0909 - val_mae: 25423.8320\n",
            "Epoch 178/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1249288567.8545 - mae: 23043.0391 - val_loss: 1434331603.7818 - val_mae: 24950.2656\n",
            "Epoch 179/1000\n",
            "880/880 [==============================] - 0s 43us/step - loss: 1234024882.0364 - mae: 22792.0176 - val_loss: 1508188250.7636 - val_mae: 25959.3281\n",
            "Epoch 180/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 1256960574.8364 - mae: 22977.0176 - val_loss: 1433599853.3818 - val_mae: 25072.5586\n",
            "Epoch 181/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 1246499656.1455 - mae: 23224.6309 - val_loss: 1463004418.3273 - val_mae: 25323.7539\n",
            "Epoch 182/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1277679208.7273 - mae: 23313.3047 - val_loss: 1631954436.6545 - val_mae: 27485.0879\n",
            "Epoch 183/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1320026727.5636 - mae: 23512.4531 - val_loss: 1475669220.0727 - val_mae: 25537.9121\n",
            "Epoch 184/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 1261562994.0364 - mae: 23040.8770 - val_loss: 1504215386.7636 - val_mae: 26333.3594\n",
            "Epoch 185/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 1298436214.6909 - mae: 23972.2891 - val_loss: 1471198526.8364 - val_mae: 25448.1582\n",
            "Epoch 186/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 1244882216.7273 - mae: 23008.4590 - val_loss: 1491335147.0545 - val_mae: 25699.4414\n",
            "Epoch 187/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 1247641198.5455 - mae: 23060.2441 - val_loss: 1493581968.2909 - val_mae: 25770.4258\n",
            "Epoch 188/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 1286990491.9273 - mae: 23101.5684 - val_loss: 1448770962.6182 - val_mae: 25197.5801\n",
            "Epoch 189/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 1279211522.3273 - mae: 23617.8574 - val_loss: 1473317254.9818 - val_mae: 25839.0918\n",
            "Epoch 190/1000\n",
            "880/880 [==============================] - 0s 44us/step - loss: 1277600130.3273 - mae: 23728.8008 - val_loss: 1413217626.7636 - val_mae: 24733.9160\n",
            "Epoch 191/1000\n",
            "880/880 [==============================] - 0s 43us/step - loss: 1222774182.4000 - mae: 22624.5781 - val_loss: 1417684514.9091 - val_mae: 24795.7832\n",
            "Epoch 192/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 1210723899.3455 - mae: 22593.3320 - val_loss: 1469893087.4182 - val_mae: 25514.4141\n",
            "Epoch 193/1000\n",
            "880/880 [==============================] - 0s 37us/step - loss: 1227139753.8909 - mae: 22703.7480 - val_loss: 1452095688.1455 - val_mae: 25241.3457\n",
            "Epoch 194/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1220289768.7273 - mae: 22666.5430 - val_loss: 1520800044.2182 - val_mae: 26100.4863\n",
            "Epoch 195/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 1232411871.4182 - mae: 23114.2227 - val_loss: 1399935101.6727 - val_mae: 24655.5820\n",
            "Epoch 196/1000\n",
            "880/880 [==============================] - 0s 39us/step - loss: 1219044831.4182 - mae: 22583.2676 - val_loss: 1399483287.2727 - val_mae: 24650.8809\n",
            "Epoch 197/1000\n",
            "880/880 [==============================] - 0s 42us/step - loss: 1252417787.3455 - mae: 22981.4609 - val_loss: 1402828907.0545 - val_mae: 24625.5859\n",
            "Epoch 198/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 1231569360.2909 - mae: 23281.5391 - val_loss: 1716132796.5091 - val_mae: 28684.0820\n",
            "Epoch 199/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 1326405245.6727 - mae: 24811.5820 - val_loss: 1395361629.0909 - val_mae: 24589.8320\n",
            "Epoch 200/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 1231137271.8545 - mae: 22877.0371 - val_loss: 1398881058.9091 - val_mae: 24685.0918\n",
            "Epoch 201/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 1238917140.9455 - mae: 22862.0273 - val_loss: 1427554450.6182 - val_mae: 24971.6445\n",
            "Epoch 202/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 1236262272.0000 - mae: 23011.7773 - val_loss: 1510483695.7091 - val_mae: 25961.5645\n",
            "Epoch 203/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1226429861.2364 - mae: 22922.6543 - val_loss: 1402022590.8364 - val_mae: 24804.2871\n",
            "Epoch 204/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 1287398301.0909 - mae: 23307.0312 - val_loss: 1422866834.6182 - val_mae: 25179.2734\n",
            "Epoch 205/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 1275264965.8182 - mae: 22986.2227 - val_loss: 1416323611.9273 - val_mae: 25081.5449\n",
            "Epoch 206/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1255629349.2364 - mae: 23517.3809 - val_loss: 1454613464.4364 - val_mae: 25290.5156\n",
            "Epoch 207/1000\n",
            "880/880 [==============================] - 0s 38us/step - loss: 1249887984.8727 - mae: 23083.4551 - val_loss: 1519123195.3455 - val_mae: 26119.6230\n",
            "Epoch 208/1000\n",
            "880/880 [==============================] - 0s 44us/step - loss: 1223857006.5455 - mae: 23136.9727 - val_loss: 1387327325.0909 - val_mae: 24592.9141\n",
            "Epoch 209/1000\n",
            "880/880 [==============================] - 0s 41us/step - loss: 1207850295.8545 - mae: 22565.1250 - val_loss: 1380480309.5273 - val_mae: 24584.8711\n",
            "Epoch 210/1000\n",
            "880/880 [==============================] - 0s 42us/step - loss: 1241017988.6545 - mae: 23503.1523 - val_loss: 1476496360.7273 - val_mae: 25598.6094\n",
            "Epoch 211/1000\n",
            "880/880 [==============================] - 0s 44us/step - loss: 1172263225.0182 - mae: 22419.9824 - val_loss: 1392657373.0909 - val_mae: 24596.6055\n",
            "Epoch 212/1000\n",
            "880/880 [==============================] - 0s 44us/step - loss: 1190583296.0000 - mae: 22227.2480 - val_loss: 1396516805.8182 - val_mae: 24550.0781\n",
            "Epoch 213/1000\n",
            "880/880 [==============================] - 0s 45us/step - loss: 1189544442.1818 - mae: 22250.4219 - val_loss: 1386760673.7455 - val_mae: 24482.4355\n",
            "Epoch 214/1000\n",
            "880/880 [==============================] - 0s 43us/step - loss: 1173246284.8000 - mae: 22263.9688 - val_loss: 1410609812.9455 - val_mae: 24755.4453\n",
            "Epoch 215/1000\n",
            "880/880 [==============================] - 0s 40us/step - loss: 1193145054.2545 - mae: 22414.9453 - val_loss: 1427989140.9455 - val_mae: 25344.4414\n",
            "Epoch 216/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 1226701012.9455 - mae: 23049.2246 - val_loss: 1390150451.2000 - val_mae: 24388.3789\n",
            "Epoch 217/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 1188921022.8364 - mae: 22452.4121 - val_loss: 1535728477.0909 - val_mae: 26316.0312\n",
            "Epoch 218/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1213489843.2000 - mae: 22789.1484 - val_loss: 1413241979.3455 - val_mae: 24805.7539\n",
            "Epoch 219/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 1310896865.7455 - mae: 23708.9629 - val_loss: 1405737604.6545 - val_mae: 25081.6641\n",
            "Epoch 220/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 1182939096.4364 - mae: 22873.9277 - val_loss: 1372825711.7091 - val_mae: 24254.0605\n",
            "Epoch 221/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 1193993981.6727 - mae: 22330.4941 - val_loss: 1366928528.2909 - val_mae: 24266.3281\n",
            "Epoch 222/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 1170572585.8909 - mae: 22253.0996 - val_loss: 1381020448.5818 - val_mae: 24384.7480\n",
            "Epoch 223/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1176930904.4364 - mae: 22257.1953 - val_loss: 1402725015.2727 - val_mae: 24654.2676\n",
            "Epoch 224/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 1177724291.4909 - mae: 22375.4473 - val_loss: 1472244044.8000 - val_mae: 25604.8320\n",
            "Epoch 225/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 1209155176.7273 - mae: 22595.4551 - val_loss: 1389574502.4000 - val_mae: 24361.7344\n",
            "Epoch 226/1000\n",
            "880/880 [==============================] - 0s 41us/step - loss: 1208398070.6909 - mae: 22950.7676 - val_loss: 1377509536.5818 - val_mae: 24650.8594\n",
            "Epoch 227/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 1202086905.0182 - mae: 22655.0234 - val_loss: 1352737014.6909 - val_mae: 24178.4902\n",
            "Epoch 228/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 1157082870.6909 - mae: 21981.7051 - val_loss: 1392770925.3818 - val_mae: 24504.1855\n",
            "Epoch 229/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1177894853.8182 - mae: 23048.2129 - val_loss: 1518369177.6000 - val_mae: 26901.1914\n",
            "Epoch 230/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 1282117789.0909 - mae: 24034.0137 - val_loss: 1351417285.8182 - val_mae: 24110.8867\n",
            "Epoch 231/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 1156695178.4727 - mae: 22118.2832 - val_loss: 1363631327.4182 - val_mae: 24224.5137\n",
            "Epoch 232/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1164071768.4364 - mae: 21922.3770 - val_loss: 1430321056.5818 - val_mae: 25092.7324\n",
            "Epoch 233/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 1205125572.6545 - mae: 22834.9824 - val_loss: 1521595806.2545 - val_mae: 26170.5273\n",
            "Epoch 234/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 1180203924.9455 - mae: 22447.2051 - val_loss: 1345708106.4727 - val_mae: 24039.5664\n",
            "Epoch 235/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 1136937582.5455 - mae: 21983.8418 - val_loss: 1419546309.8182 - val_mae: 24934.8066\n",
            "Epoch 236/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1153486195.2000 - mae: 21870.4766 - val_loss: 1347837232.8727 - val_mae: 24045.5449\n",
            "Epoch 237/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 1150280423.5636 - mae: 21911.6582 - val_loss: 1348035314.0364 - val_mae: 24016.5098\n",
            "Epoch 238/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 1158454298.7636 - mae: 22279.3145 - val_loss: 1346744482.9091 - val_mae: 23999.4316\n",
            "Epoch 239/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 1153901969.4545 - mae: 22002.4824 - val_loss: 1346285693.6727 - val_mae: 24104.8145\n",
            "Epoch 240/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 1163055664.8727 - mae: 22362.2031 - val_loss: 1352051968.0000 - val_mae: 24219.1855\n",
            "Epoch 241/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 1229858166.6909 - mae: 23316.0039 - val_loss: 1414431555.4909 - val_mae: 24876.8184\n",
            "Epoch 242/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 1149908484.6545 - mae: 22176.4629 - val_loss: 1405238164.9455 - val_mae: 24809.2656\n",
            "Epoch 243/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 1138958774.6909 - mae: 22132.0566 - val_loss: 1407763490.9091 - val_mae: 24849.5117\n",
            "Epoch 244/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 1159904829.6727 - mae: 22188.7441 - val_loss: 1331400783.1273 - val_mae: 23779.2461\n",
            "Epoch 245/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 1173381057.1636 - mae: 22332.0645 - val_loss: 1384613203.7818 - val_mae: 24824.6191\n",
            "Epoch 246/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 1173686461.6727 - mae: 22911.0605 - val_loss: 1329885979.9273 - val_mae: 23831.4023\n",
            "Epoch 247/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1139595586.3273 - mae: 21944.9004 - val_loss: 1321418502.9818 - val_mae: 23911.6816\n",
            "Epoch 248/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1137147461.8182 - mae: 22003.2773 - val_loss: 1350834015.4182 - val_mae: 24457.8633\n",
            "Epoch 249/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1177763994.7636 - mae: 22825.5859 - val_loss: 1353131543.2727 - val_mae: 24007.5996\n",
            "Epoch 250/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 1112737680.2909 - mae: 21804.3203 - val_loss: 1443988179.7818 - val_mae: 25306.5859\n",
            "Epoch 251/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 1152331468.8000 - mae: 22045.4863 - val_loss: 1412493335.2727 - val_mae: 24919.7070\n",
            "Epoch 252/1000\n",
            "880/880 [==============================] - 0s 38us/step - loss: 1133085153.7455 - mae: 21868.5117 - val_loss: 1322626620.5091 - val_mae: 23702.1133\n",
            "Epoch 253/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1110485236.3636 - mae: 21828.0820 - val_loss: 1360842877.6727 - val_mae: 24113.4551\n",
            "Epoch 254/1000\n",
            "880/880 [==============================] - 0s 39us/step - loss: 1106642693.8182 - mae: 21539.3359 - val_loss: 1381690195.7818 - val_mae: 24455.9160\n",
            "Epoch 255/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1123604868.6545 - mae: 22126.6660 - val_loss: 1314563709.6727 - val_mae: 23604.5176\n",
            "Epoch 256/1000\n",
            "880/880 [==============================] - 0s 41us/step - loss: 1152473783.8545 - mae: 22618.1074 - val_loss: 1388496919.2727 - val_mae: 25262.9023\n",
            "Epoch 257/1000\n",
            "880/880 [==============================] - 0s 37us/step - loss: 1147976105.8909 - mae: 22125.0273 - val_loss: 1317081318.4000 - val_mae: 23666.4824\n",
            "Epoch 258/1000\n",
            "880/880 [==============================] - 0s 37us/step - loss: 1107494386.0364 - mae: 21549.4746 - val_loss: 1420714219.0545 - val_mae: 25050.9688\n",
            "Epoch 259/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1167957960.1455 - mae: 23072.5684 - val_loss: 1307853025.7455 - val_mae: 23478.6699\n",
            "Epoch 260/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1095812445.0909 - mae: 21715.4023 - val_loss: 1313973499.3455 - val_mae: 23787.2949\n",
            "Epoch 261/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1122807931.3455 - mae: 21760.5918 - val_loss: 1302987191.8545 - val_mae: 23527.9434\n",
            "Epoch 262/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 1090951084.2182 - mae: 21451.2461 - val_loss: 1374200333.9636 - val_mae: 24455.7773\n",
            "Epoch 263/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1091759013.2364 - mae: 21595.5312 - val_loss: 1295181588.9455 - val_mae: 23406.3711\n",
            "Epoch 264/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 1084827373.3818 - mae: 21741.5312 - val_loss: 1364923287.2727 - val_mae: 24897.1777\n",
            "Epoch 265/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1193608643.4909 - mae: 23750.3926 - val_loss: 1317829550.5455 - val_mae: 23708.3066\n",
            "Epoch 266/1000\n",
            "880/880 [==============================] - 0s 37us/step - loss: 1085762279.5636 - mae: 21715.2910 - val_loss: 1335470347.6364 - val_mae: 23952.2461\n",
            "Epoch 267/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 1066977243.9273 - mae: 21308.4355 - val_loss: 1284519060.9455 - val_mae: 23508.3223\n",
            "Epoch 268/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 1093637484.2182 - mae: 21588.8633 - val_loss: 1340304081.4545 - val_mae: 24214.4219\n",
            "Epoch 269/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 1143172371.7818 - mae: 22131.8613 - val_loss: 1294283471.1273 - val_mae: 23373.8633\n",
            "Epoch 270/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 1114215430.9818 - mae: 21936.6797 - val_loss: 1285198075.3455 - val_mae: 23265.5742\n",
            "Epoch 271/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1091943803.3455 - mae: 21468.6973 - val_loss: 1351203206.9818 - val_mae: 24209.8457\n",
            "Epoch 272/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1123803962.1818 - mae: 21585.2168 - val_loss: 1316445384.1455 - val_mae: 23720.3184\n",
            "Epoch 273/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1073134780.5091 - mae: 21780.5312 - val_loss: 1383652051.7818 - val_mae: 24687.9121\n",
            "Epoch 274/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1074396015.7091 - mae: 21548.6406 - val_loss: 1276097524.3636 - val_mae: 23134.7871\n",
            "Epoch 275/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1075943507.7818 - mae: 21149.7461 - val_loss: 1271046672.2909 - val_mae: 23181.0312\n",
            "Epoch 276/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 1075067224.4364 - mae: 21712.9121 - val_loss: 1306484314.7636 - val_mae: 23630.1133\n",
            "Epoch 277/1000\n",
            "880/880 [==============================] - 0s 37us/step - loss: 1044634444.8000 - mae: 21021.0469 - val_loss: 1366380301.9636 - val_mae: 24448.2266\n",
            "Epoch 278/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 1076636893.0909 - mae: 21351.9746 - val_loss: 1365564774.4000 - val_mae: 24407.6289\n",
            "Epoch 279/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1092983945.3091 - mae: 21902.4863 - val_loss: 1310635859.7818 - val_mae: 23712.2871\n",
            "Epoch 280/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 1054615350.6909 - mae: 20846.2402 - val_loss: 1298803341.9636 - val_mae: 23485.5449\n",
            "Epoch 281/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 1036518120.7273 - mae: 20992.1777 - val_loss: 1283132283.3455 - val_mae: 23727.0801\n",
            "Epoch 282/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 1119515102.2545 - mae: 21912.6777 - val_loss: 1364918565.2364 - val_mae: 25048.7559\n",
            "Epoch 283/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 1144967570.6182 - mae: 22728.0703 - val_loss: 1269911235.4909 - val_mae: 23038.1543\n",
            "Epoch 284/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 1091515265.1636 - mae: 21367.8496 - val_loss: 1261383970.9091 - val_mae: 23190.6816\n",
            "Epoch 285/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 1027606742.1091 - mae: 21163.8320 - val_loss: 1290830619.9273 - val_mae: 23414.2363\n",
            "Epoch 286/1000\n",
            "880/880 [==============================] - 0s 42us/step - loss: 1041052367.1273 - mae: 21055.2266 - val_loss: 1332389862.4000 - val_mae: 23988.2266\n",
            "Epoch 287/1000\n",
            "880/880 [==============================] - 0s 37us/step - loss: 1039412112.2909 - mae: 21019.7910 - val_loss: 1374421934.5455 - val_mae: 24608.6855\n",
            "Epoch 288/1000\n",
            "880/880 [==============================] - 0s 42us/step - loss: 1089863439.1273 - mae: 21884.8613 - val_loss: 1334616059.3455 - val_mae: 24035.0312\n",
            "Epoch 289/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1046990374.4000 - mae: 21303.6523 - val_loss: 1278121516.2182 - val_mae: 23278.5703\n",
            "Epoch 290/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1048098548.3636 - mae: 21065.7910 - val_loss: 1292818043.3455 - val_mae: 23496.4355\n",
            "Epoch 291/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1016042405.2364 - mae: 20708.2051 - val_loss: 1237901486.5455 - val_mae: 22798.5312\n",
            "Epoch 292/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 1076618309.8182 - mae: 21478.6992 - val_loss: 1263336126.8364 - val_mae: 23437.6953\n",
            "Epoch 293/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 1058534910.8364 - mae: 21886.9531 - val_loss: 1243108954.7636 - val_mae: 22859.3223\n",
            "Epoch 294/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 1026393192.7273 - mae: 21049.1523 - val_loss: 1418716630.1091 - val_mae: 25359.0137\n",
            "Epoch 295/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1039218546.0364 - mae: 21404.6895 - val_loss: 1374911485.6727 - val_mae: 24671.7383\n",
            "Epoch 296/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 1008597012.9455 - mae: 21278.3105 - val_loss: 1219377517.3818 - val_mae: 22668.3867\n",
            "Epoch 297/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1038040665.6000 - mae: 21122.7363 - val_loss: 1221907023.1273 - val_mae: 22460.7949\n",
            "Epoch 298/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 999002919.5636 - mae: 20578.0293 - val_loss: 1219950205.6727 - val_mae: 22492.8750\n",
            "Epoch 299/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 1038467855.1273 - mae: 21200.8906 - val_loss: 1225751330.9091 - val_mae: 22565.7402\n",
            "Epoch 300/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 997408498.0364 - mae: 20434.4688 - val_loss: 1220398955.0545 - val_mae: 22766.1191\n",
            "Epoch 301/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 997042369.1636 - mae: 20710.2266 - val_loss: 1209420346.1818 - val_mae: 22326.7129\n",
            "Epoch 302/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 985734630.4000 - mae: 20484.4824 - val_loss: 1281463973.2364 - val_mae: 23351.9629\n",
            "Epoch 303/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 984168363.0545 - mae: 20480.0293 - val_loss: 1205637785.6000 - val_mae: 22405.9395\n",
            "Epoch 304/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1008695691.6364 - mae: 21225.7617 - val_loss: 1400774893.3818 - val_mae: 25179.2227\n",
            "Epoch 305/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 1095412610.3273 - mae: 22055.8027 - val_loss: 1358075259.3455 - val_mae: 24558.8047\n",
            "Epoch 306/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 1098511285.5273 - mae: 22707.7402 - val_loss: 1317660402.0364 - val_mae: 23916.6406\n",
            "Epoch 307/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 1045605001.3091 - mae: 21335.8184 - val_loss: 1289955246.5455 - val_mae: 23435.7539\n",
            "Epoch 308/1000\n",
            "880/880 [==============================] - 0s 38us/step - loss: 1033572175.1273 - mae: 20944.9883 - val_loss: 1209688275.7818 - val_mae: 22589.3301\n",
            "Epoch 309/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 985563117.3818 - mae: 20446.1699 - val_loss: 1230975536.8727 - val_mae: 22749.3984\n",
            "Epoch 310/1000\n",
            "880/880 [==============================] - 0s 37us/step - loss: 977266532.0727 - mae: 20418.1855 - val_loss: 1258647435.6364 - val_mae: 22990.6953\n",
            "Epoch 311/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1010720095.4182 - mae: 21499.2637 - val_loss: 1635788537.0182 - val_mae: 29064.6934\n",
            "Epoch 312/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 1180596520.7273 - mae: 23921.0098 - val_loss: 1652573426.0364 - val_mae: 29237.1543\n",
            "Epoch 313/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 1204263104.0000 - mae: 24140.6953 - val_loss: 1846753470.8364 - val_mae: 31977.0938\n",
            "Epoch 314/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 1162770359.8545 - mae: 23742.4883 - val_loss: 1420623001.6000 - val_mae: 25678.9121\n",
            "Epoch 315/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 1106293443.4909 - mae: 22578.6387 - val_loss: 1234003756.2182 - val_mae: 22738.0449\n",
            "Epoch 316/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 961153920.0000 - mae: 20371.7695 - val_loss: 1218538468.0727 - val_mae: 22533.5566\n",
            "Epoch 317/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 939851694.5455 - mae: 19973.3418 - val_loss: 1193161125.2364 - val_mae: 22303.1719\n",
            "Epoch 318/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 965298703.1273 - mae: 20458.7539 - val_loss: 1201431142.4000 - val_mae: 22450.7891\n",
            "Epoch 319/1000\n",
            "880/880 [==============================] - 0s 46us/step - loss: 973781671.5636 - mae: 21189.0254 - val_loss: 1169536456.1455 - val_mae: 21809.5703\n",
            "Epoch 320/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 1151140625.4545 - mae: 22254.8418 - val_loss: 1239426506.4727 - val_mae: 23289.6113\n",
            "Epoch 321/1000\n",
            "880/880 [==============================] - 0s 40us/step - loss: 1145902169.6000 - mae: 23562.3184 - val_loss: 1199003250.0364 - val_mae: 22087.1719\n",
            "Epoch 322/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 1003789544.7273 - mae: 20687.5547 - val_loss: 1174320230.4000 - val_mae: 22035.5723\n",
            "Epoch 323/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 1037246396.5091 - mae: 21915.0195 - val_loss: 1181671398.4000 - val_mae: 22064.2812\n",
            "Epoch 324/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 962292435.7818 - mae: 20882.4902 - val_loss: 1401313933.9636 - val_mae: 25355.4883\n",
            "Epoch 325/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 1028095343.7091 - mae: 21205.4980 - val_loss: 1270966676.9455 - val_mae: 23473.8047\n",
            "Epoch 326/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 1069618562.3273 - mae: 21924.9609 - val_loss: 1264835909.8182 - val_mae: 23365.3457\n",
            "Epoch 327/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 1049171736.4364 - mae: 22121.5840 - val_loss: 1379459279.1273 - val_mae: 25008.2871\n",
            "Epoch 328/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 933726629.2364 - mae: 20417.7910 - val_loss: 1218253030.4000 - val_mae: 22672.7402\n",
            "Epoch 329/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 940698719.4182 - mae: 20169.2910 - val_loss: 1260946688.0000 - val_mae: 23733.2090\n",
            "Epoch 330/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 986821876.3636 - mae: 22214.6973 - val_loss: 1157981826.3273 - val_mae: 21528.3945\n",
            "Epoch 331/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 973470437.2364 - mae: 20344.0684 - val_loss: 1144951058.6182 - val_mae: 21890.1543\n",
            "Epoch 332/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 973412546.3273 - mae: 20541.4590 - val_loss: 1163570399.4182 - val_mae: 22012.6230\n",
            "Epoch 333/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 907194044.5091 - mae: 19735.9863 - val_loss: 1150012409.0182 - val_mae: 21664.0195\n",
            "Epoch 334/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 907188766.2545 - mae: 19540.4883 - val_loss: 1137881276.5091 - val_mae: 21521.3945\n",
            "Epoch 335/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 936944723.7818 - mae: 20503.8281 - val_loss: 1162921067.0545 - val_mae: 21775.8418\n",
            "Epoch 336/1000\n",
            "880/880 [==============================] - 0s 47us/step - loss: 898659860.9455 - mae: 19747.6133 - val_loss: 1185205464.4364 - val_mae: 22333.5566\n",
            "Epoch 337/1000\n",
            "880/880 [==============================] - 0s 47us/step - loss: 888957413.2364 - mae: 19559.5371 - val_loss: 1122934376.7273 - val_mae: 21429.9141\n",
            "Epoch 338/1000\n",
            "880/880 [==============================] - 0s 42us/step - loss: 873320439.8545 - mae: 19363.8887 - val_loss: 1138324484.6545 - val_mae: 21483.0039\n",
            "Epoch 339/1000\n",
            "880/880 [==============================] - 0s 43us/step - loss: 869784593.4545 - mae: 19656.3789 - val_loss: 1166572667.3455 - val_mae: 22115.7051\n",
            "Epoch 340/1000\n",
            "880/880 [==============================] - 0s 43us/step - loss: 975675334.9818 - mae: 21006.5234 - val_loss: 1146962620.5091 - val_mae: 21600.2324\n",
            "Epoch 341/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 888504150.1091 - mae: 19834.2207 - val_loss: 1141347544.4364 - val_mae: 21690.4062\n",
            "Epoch 342/1000\n",
            "880/880 [==============================] - 0s 43us/step - loss: 871336623.7091 - mae: 19499.7793 - val_loss: 1139521480.1455 - val_mae: 21653.0918\n",
            "Epoch 343/1000\n",
            "880/880 [==============================] - 0s 43us/step - loss: 871038811.9273 - mae: 19377.9297 - val_loss: 1109434368.0000 - val_mae: 21115.8730\n",
            "Epoch 344/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 900954760.1455 - mae: 20507.6445 - val_loss: 1097292844.2182 - val_mae: 21074.7461\n",
            "Epoch 345/1000\n",
            "880/880 [==============================] - 0s 40us/step - loss: 945986352.8727 - mae: 20420.6387 - val_loss: 1241437740.2182 - val_mae: 23400.8496\n",
            "Epoch 346/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 898428759.2727 - mae: 20439.5547 - val_loss: 1132867360.5818 - val_mae: 21683.7305\n",
            "Epoch 347/1000\n",
            "880/880 [==============================] - 0s 39us/step - loss: 898389885.6727 - mae: 20424.7637 - val_loss: 1102925281.7455 - val_mae: 21263.0020\n",
            "Epoch 348/1000\n",
            "880/880 [==============================] - 0s 38us/step - loss: 883525855.4182 - mae: 19303.3301 - val_loss: 1138654252.2182 - val_mae: 21796.3047\n",
            "Epoch 349/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 845583157.5273 - mae: 19059.3301 - val_loss: 1135108361.3091 - val_mae: 21733.6309\n",
            "Epoch 350/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 857864472.4364 - mae: 19416.6133 - val_loss: 1072365882.1818 - val_mae: 20777.5332\n",
            "Epoch 351/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 815087013.2364 - mae: 18755.7324 - val_loss: 1060295852.2182 - val_mae: 20787.0605\n",
            "Epoch 352/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 853463477.5273 - mae: 19836.3633 - val_loss: 1062426568.1455 - val_mae: 20719.1211\n",
            "Epoch 353/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 833157604.0727 - mae: 18991.5469 - val_loss: 1087298925.3818 - val_mae: 21207.6582\n",
            "Epoch 354/1000\n",
            "880/880 [==============================] - 0s 37us/step - loss: 841831478.6909 - mae: 19461.8906 - val_loss: 1057926881.7455 - val_mae: 20523.2676\n",
            "Epoch 355/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 803300118.1091 - mae: 18718.2930 - val_loss: 1192076783.7091 - val_mae: 23135.6582\n",
            "Epoch 356/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 827617487.1273 - mae: 19303.7949 - val_loss: 1051130137.6000 - val_mae: 20554.6582\n",
            "Epoch 357/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 784485465.6000 - mae: 18518.9199 - val_loss: 1077410066.6182 - val_mae: 20946.1582\n",
            "Epoch 358/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 784084653.9636 - mae: 18390.3203 - val_loss: 1042922149.2364 - val_mae: 20457.2539\n",
            "Epoch 359/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 804596127.4182 - mae: 18891.5898 - val_loss: 1029278380.2182 - val_mae: 20419.9727\n",
            "Epoch 360/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 775725419.0545 - mae: 18570.8867 - val_loss: 1015356646.4000 - val_mae: 20275.5918\n",
            "Epoch 361/1000\n",
            "880/880 [==============================] - 0s 37us/step - loss: 759574949.2364 - mae: 18579.9434 - val_loss: 1190421985.7455 - val_mae: 23100.9043\n",
            "Epoch 362/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 967947115.0545 - mae: 21770.4336 - val_loss: 1082312366.5455 - val_mae: 21379.7363\n",
            "Epoch 363/1000\n",
            "880/880 [==============================] - 0s 37us/step - loss: 848489785.0182 - mae: 19670.8340 - val_loss: 1057292327.5636 - val_mae: 20694.9941\n",
            "Epoch 364/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 779132725.5273 - mae: 18907.8555 - val_loss: 1065793675.6364 - val_mae: 21070.9082\n",
            "Epoch 365/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 784547571.2000 - mae: 18628.4688 - val_loss: 1023921757.0909 - val_mae: 20331.3184\n",
            "Epoch 366/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 769742048.5818 - mae: 18552.4883 - val_loss: 1014112286.2545 - val_mae: 19937.9961\n",
            "Epoch 367/1000\n",
            "880/880 [==============================] - 0s 42us/step - loss: 807521868.8000 - mae: 19147.6836 - val_loss: 1027941138.6182 - val_mae: 20535.4414\n",
            "Epoch 368/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 786292627.7818 - mae: 19489.6113 - val_loss: 1040033670.9818 - val_mae: 20907.6582\n",
            "Epoch 369/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 761865224.1455 - mae: 18711.9180 - val_loss: 1041996278.6909 - val_mae: 20522.8418\n",
            "Epoch 370/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 806741842.6182 - mae: 19466.5566 - val_loss: 1139480555.0545 - val_mae: 22370.5137\n",
            "Epoch 371/1000\n",
            "880/880 [==============================] - 0s 39us/step - loss: 808414673.4545 - mae: 19285.7539 - val_loss: 993908142.5455 - val_mae: 19898.4434\n",
            "Epoch 372/1000\n",
            "880/880 [==============================] - 0s 42us/step - loss: 731963687.5636 - mae: 18401.7441 - val_loss: 1004445088.5818 - val_mae: 20086.3164\n",
            "Epoch 373/1000\n",
            "880/880 [==============================] - 0s 37us/step - loss: 778714435.4909 - mae: 19346.4961 - val_loss: 1155367938.3273 - val_mae: 23040.1953\n",
            "Epoch 374/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 852153285.8182 - mae: 19856.8652 - val_loss: 1071881278.8364 - val_mae: 21476.0020\n",
            "Epoch 375/1000\n",
            "880/880 [==============================] - 0s 37us/step - loss: 813875147.6364 - mae: 19510.4219 - val_loss: 1017855276.2182 - val_mae: 20353.0781\n",
            "Epoch 376/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 811795809.7455 - mae: 19296.5820 - val_loss: 1014235913.3091 - val_mae: 20358.1699\n",
            "Epoch 377/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 702032791.8545 - mae: 17674.9922 - val_loss: 970206107.9273 - val_mae: 19718.2891\n",
            "Epoch 378/1000\n",
            "880/880 [==============================] - 0s 37us/step - loss: 721972079.7091 - mae: 18287.9961 - val_loss: 965005172.3636 - val_mae: 19591.3359\n",
            "Epoch 379/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 704467759.7091 - mae: 17872.7383 - val_loss: 975982873.6000 - val_mae: 19763.0469\n",
            "Epoch 380/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 688341003.6364 - mae: 17661.1270 - val_loss: 963140473.0182 - val_mae: 19513.4219\n",
            "Epoch 381/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 691285440.5818 - mae: 17799.2480 - val_loss: 958322944.0000 - val_mae: 19436.7559\n",
            "Epoch 382/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 689336666.7636 - mae: 17640.7363 - val_loss: 941637364.3636 - val_mae: 19371.8691\n",
            "Epoch 383/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 679954128.2909 - mae: 17686.9883 - val_loss: 946759086.5455 - val_mae: 19228.0371\n",
            "Epoch 384/1000\n",
            "880/880 [==============================] - 0s 37us/step - loss: 689143137.7455 - mae: 17708.5879 - val_loss: 1007213824.0000 - val_mae: 20559.0273\n",
            "Epoch 385/1000\n",
            "880/880 [==============================] - 0s 45us/step - loss: 674457903.7091 - mae: 18218.9473 - val_loss: 940311042.3273 - val_mae: 19302.9766\n",
            "Epoch 386/1000\n",
            "880/880 [==============================] - 0s 42us/step - loss: 657936115.2000 - mae: 17769.3027 - val_loss: 939665989.8182 - val_mae: 19297.1953\n",
            "Epoch 387/1000\n",
            "880/880 [==============================] - 0s 43us/step - loss: 825060166.9818 - mae: 19875.7266 - val_loss: 1020491508.3636 - val_mae: 20716.5586\n",
            "Epoch 388/1000\n",
            "880/880 [==============================] - 0s 42us/step - loss: 712714679.8545 - mae: 18190.5312 - val_loss: 980258189.9636 - val_mae: 20486.5234\n",
            "Epoch 389/1000\n",
            "880/880 [==============================] - 0s 41us/step - loss: 747862865.4545 - mae: 19384.3047 - val_loss: 962498425.0182 - val_mae: 19187.1641\n",
            "Epoch 390/1000\n",
            "880/880 [==============================] - 0s 43us/step - loss: 686054342.9818 - mae: 18258.5625 - val_loss: 952373750.6909 - val_mae: 19339.0410\n",
            "Epoch 391/1000\n",
            "880/880 [==============================] - 0s 44us/step - loss: 676217971.7818 - mae: 17888.8184 - val_loss: 1192243865.6000 - val_mae: 24412.1445\n",
            "Epoch 392/1000\n",
            "880/880 [==============================] - 0s 44us/step - loss: 743067862.1091 - mae: 18805.1582 - val_loss: 972429882.1818 - val_mae: 19622.0254\n",
            "Epoch 393/1000\n",
            "880/880 [==============================] - 0s 44us/step - loss: 713666924.8000 - mae: 18501.0449 - val_loss: 926583042.3273 - val_mae: 19233.7539\n",
            "Epoch 394/1000\n",
            "880/880 [==============================] - 0s 42us/step - loss: 644444546.3273 - mae: 17375.6992 - val_loss: 938179872.5818 - val_mae: 19272.6484\n",
            "Epoch 395/1000\n",
            "880/880 [==============================] - 0s 43us/step - loss: 651219942.4000 - mae: 17509.5859 - val_loss: 971767719.5636 - val_mae: 20286.7734\n",
            "Epoch 396/1000\n",
            "880/880 [==============================] - 0s 44us/step - loss: 662763858.6182 - mae: 17701.3574 - val_loss: 1044555131.3455 - val_mae: 21993.2754\n",
            "Epoch 397/1000\n",
            "880/880 [==============================] - 0s 44us/step - loss: 653179217.4545 - mae: 17748.0879 - val_loss: 927704885.5273 - val_mae: 19229.3223\n",
            "Epoch 398/1000\n",
            "880/880 [==============================] - 0s 43us/step - loss: 636933171.2000 - mae: 17274.9258 - val_loss: 914722669.3818 - val_mae: 18970.5703\n",
            "Epoch 399/1000\n",
            "880/880 [==============================] - 0s 43us/step - loss: 630912104.1455 - mae: 17171.2871 - val_loss: 933454624.5818 - val_mae: 19475.8027\n",
            "Epoch 400/1000\n",
            "880/880 [==============================] - 0s 37us/step - loss: 606864086.1091 - mae: 17089.4082 - val_loss: 922741099.0545 - val_mae: 19040.7734\n",
            "Epoch 401/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 690158967.8545 - mae: 18526.4844 - val_loss: 901954399.4182 - val_mae: 18886.5312\n",
            "Epoch 402/1000\n",
            "880/880 [==============================] - 0s 41us/step - loss: 780820356.6545 - mae: 19805.2383 - val_loss: 993829410.9091 - val_mae: 20935.8906\n",
            "Epoch 403/1000\n",
            "880/880 [==============================] - 0s 42us/step - loss: 716571353.6000 - mae: 18717.4512 - val_loss: 1027683446.6909 - val_mae: 20781.2031\n",
            "Epoch 404/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 740207664.2909 - mae: 19283.9844 - val_loss: 906542971.3455 - val_mae: 19166.9688\n",
            "Epoch 405/1000\n",
            "880/880 [==============================] - 0s 42us/step - loss: 647977416.1455 - mae: 17699.4746 - val_loss: 1169964932.6545 - val_mae: 24758.7734\n",
            "Epoch 406/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 734835044.0727 - mae: 19182.3750 - val_loss: 896851840.0000 - val_mae: 18778.5430\n",
            "Epoch 407/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 643996810.4727 - mae: 17561.6074 - val_loss: 933338491.3455 - val_mae: 19390.5039\n",
            "Epoch 408/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 638990188.8000 - mae: 17821.8516 - val_loss: 904355877.2364 - val_mae: 19108.6406\n",
            "Epoch 409/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 696125370.1818 - mae: 18197.9570 - val_loss: 976352591.1273 - val_mae: 20786.5098\n",
            "Epoch 410/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 654365857.7455 - mae: 17916.7109 - val_loss: 1009684817.4545 - val_mae: 21026.6191\n",
            "Epoch 411/1000\n",
            "880/880 [==============================] - 0s 37us/step - loss: 686823631.1273 - mae: 18182.9434 - val_loss: 952106065.4545 - val_mae: 19493.3008\n",
            "Epoch 412/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 621094511.1273 - mae: 17597.5664 - val_loss: 910373853.0909 - val_mae: 18832.9102\n",
            "Epoch 413/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 590648505.6000 - mae: 16891.8457 - val_loss: 895454408.1455 - val_mae: 19195.2363\n",
            "Epoch 414/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 605177910.6909 - mae: 17225.2188 - val_loss: 886906707.7818 - val_mae: 18796.4590\n",
            "Epoch 415/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 615268713.8909 - mae: 17304.9453 - val_loss: 904197573.8182 - val_mae: 18922.3027\n",
            "Epoch 416/1000\n",
            "880/880 [==============================] - 0s 41us/step - loss: 590937796.6545 - mae: 17148.5879 - val_loss: 970367816.1455 - val_mae: 20978.2812\n",
            "Epoch 417/1000\n",
            "880/880 [==============================] - 0s 39us/step - loss: 659757289.8909 - mae: 18316.4199 - val_loss: 933313759.4182 - val_mae: 20283.9434\n",
            "Epoch 418/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 611528943.7091 - mae: 17534.9023 - val_loss: 886649595.3455 - val_mae: 18483.8066\n",
            "Epoch 419/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 604384029.0909 - mae: 17269.6016 - val_loss: 915231825.4545 - val_mae: 19134.0586\n",
            "Epoch 420/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 792006721.1636 - mae: 20304.3770 - val_loss: 1101634308.6545 - val_mae: 23643.5000\n",
            "Epoch 421/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 685652461.3818 - mae: 18340.6738 - val_loss: 899228672.0000 - val_mae: 18550.9453\n",
            "Epoch 422/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 580196758.1091 - mae: 16703.0996 - val_loss: 873133508.6545 - val_mae: 18659.1934\n",
            "Epoch 423/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 608535472.2909 - mae: 17261.8848 - val_loss: 877083887.7091 - val_mae: 18974.4395\n",
            "Epoch 424/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 540721248.5818 - mae: 16269.0654 - val_loss: 880347077.8182 - val_mae: 18609.7793\n",
            "Epoch 425/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 607398490.7636 - mae: 17364.8633 - val_loss: 1008804449.7455 - val_mae: 21932.4297\n",
            "Epoch 426/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 611456352.5818 - mae: 17200.2832 - val_loss: 890567230.8364 - val_mae: 19156.8457\n",
            "Epoch 427/1000\n",
            "880/880 [==============================] - 0s 37us/step - loss: 683158462.8364 - mae: 18628.8574 - val_loss: 1121679455.4182 - val_mae: 22895.0781\n",
            "Epoch 428/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 843016342.6909 - mae: 20632.1055 - val_loss: 1151087357.6727 - val_mae: 24561.4551\n",
            "Epoch 429/1000\n",
            "880/880 [==============================] - 0s 39us/step - loss: 772095058.6182 - mae: 20004.2656 - val_loss: 1104203671.2727 - val_mae: 24061.5820\n",
            "Epoch 430/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 651838687.4182 - mae: 17916.4961 - val_loss: 888586966.1091 - val_mae: 18901.8730\n",
            "Epoch 431/1000\n",
            "880/880 [==============================] - 0s 39us/step - loss: 612816239.7091 - mae: 17448.2910 - val_loss: 900499297.7455 - val_mae: 19252.8457\n",
            "Epoch 432/1000\n",
            "880/880 [==============================] - 0s 40us/step - loss: 601689460.3636 - mae: 17558.2793 - val_loss: 859922365.6727 - val_mae: 18574.6934\n",
            "Epoch 433/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 544123378.0364 - mae: 16183.4023 - val_loss: 915567311.1273 - val_mae: 19915.1582\n",
            "Epoch 434/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 537413335.2727 - mae: 16337.2373 - val_loss: 878075571.2000 - val_mae: 19150.8691\n",
            "Epoch 435/1000\n",
            "880/880 [==============================] - 0s 45us/step - loss: 567123030.6909 - mae: 16858.7930 - val_loss: 905765827.4909 - val_mae: 18964.2949\n",
            "Epoch 436/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 563701940.9455 - mae: 16564.3379 - val_loss: 854828461.3818 - val_mae: 18543.1367\n",
            "Epoch 437/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 551819191.8545 - mae: 16319.1172 - val_loss: 959526816.5818 - val_mae: 21057.2246\n",
            "Epoch 438/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 569613401.0182 - mae: 16876.5742 - val_loss: 874431875.4909 - val_mae: 18703.8926\n",
            "Epoch 439/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 583907243.6364 - mae: 17018.0723 - val_loss: 868580635.9273 - val_mae: 18676.0195\n",
            "Epoch 440/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 517834710.1091 - mae: 15964.5215 - val_loss: 831945114.7636 - val_mae: 18554.8516\n",
            "Epoch 441/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 518995412.9455 - mae: 16166.2109 - val_loss: 859497339.3455 - val_mae: 18670.6152\n",
            "Epoch 442/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 548510899.2000 - mae: 16704.6094 - val_loss: 926542245.2364 - val_mae: 19696.9551\n",
            "Epoch 443/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 597374716.5091 - mae: 17098.5938 - val_loss: 1079600030.2545 - val_mae: 23860.5273\n",
            "Epoch 444/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 595668483.4909 - mae: 17399.9688 - val_loss: 857974796.8000 - val_mae: 18636.6855\n",
            "Epoch 445/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 539978950.9818 - mae: 16477.8809 - val_loss: 833364160.0000 - val_mae: 18319.5625\n",
            "Epoch 446/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 562095254.1091 - mae: 16810.6816 - val_loss: 915100192.5818 - val_mae: 20425.6836\n",
            "Epoch 447/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 510041153.1636 - mae: 15950.7344 - val_loss: 844772718.5455 - val_mae: 18701.9277\n",
            "Epoch 448/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 499716997.8182 - mae: 15717.0166 - val_loss: 843158856.1455 - val_mae: 18824.5020\n",
            "Epoch 449/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 493837637.8182 - mae: 15676.9443 - val_loss: 857395208.1455 - val_mae: 18993.0469\n",
            "Epoch 450/1000\n",
            "880/880 [==============================] - 0s 43us/step - loss: 500990644.9455 - mae: 15857.3047 - val_loss: 838382907.3455 - val_mae: 18391.5508\n",
            "Epoch 451/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 495938050.3273 - mae: 15827.8525 - val_loss: 811354775.2727 - val_mae: 18280.3047\n",
            "Epoch 452/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 493311090.6182 - mae: 15632.6270 - val_loss: 849712738.9091 - val_mae: 18350.7637\n",
            "Epoch 453/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 489037977.0182 - mae: 15728.4609 - val_loss: 843227772.5091 - val_mae: 19343.5234\n",
            "Epoch 454/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 492980626.0364 - mae: 15852.5557 - val_loss: 830290882.3273 - val_mae: 18441.5254\n",
            "Epoch 455/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 486933153.1636 - mae: 15816.4395 - val_loss: 818044825.6000 - val_mae: 18518.9590\n",
            "Epoch 456/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 553578278.4000 - mae: 16949.2363 - val_loss: 946494063.7091 - val_mae: 21357.0195\n",
            "Epoch 457/1000\n",
            "880/880 [==============================] - 0s 39us/step - loss: 646445321.3091 - mae: 18627.0801 - val_loss: 1286738955.6364 - val_mae: 25072.5098\n",
            "Epoch 458/1000\n",
            "880/880 [==============================] - 0s 44us/step - loss: 694931869.0909 - mae: 19873.9590 - val_loss: 881126184.7273 - val_mae: 18627.5098\n",
            "Epoch 459/1000\n",
            "880/880 [==============================] - 0s 37us/step - loss: 606139813.8182 - mae: 17627.4648 - val_loss: 941867415.2727 - val_mae: 21188.2695\n",
            "Epoch 460/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 567393666.3273 - mae: 16783.3477 - val_loss: 832574854.9818 - val_mae: 18207.2383\n",
            "Epoch 461/1000\n",
            "880/880 [==============================] - 0s 38us/step - loss: 514734118.4000 - mae: 15828.4355 - val_loss: 831663707.9273 - val_mae: 18885.1406\n",
            "Epoch 462/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 514182362.1818 - mae: 15978.3564 - val_loss: 843256000.0000 - val_mae: 18848.7773\n",
            "Epoch 463/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 475021192.1455 - mae: 15583.5049 - val_loss: 803118107.9273 - val_mae: 18112.2520\n",
            "Epoch 464/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 485094354.6182 - mae: 15626.4404 - val_loss: 820964694.1091 - val_mae: 18168.7969\n",
            "Epoch 465/1000\n",
            "880/880 [==============================] - 0s 48us/step - loss: 506762665.8909 - mae: 16014.0820 - val_loss: 831495868.5091 - val_mae: 18112.8945\n",
            "Epoch 466/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 496362443.0545 - mae: 15692.3291 - val_loss: 884910960.8727 - val_mae: 20201.8926\n",
            "Epoch 467/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 508152438.6909 - mae: 16241.9561 - val_loss: 834243948.2182 - val_mae: 18992.1699\n",
            "Epoch 468/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 499380732.5091 - mae: 16100.4346 - val_loss: 858864478.2545 - val_mae: 19010.3281\n",
            "Epoch 469/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 517508985.0182 - mae: 16292.9434 - val_loss: 974778740.3636 - val_mae: 22232.1777\n",
            "Epoch 470/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 505437094.4000 - mae: 16090.7637 - val_loss: 799600674.9091 - val_mae: 18407.6699\n",
            "Epoch 471/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 547496660.9455 - mae: 16475.0996 - val_loss: 829713973.5273 - val_mae: 18159.8945\n",
            "Epoch 472/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 565145981.6727 - mae: 16922.0430 - val_loss: 1129708571.9273 - val_mae: 25280.4219\n",
            "Epoch 473/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 707055305.8909 - mae: 19669.8555 - val_loss: 948385975.8545 - val_mae: 19887.9883\n",
            "Epoch 474/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 653707165.0909 - mae: 18356.4199 - val_loss: 829575170.3273 - val_mae: 18163.7402\n",
            "Epoch 475/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 495599823.7091 - mae: 15786.6025 - val_loss: 858467422.2545 - val_mae: 19841.3105\n",
            "Epoch 476/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 492019043.4909 - mae: 15839.0957 - val_loss: 815760225.7455 - val_mae: 18218.8867\n",
            "Epoch 477/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 497438756.6545 - mae: 15667.4404 - val_loss: 826256468.9455 - val_mae: 18397.4961\n",
            "Epoch 478/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 522614237.6727 - mae: 16170.8867 - val_loss: 878266212.0727 - val_mae: 20026.7656\n",
            "Epoch 479/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 483213783.2727 - mae: 15708.3027 - val_loss: 792405423.7091 - val_mae: 18179.9688\n",
            "Epoch 480/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 471973451.6364 - mae: 15582.2139 - val_loss: 844749437.6727 - val_mae: 19325.0273\n",
            "Epoch 481/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 492430032.2909 - mae: 15546.0547 - val_loss: 800385240.4364 - val_mae: 18016.1777\n",
            "Epoch 482/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 473157740.2182 - mae: 15512.1592 - val_loss: 836294467.4909 - val_mae: 19130.3027\n",
            "Epoch 483/1000\n",
            "880/880 [==============================] - 0s 37us/step - loss: 467826930.0364 - mae: 15215.0420 - val_loss: 817635475.7818 - val_mae: 18905.5801\n",
            "Epoch 484/1000\n",
            "880/880 [==============================] - 0s 40us/step - loss: 455092744.1455 - mae: 15138.7217 - val_loss: 803908411.3455 - val_mae: 18241.4688\n",
            "Epoch 485/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 464400712.1455 - mae: 15340.5566 - val_loss: 793576679.5636 - val_mae: 18284.3086\n",
            "Epoch 486/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 463801814.1091 - mae: 15524.3955 - val_loss: 945504495.7091 - val_mae: 21905.0586\n",
            "Epoch 487/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 521850093.3818 - mae: 16583.1816 - val_loss: 861696182.6909 - val_mae: 19173.3047\n",
            "Epoch 488/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 569899250.0364 - mae: 17660.8223 - val_loss: 793725066.4727 - val_mae: 17741.5371\n",
            "Epoch 489/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 530391280.8727 - mae: 16526.4609 - val_loss: 1011396619.6364 - val_mae: 22828.3809\n",
            "Epoch 490/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 507669877.5273 - mae: 15726.6504 - val_loss: 779347105.7455 - val_mae: 18380.8887\n",
            "Epoch 491/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 518172052.3636 - mae: 15633.5859 - val_loss: 863297413.8182 - val_mae: 19009.1191\n",
            "Epoch 492/1000\n",
            "880/880 [==============================] - 0s 45us/step - loss: 521120929.7455 - mae: 16300.4297 - val_loss: 842837488.8727 - val_mae: 19772.6895\n",
            "Epoch 493/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 543226316.2182 - mae: 16694.2344 - val_loss: 824902110.2545 - val_mae: 17928.5723\n",
            "Epoch 494/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 502889281.1636 - mae: 16090.0293 - val_loss: 908042004.9455 - val_mae: 20907.1055\n",
            "Epoch 495/1000\n",
            "880/880 [==============================] - 0s 41us/step - loss: 472684950.1091 - mae: 15552.6895 - val_loss: 770552631.8545 - val_mae: 18011.5801\n",
            "Epoch 496/1000\n",
            "880/880 [==============================] - 0s 37us/step - loss: 431418488.4364 - mae: 14862.1182 - val_loss: 817530065.4545 - val_mae: 18030.8203\n",
            "Epoch 497/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 458118461.6727 - mae: 15281.1484 - val_loss: 784449793.1636 - val_mae: 18265.2598\n",
            "Epoch 498/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 451363318.1091 - mae: 15394.5117 - val_loss: 838645453.9636 - val_mae: 19673.2949\n",
            "Epoch 499/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 473341341.6727 - mae: 15644.1445 - val_loss: 777200612.0727 - val_mae: 17731.1152\n",
            "Epoch 500/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 461883611.9273 - mae: 15227.2100 - val_loss: 828551392.5818 - val_mae: 19509.8340\n",
            "Epoch 501/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 470288283.9273 - mae: 15590.6182 - val_loss: 769593056.5818 - val_mae: 17979.4160\n",
            "Epoch 502/1000\n",
            "880/880 [==============================] - 0s 43us/step - loss: 469739204.6545 - mae: 15841.8828 - val_loss: 785897210.1818 - val_mae: 17883.9609\n",
            "Epoch 503/1000\n",
            "880/880 [==============================] - 0s 37us/step - loss: 449458390.1091 - mae: 15149.4814 - val_loss: 924325095.5636 - val_mae: 21674.1406\n",
            "Epoch 504/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 454698578.0364 - mae: 15351.9697 - val_loss: 783968956.5091 - val_mae: 18310.9570\n",
            "Epoch 505/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 454433158.4000 - mae: 15209.2754 - val_loss: 776417394.0364 - val_mae: 17812.9766\n",
            "Epoch 506/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 471576000.0000 - mae: 15856.8486 - val_loss: 941530605.3818 - val_mae: 21949.4473\n",
            "Epoch 507/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 501802269.6727 - mae: 16174.4736 - val_loss: 789914869.5273 - val_mae: 17900.8926\n",
            "Epoch 508/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 535994292.3636 - mae: 16418.3613 - val_loss: 786783875.4909 - val_mae: 18287.0039\n",
            "Epoch 509/1000\n",
            "880/880 [==============================] - 0s 41us/step - loss: 470490251.6364 - mae: 15964.7275 - val_loss: 1114201241.6000 - val_mae: 25108.6543\n",
            "Epoch 510/1000\n",
            "880/880 [==============================] - 0s 44us/step - loss: 562273438.8364 - mae: 17535.6914 - val_loss: 764542047.4182 - val_mae: 17876.3926\n",
            "Epoch 511/1000\n",
            "880/880 [==============================] - 0s 43us/step - loss: 498979415.2727 - mae: 16108.4775 - val_loss: 761646592.0000 - val_mae: 17894.3633\n",
            "Epoch 512/1000\n",
            "880/880 [==============================] - 0s 42us/step - loss: 420345111.2727 - mae: 14754.9326 - val_loss: 803769295.1273 - val_mae: 19243.8633\n",
            "Epoch 513/1000\n",
            "880/880 [==============================] - 0s 48us/step - loss: 437014977.7455 - mae: 14994.4639 - val_loss: 779206543.1273 - val_mae: 18366.4941\n",
            "Epoch 514/1000\n",
            "880/880 [==============================] - 0s 41us/step - loss: 407389140.9455 - mae: 14311.8594 - val_loss: 757427291.9273 - val_mae: 18036.9355\n",
            "Epoch 515/1000\n",
            "880/880 [==============================] - 0s 38us/step - loss: 419141720.4364 - mae: 14732.2910 - val_loss: 782627294.2545 - val_mae: 18517.5801\n",
            "Epoch 516/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 406311577.0182 - mae: 14424.6377 - val_loss: 779791193.6000 - val_mae: 18514.0723\n",
            "Epoch 517/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 415112225.7455 - mae: 14669.9795 - val_loss: 753464181.5273 - val_mae: 17829.0801\n",
            "Epoch 518/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 396624631.2727 - mae: 14296.6875 - val_loss: 769113516.2182 - val_mae: 17817.1719\n",
            "Epoch 519/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 408341100.8000 - mae: 14537.5469 - val_loss: 753665515.0545 - val_mae: 17767.8301\n",
            "Epoch 520/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 407231507.7818 - mae: 14655.4404 - val_loss: 759021095.5636 - val_mae: 18061.0566\n",
            "Epoch 521/1000\n",
            "880/880 [==============================] - 0s 39us/step - loss: 392367849.3091 - mae: 14283.8027 - val_loss: 756223362.3273 - val_mae: 18076.1699\n",
            "Epoch 522/1000\n",
            "880/880 [==============================] - 0s 44us/step - loss: 411040994.9091 - mae: 14634.9717 - val_loss: 779180213.5273 - val_mae: 18788.4746\n",
            "Epoch 523/1000\n",
            "880/880 [==============================] - 0s 42us/step - loss: 426748057.0182 - mae: 14820.1318 - val_loss: 771793707.0545 - val_mae: 17668.6230\n",
            "Epoch 524/1000\n",
            "880/880 [==============================] - 0s 50us/step - loss: 417582334.8364 - mae: 14806.7578 - val_loss: 750765562.1818 - val_mae: 18063.0703\n",
            "Epoch 525/1000\n",
            "880/880 [==============================] - 0s 44us/step - loss: 457399173.8182 - mae: 15201.2139 - val_loss: 929704454.9818 - val_mae: 22073.0840\n",
            "Epoch 526/1000\n",
            "880/880 [==============================] - 0s 43us/step - loss: 597176487.5636 - mae: 18084.5820 - val_loss: 927512463.1273 - val_mae: 20232.4883\n",
            "Epoch 527/1000\n",
            "880/880 [==============================] - 0s 43us/step - loss: 538829828.6545 - mae: 17145.3691 - val_loss: 1115945646.5455 - val_mae: 25488.4551\n",
            "Epoch 528/1000\n",
            "880/880 [==============================] - 0s 40us/step - loss: 568970558.8364 - mae: 17641.0820 - val_loss: 756050752.0000 - val_mae: 18247.8027\n",
            "Epoch 529/1000\n",
            "880/880 [==============================] - 0s 41us/step - loss: 439728838.9818 - mae: 14947.0361 - val_loss: 771698611.2000 - val_mae: 18427.8789\n",
            "Epoch 530/1000\n",
            "880/880 [==============================] - 0s 43us/step - loss: 411687036.5091 - mae: 14557.0566 - val_loss: 737190191.7091 - val_mae: 17614.3594\n",
            "Epoch 531/1000\n",
            "880/880 [==============================] - 0s 44us/step - loss: 405609124.0727 - mae: 14555.4053 - val_loss: 756008146.6182 - val_mae: 17763.2773\n",
            "Epoch 532/1000\n",
            "880/880 [==============================] - 0s 44us/step - loss: 406818468.6545 - mae: 14523.0703 - val_loss: 751672335.1273 - val_mae: 17960.1543\n",
            "Epoch 533/1000\n",
            "880/880 [==============================] - 0s 43us/step - loss: 431538028.2182 - mae: 15028.6416 - val_loss: 879073454.5455 - val_mae: 21097.3770\n",
            "Epoch 534/1000\n",
            "880/880 [==============================] - 0s 41us/step - loss: 415417989.8182 - mae: 14689.5771 - val_loss: 791007706.7636 - val_mae: 17972.0195\n",
            "Epoch 535/1000\n",
            "880/880 [==============================] - 0s 49us/step - loss: 413071210.4727 - mae: 14587.8242 - val_loss: 761299456.0000 - val_mae: 18475.1465\n",
            "Epoch 536/1000\n",
            "880/880 [==============================] - 0s 46us/step - loss: 399719553.1636 - mae: 14347.7842 - val_loss: 754591301.8182 - val_mae: 18051.0742\n",
            "Epoch 537/1000\n",
            "880/880 [==============================] - 0s 41us/step - loss: 391823942.9818 - mae: 14231.1025 - val_loss: 751306392.4364 - val_mae: 17500.0918\n",
            "Epoch 538/1000\n",
            "880/880 [==============================] - 0s 45us/step - loss: 403147643.3455 - mae: 14386.7158 - val_loss: 776172685.9636 - val_mae: 18728.1621\n",
            "Epoch 539/1000\n",
            "880/880 [==============================] - 0s 42us/step - loss: 401592331.0545 - mae: 14415.1680 - val_loss: 750531594.4727 - val_mae: 17464.4961\n",
            "Epoch 540/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 401244137.6000 - mae: 14425.1572 - val_loss: 745471582.2545 - val_mae: 17812.0098\n",
            "Epoch 541/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 387380016.2909 - mae: 14243.3096 - val_loss: 770490441.3091 - val_mae: 18656.8086\n",
            "Epoch 542/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 385404495.1273 - mae: 14211.8584 - val_loss: 750785633.7455 - val_mae: 17483.8320\n",
            "Epoch 543/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 433338634.4727 - mae: 15235.0059 - val_loss: 741101296.8727 - val_mae: 17757.8789\n",
            "Epoch 544/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 411492190.8364 - mae: 14820.8252 - val_loss: 825920871.5636 - val_mae: 20030.8203\n",
            "Epoch 545/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 387704100.0727 - mae: 14243.2295 - val_loss: 745162427.3455 - val_mae: 17786.3145\n",
            "Epoch 546/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 406283529.8909 - mae: 14480.7988 - val_loss: 822911286.6909 - val_mae: 19952.1504\n",
            "Epoch 547/1000\n",
            "880/880 [==============================] - 0s 38us/step - loss: 420288713.8909 - mae: 14870.0020 - val_loss: 753992735.4182 - val_mae: 17506.1191\n",
            "Epoch 548/1000\n",
            "880/880 [==============================] - 0s 37us/step - loss: 403852986.7636 - mae: 14442.0273 - val_loss: 758028742.9818 - val_mae: 18512.8301\n",
            "Epoch 549/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 400953158.9818 - mae: 14634.2197 - val_loss: 758945828.0727 - val_mae: 18373.4336\n",
            "Epoch 550/1000\n",
            "880/880 [==============================] - 0s 37us/step - loss: 370759132.5091 - mae: 13730.4326 - val_loss: 747248650.4727 - val_mae: 18075.5762\n",
            "Epoch 551/1000\n",
            "880/880 [==============================] - 0s 47us/step - loss: 382638344.1455 - mae: 14171.6865 - val_loss: 783169204.3636 - val_mae: 18036.0938\n",
            "Epoch 552/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 411773462.6909 - mae: 14686.2500 - val_loss: 874070324.3636 - val_mae: 21005.5039\n",
            "Epoch 553/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 411297264.8727 - mae: 14682.7979 - val_loss: 758193768.7273 - val_mae: 17571.4902\n",
            "Epoch 554/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 371235278.5455 - mae: 13807.6816 - val_loss: 738095787.0545 - val_mae: 17681.6895\n",
            "Epoch 555/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 370416228.6545 - mae: 13935.2139 - val_loss: 819098719.4182 - val_mae: 19721.6133\n",
            "Epoch 556/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 375417827.4909 - mae: 14038.0615 - val_loss: 723385430.1091 - val_mae: 17582.5234\n",
            "Epoch 557/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 366649776.2909 - mae: 13746.3613 - val_loss: 800094730.4727 - val_mae: 19251.1621\n",
            "Epoch 558/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 409159449.0182 - mae: 14566.1465 - val_loss: 742167646.2545 - val_mae: 18144.3594\n",
            "Epoch 559/1000\n",
            "880/880 [==============================] - 0s 40us/step - loss: 469123287.2727 - mae: 15280.1553 - val_loss: 774917985.7455 - val_mae: 18283.9590\n",
            "Epoch 560/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 414363923.7818 - mae: 14799.3486 - val_loss: 742377200.8727 - val_mae: 17961.2090\n",
            "Epoch 561/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 385850303.4182 - mae: 14148.6406 - val_loss: 750874537.8909 - val_mae: 17806.2246\n",
            "Epoch 562/1000\n",
            "880/880 [==============================] - 0s 37us/step - loss: 367553557.5273 - mae: 13787.0977 - val_loss: 722132944.2909 - val_mae: 17562.5820\n",
            "Epoch 563/1000\n",
            "880/880 [==============================] - 0s 42us/step - loss: 363286006.1091 - mae: 13627.2559 - val_loss: 727615306.4727 - val_mae: 17367.1582\n",
            "Epoch 564/1000\n",
            "880/880 [==============================] - 0s 39us/step - loss: 372565150.8364 - mae: 13967.0010 - val_loss: 727129551.1273 - val_mae: 17906.9004\n",
            "Epoch 565/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 397558271.4182 - mae: 14409.3271 - val_loss: 750604126.2545 - val_mae: 18112.6621\n",
            "Epoch 566/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 380224540.5091 - mae: 14071.4033 - val_loss: 725102747.9273 - val_mae: 17726.5371\n",
            "Epoch 567/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 356518946.3273 - mae: 13729.1064 - val_loss: 745588656.8727 - val_mae: 17923.4844\n",
            "Epoch 568/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 396034877.0909 - mae: 14506.8242 - val_loss: 729938959.1273 - val_mae: 17784.0684\n",
            "Epoch 569/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 360120930.9091 - mae: 13810.7012 - val_loss: 749921124.0727 - val_mae: 18146.4707\n",
            "Epoch 570/1000\n",
            "880/880 [==============================] - 0s 42us/step - loss: 352772197.2364 - mae: 13586.5742 - val_loss: 732379361.7455 - val_mae: 17927.0449\n",
            "Epoch 571/1000\n",
            "880/880 [==============================] - 0s 45us/step - loss: 388724846.5455 - mae: 14201.2285 - val_loss: 731917292.2182 - val_mae: 17205.6914\n",
            "Epoch 572/1000\n",
            "880/880 [==============================] - 0s 40us/step - loss: 358729917.6727 - mae: 13601.9971 - val_loss: 717288015.1273 - val_mae: 17511.7559\n",
            "Epoch 573/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 341832677.2364 - mae: 13352.3740 - val_loss: 730696201.3091 - val_mae: 17438.7090\n",
            "Epoch 574/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 353781828.0727 - mae: 13671.9531 - val_loss: 760188769.7455 - val_mae: 18580.5996\n",
            "Epoch 575/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 362026390.1091 - mae: 13766.7939 - val_loss: 734478185.8909 - val_mae: 17859.5137\n",
            "Epoch 576/1000\n",
            "880/880 [==============================] - 0s 40us/step - loss: 336478301.9636 - mae: 13121.8379 - val_loss: 816225108.9455 - val_mae: 20051.9902\n",
            "Epoch 577/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 350417644.8000 - mae: 13570.9463 - val_loss: 724439555.4909 - val_mae: 17683.7656\n",
            "Epoch 578/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 345458519.2727 - mae: 13501.6953 - val_loss: 739158643.2000 - val_mae: 17818.2734\n",
            "Epoch 579/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 356360721.4545 - mae: 13833.2988 - val_loss: 718243047.5636 - val_mae: 17358.0742\n",
            "Epoch 580/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 361150619.3455 - mae: 13882.3350 - val_loss: 803484765.0909 - val_mae: 19655.6484\n",
            "Epoch 581/1000\n",
            "880/880 [==============================] - 0s 43us/step - loss: 341989352.4364 - mae: 13595.2021 - val_loss: 733849444.0727 - val_mae: 18000.2598\n",
            "Epoch 582/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 374526539.0545 - mae: 14017.1035 - val_loss: 729550352.2909 - val_mae: 17199.2109\n",
            "Epoch 583/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 366976153.6000 - mae: 13763.7988 - val_loss: 772208489.8909 - val_mae: 18787.4824\n",
            "Epoch 584/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 383107545.0182 - mae: 14140.1953 - val_loss: 759283831.8545 - val_mae: 17987.7070\n",
            "Epoch 585/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 379484502.6909 - mae: 14220.8906 - val_loss: 830940212.3636 - val_mae: 20219.4590\n",
            "Epoch 586/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 399483326.8364 - mae: 14579.5762 - val_loss: 870393852.5091 - val_mae: 19562.8730\n",
            "Epoch 587/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 397594692.0727 - mae: 14707.3721 - val_loss: 799618293.5273 - val_mae: 19374.4219\n",
            "Epoch 588/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 348323819.6364 - mae: 13437.6377 - val_loss: 746767205.2364 - val_mae: 17507.6523\n",
            "Epoch 589/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 384470835.7818 - mae: 14177.0293 - val_loss: 802844450.9091 - val_mae: 19596.0449\n",
            "Epoch 590/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 390918978.3273 - mae: 14271.0332 - val_loss: 771563358.2545 - val_mae: 17838.9199\n",
            "Epoch 591/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 353714499.4909 - mae: 13466.4404 - val_loss: 724587415.2727 - val_mae: 17994.3965\n",
            "Epoch 592/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 362412144.8727 - mae: 13756.8330 - val_loss: 804594229.5273 - val_mae: 19624.6348\n",
            "Epoch 593/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 385811322.7636 - mae: 14393.3330 - val_loss: 715269187.4909 - val_mae: 17609.6230\n",
            "Epoch 594/1000\n",
            "880/880 [==============================] - 0s 42us/step - loss: 343931835.6364 - mae: 13573.6611 - val_loss: 747009141.5273 - val_mae: 18295.6465\n",
            "Epoch 595/1000\n",
            "880/880 [==============================] - 0s 44us/step - loss: 350039508.9455 - mae: 13676.7002 - val_loss: 776676518.4000 - val_mae: 18073.0879\n",
            "Epoch 596/1000\n",
            "880/880 [==============================] - 0s 47us/step - loss: 402042138.1818 - mae: 14730.0615 - val_loss: 831950953.8909 - val_mae: 20375.8906\n",
            "Epoch 597/1000\n",
            "880/880 [==============================] - 0s 44us/step - loss: 400816192.0000 - mae: 14678.3105 - val_loss: 829845800.7273 - val_mae: 18920.4238\n",
            "Epoch 598/1000\n",
            "880/880 [==============================] - 0s 39us/step - loss: 422198240.0000 - mae: 15005.9453 - val_loss: 967648836.6545 - val_mae: 22894.5039\n",
            "Epoch 599/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 399995361.7455 - mae: 14757.9844 - val_loss: 725393264.8727 - val_mae: 17365.6484\n",
            "Epoch 600/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 408596055.2727 - mae: 14418.8799 - val_loss: 1002324745.3091 - val_mae: 23704.6504\n",
            "Epoch 601/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 397338572.8000 - mae: 14620.6797 - val_loss: 736135732.3636 - val_mae: 17381.7285\n",
            "Epoch 602/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 364481546.4727 - mae: 13907.5625 - val_loss: 780992969.3091 - val_mae: 19038.8750\n",
            "Epoch 603/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 331295822.5455 - mae: 13107.2998 - val_loss: 725430908.5091 - val_mae: 17416.6660\n",
            "Epoch 604/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 329918752.5818 - mae: 13213.4746 - val_loss: 762232000.0000 - val_mae: 18643.2930\n",
            "Epoch 605/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 343107552.2909 - mae: 13500.7549 - val_loss: 743157562.1818 - val_mae: 18101.4141\n",
            "Epoch 606/1000\n",
            "880/880 [==============================] - 0s 37us/step - loss: 318199351.2727 - mae: 12782.8516 - val_loss: 706099152.2909 - val_mae: 17405.5176\n",
            "Epoch 607/1000\n",
            "880/880 [==============================] - 0s 37us/step - loss: 347031027.7818 - mae: 13530.5469 - val_loss: 785985448.7273 - val_mae: 19241.7637\n",
            "Epoch 608/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 327955753.3091 - mae: 13214.3809 - val_loss: 767052474.1818 - val_mae: 18160.5469\n",
            "Epoch 609/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 358292094.8364 - mae: 13818.4346 - val_loss: 788204708.0727 - val_mae: 19418.7930\n",
            "Epoch 610/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 372487750.4000 - mae: 14171.3428 - val_loss: 742042113.1636 - val_mae: 17637.5195\n",
            "Epoch 611/1000\n",
            "880/880 [==============================] - 0s 44us/step - loss: 404339588.0727 - mae: 14487.1904 - val_loss: 924328648.1455 - val_mae: 22130.0879\n",
            "Epoch 612/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 401647596.8000 - mae: 14678.9248 - val_loss: 714999545.0182 - val_mae: 17114.1133\n",
            "Epoch 613/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 354209234.6182 - mae: 13578.2275 - val_loss: 754675665.4545 - val_mae: 18684.6074\n",
            "Epoch 614/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 352555556.6545 - mae: 13727.7578 - val_loss: 730672544.5818 - val_mae: 17486.9395\n",
            "Epoch 615/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 349259414.6909 - mae: 13692.9434 - val_loss: 718733113.0182 - val_mae: 17199.8906\n",
            "Epoch 616/1000\n",
            "880/880 [==============================] - 0s 45us/step - loss: 320873781.5273 - mae: 13161.4102 - val_loss: 728286067.2000 - val_mae: 18073.4688\n",
            "Epoch 617/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 320423876.0727 - mae: 12981.5967 - val_loss: 750107700.3636 - val_mae: 18605.6230\n",
            "Epoch 618/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 320294188.2182 - mae: 12943.9941 - val_loss: 709745321.8909 - val_mae: 17378.7949\n",
            "Epoch 619/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 318501850.7636 - mae: 12983.9424 - val_loss: 703238516.3636 - val_mae: 17263.9844\n",
            "Epoch 620/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 307272699.3455 - mae: 12674.9590 - val_loss: 717095854.5455 - val_mae: 17529.4258\n",
            "Epoch 621/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 305846963.4909 - mae: 12547.6221 - val_loss: 716471354.1818 - val_mae: 17537.9531\n",
            "Epoch 622/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 334675943.5636 - mae: 13138.3027 - val_loss: 718011369.8909 - val_mae: 17183.5078\n",
            "Epoch 623/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 353348100.0727 - mae: 13620.0996 - val_loss: 725606765.3818 - val_mae: 17734.7520\n",
            "Epoch 624/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 335672301.9636 - mae: 13424.9727 - val_loss: 810948498.6182 - val_mae: 19784.0801\n",
            "Epoch 625/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 373860155.3455 - mae: 14132.2803 - val_loss: 709609065.8909 - val_mae: 17167.5547\n",
            "Epoch 626/1000\n",
            "880/880 [==============================] - 0s 37us/step - loss: 336813238.6909 - mae: 13453.7432 - val_loss: 709757715.7818 - val_mae: 17290.6309\n",
            "Epoch 627/1000\n",
            "880/880 [==============================] - 0s 44us/step - loss: 323447614.8364 - mae: 13163.4668 - val_loss: 843772016.8727 - val_mae: 20702.5000\n",
            "Epoch 628/1000\n",
            "880/880 [==============================] - 0s 45us/step - loss: 324007380.3636 - mae: 13162.0840 - val_loss: 715959603.2000 - val_mae: 17427.1250\n",
            "Epoch 629/1000\n",
            "880/880 [==============================] - 0s 43us/step - loss: 342515416.4364 - mae: 13421.6738 - val_loss: 739309670.4000 - val_mae: 17832.4883\n",
            "Epoch 630/1000\n",
            "880/880 [==============================] - 0s 47us/step - loss: 353989296.8727 - mae: 13752.3545 - val_loss: 731737374.2545 - val_mae: 17493.6309\n",
            "Epoch 631/1000\n",
            "880/880 [==============================] - 0s 45us/step - loss: 418383848.1455 - mae: 14532.0566 - val_loss: 808910292.9455 - val_mae: 19918.8320\n",
            "Epoch 632/1000\n",
            "880/880 [==============================] - 0s 41us/step - loss: 468464844.8000 - mae: 16172.9141 - val_loss: 804421564.5091 - val_mae: 18320.1836\n",
            "Epoch 633/1000\n",
            "880/880 [==============================] - 0s 41us/step - loss: 448799524.6545 - mae: 15619.7998 - val_loss: 698899661.9636 - val_mae: 17066.6758\n",
            "Epoch 634/1000\n",
            "880/880 [==============================] - 0s 48us/step - loss: 387128411.9273 - mae: 14369.0137 - val_loss: 711764186.7636 - val_mae: 17685.5938\n",
            "Epoch 635/1000\n",
            "880/880 [==============================] - 0s 42us/step - loss: 342417804.2182 - mae: 13517.2178 - val_loss: 721340969.8909 - val_mae: 17767.8047\n",
            "Epoch 636/1000\n",
            "880/880 [==============================] - 0s 43us/step - loss: 326432781.3818 - mae: 12912.1641 - val_loss: 709348218.1818 - val_mae: 17730.0957\n",
            "Epoch 637/1000\n",
            "880/880 [==============================] - 0s 42us/step - loss: 312416826.7636 - mae: 12871.4463 - val_loss: 715810151.5636 - val_mae: 17072.3789\n",
            "Epoch 638/1000\n",
            "880/880 [==============================] - 0s 44us/step - loss: 324800475.3455 - mae: 13092.2314 - val_loss: 741401125.2364 - val_mae: 18252.3535\n",
            "Epoch 639/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 320214726.4000 - mae: 12948.4004 - val_loss: 773745712.8727 - val_mae: 17869.6367\n",
            "Epoch 640/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 370563493.2364 - mae: 13928.4727 - val_loss: 928739629.3818 - val_mae: 22404.4629\n",
            "Epoch 641/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 362644761.6000 - mae: 14186.8955 - val_loss: 723652527.7091 - val_mae: 17028.4844\n",
            "Epoch 642/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 406935603.2000 - mae: 14942.3848 - val_loss: 921813897.3091 - val_mae: 21988.9883\n",
            "Epoch 643/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 360190804.3636 - mae: 13721.3652 - val_loss: 780716752.2909 - val_mae: 18262.9043\n",
            "Epoch 644/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 368101261.9636 - mae: 13961.4512 - val_loss: 919037869.3818 - val_mae: 22248.7168\n",
            "Epoch 645/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 396866490.1818 - mae: 14214.3496 - val_loss: 703919872.0000 - val_mae: 17226.4062\n",
            "Epoch 646/1000\n",
            "880/880 [==============================] - 0s 37us/step - loss: 318697829.8182 - mae: 12769.4941 - val_loss: 760733161.8909 - val_mae: 18838.6152\n",
            "Epoch 647/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 418918973.6727 - mae: 14602.0361 - val_loss: 741321296.2909 - val_mae: 17664.2480\n",
            "Epoch 648/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 346332798.2545 - mae: 13532.5859 - val_loss: 809178949.8182 - val_mae: 19857.3594\n",
            "Epoch 649/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 395964036.0727 - mae: 14696.4590 - val_loss: 736736271.1273 - val_mae: 17292.0176\n",
            "Epoch 650/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 396570066.6182 - mae: 14548.3936 - val_loss: 709911532.2182 - val_mae: 17714.2129\n",
            "Epoch 651/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 410899431.5636 - mae: 14929.1299 - val_loss: 792517471.4182 - val_mae: 19570.7949\n",
            "Epoch 652/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 396752431.7091 - mae: 14620.2529 - val_loss: 867204897.7455 - val_mae: 19718.7344\n",
            "Epoch 653/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 407036697.6000 - mae: 14964.8633 - val_loss: 910522100.3636 - val_mae: 21890.9180\n",
            "Epoch 654/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 395816765.0909 - mae: 14354.8877 - val_loss: 771638515.2000 - val_mae: 18025.6797\n",
            "Epoch 655/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 372283476.9455 - mae: 14117.1777 - val_loss: 696189237.5273 - val_mae: 16956.9824\n",
            "Epoch 656/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 317034508.2182 - mae: 12812.7666 - val_loss: 699669460.9455 - val_mae: 16946.8027\n",
            "Epoch 657/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 347295858.6182 - mae: 13771.1377 - val_loss: 706062486.1091 - val_mae: 17569.4512\n",
            "Epoch 658/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 311558899.2000 - mae: 12974.8096 - val_loss: 832292898.9091 - val_mae: 20522.4453\n",
            "Epoch 659/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 378065968.2909 - mae: 14207.3359 - val_loss: 777176556.2182 - val_mae: 18231.4062\n",
            "Epoch 660/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 408058043.9273 - mae: 15036.8662 - val_loss: 848488259.4909 - val_mae: 20829.0664\n",
            "Epoch 661/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 355235347.2000 - mae: 13793.7637 - val_loss: 698530123.6364 - val_mae: 17245.0391\n",
            "Epoch 662/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 329889648.8727 - mae: 13048.8135 - val_loss: 744788015.7091 - val_mae: 18537.1484\n",
            "Epoch 663/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 307916281.6000 - mae: 12759.9541 - val_loss: 754039861.5273 - val_mae: 18572.2793\n",
            "Epoch 664/1000\n",
            "880/880 [==============================] - 0s 41us/step - loss: 329028215.2727 - mae: 13299.6475 - val_loss: 715491614.2545 - val_mae: 17314.5840\n",
            "Epoch 665/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 300557327.1273 - mae: 12674.2842 - val_loss: 729329222.9818 - val_mae: 17961.5039\n",
            "Epoch 666/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 288634454.9818 - mae: 12416.1094 - val_loss: 716074324.9455 - val_mae: 17865.6523\n",
            "Epoch 667/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 324999024.2909 - mae: 13152.4707 - val_loss: 811060955.9273 - val_mae: 20039.5918\n",
            "Epoch 668/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 302999837.6727 - mae: 12521.0117 - val_loss: 703224549.2364 - val_mae: 17770.2188\n",
            "Epoch 669/1000\n",
            "880/880 [==============================] - 0s 42us/step - loss: 288544400.2909 - mae: 12256.1045 - val_loss: 733216394.4727 - val_mae: 18099.2852\n",
            "Epoch 670/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 306837386.4727 - mae: 12751.4258 - val_loss: 701222664.1455 - val_mae: 17184.2363\n",
            "Epoch 671/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 287918561.1636 - mae: 12276.6787 - val_loss: 714842817.1636 - val_mae: 17840.5234\n",
            "Epoch 672/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 284450884.6545 - mae: 12279.1045 - val_loss: 695681030.9818 - val_mae: 17256.3066\n",
            "Epoch 673/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 282450095.1273 - mae: 12171.1113 - val_loss: 698097370.7636 - val_mae: 17182.4668\n",
            "Epoch 674/1000\n",
            "880/880 [==============================] - 0s 38us/step - loss: 301335181.6727 - mae: 12646.9238 - val_loss: 813611301.2364 - val_mae: 20124.2246\n",
            "Epoch 675/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 321425709.9636 - mae: 13359.1797 - val_loss: 698676329.8909 - val_mae: 17154.7852\n",
            "Epoch 676/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 315589004.8000 - mae: 13089.4805 - val_loss: 743398504.7273 - val_mae: 18430.1934\n",
            "Epoch 677/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 301083290.7636 - mae: 12517.9297 - val_loss: 716765153.7455 - val_mae: 17902.8438\n",
            "Epoch 678/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 289571062.6909 - mae: 12362.9678 - val_loss: 705479930.1818 - val_mae: 17121.9941\n",
            "Epoch 679/1000\n",
            "880/880 [==============================] - 0s 45us/step - loss: 280271856.0000 - mae: 12061.0410 - val_loss: 697993321.8909 - val_mae: 17437.6445\n",
            "Epoch 680/1000\n",
            "880/880 [==============================] - 0s 42us/step - loss: 311921660.5091 - mae: 12901.0273 - val_loss: 742265233.4545 - val_mae: 18424.4902\n",
            "Epoch 681/1000\n",
            "880/880 [==============================] - 0s 41us/step - loss: 293882791.5636 - mae: 12596.5566 - val_loss: 712990638.5455 - val_mae: 17406.5391\n",
            "Epoch 682/1000\n",
            "880/880 [==============================] - 0s 42us/step - loss: 362659892.9455 - mae: 13967.9004 - val_loss: 696370630.9818 - val_mae: 17212.9805\n",
            "Epoch 683/1000\n",
            "880/880 [==============================] - 0s 43us/step - loss: 352159204.6545 - mae: 13910.7656 - val_loss: 689408866.9091 - val_mae: 16997.5723\n",
            "Epoch 684/1000\n",
            "880/880 [==============================] - 0s 37us/step - loss: 299821292.8000 - mae: 12613.8027 - val_loss: 805081283.4909 - val_mae: 19929.1953\n",
            "Epoch 685/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 302644616.1455 - mae: 12700.9307 - val_loss: 704499707.3455 - val_mae: 17386.1660\n",
            "Epoch 686/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 295185111.2727 - mae: 12567.5635 - val_loss: 691146235.3455 - val_mae: 17293.9883\n",
            "Epoch 687/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 283976614.9818 - mae: 12257.0391 - val_loss: 703759892.9455 - val_mae: 17818.0742\n",
            "Epoch 688/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 275961659.9273 - mae: 12192.2480 - val_loss: 717124247.2727 - val_mae: 18110.9707\n",
            "Epoch 689/1000\n",
            "880/880 [==============================] - 0s 38us/step - loss: 270454828.2182 - mae: 11920.7910 - val_loss: 705066274.9091 - val_mae: 17423.9805\n",
            "Epoch 690/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 297808816.8727 - mae: 12679.0850 - val_loss: 693397729.7455 - val_mae: 17742.6621\n",
            "Epoch 691/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 304409851.3455 - mae: 12863.0928 - val_loss: 709949022.2545 - val_mae: 17269.4961\n",
            "Epoch 692/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 310740638.2545 - mae: 12989.5234 - val_loss: 739667077.8182 - val_mae: 18574.1309\n",
            "Epoch 693/1000\n",
            "880/880 [==============================] - 0s 40us/step - loss: 276995268.0727 - mae: 11992.1660 - val_loss: 702550119.5636 - val_mae: 17124.3145\n",
            "Epoch 694/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 275065208.4364 - mae: 11935.9775 - val_loss: 707945091.4909 - val_mae: 17687.4746\n",
            "Epoch 695/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 273430801.7455 - mae: 12038.2861 - val_loss: 735302675.7818 - val_mae: 18303.3730\n",
            "Epoch 696/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 272553633.4545 - mae: 11876.7432 - val_loss: 690068206.5455 - val_mae: 17515.0254\n",
            "Epoch 697/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 262147496.1455 - mae: 11712.0918 - val_loss: 700998367.4182 - val_mae: 17549.3066\n",
            "Epoch 698/1000\n",
            "880/880 [==============================] - 0s 43us/step - loss: 267148427.6364 - mae: 11871.9385 - val_loss: 734983513.6000 - val_mae: 18391.6465\n",
            "Epoch 699/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 266856161.1636 - mae: 11969.1553 - val_loss: 709619513.0182 - val_mae: 17776.9219\n",
            "Epoch 700/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 261298962.0364 - mae: 11619.3311 - val_loss: 713973466.7636 - val_mae: 17713.0996\n",
            "Epoch 701/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 262320383.7091 - mae: 11798.4248 - val_loss: 697168683.0545 - val_mae: 17261.8770\n",
            "Epoch 702/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 261802027.0545 - mae: 11703.8867 - val_loss: 752771766.6909 - val_mae: 18944.3984\n",
            "Epoch 703/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 317730159.7091 - mae: 13224.7725 - val_loss: 753594407.5636 - val_mae: 18127.8906\n",
            "Epoch 704/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 313697541.8182 - mae: 13028.9492 - val_loss: 810743806.8364 - val_mae: 20139.0195\n",
            "Epoch 705/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 324402610.6182 - mae: 13212.1748 - val_loss: 707591969.7455 - val_mae: 17278.4961\n",
            "Epoch 706/1000\n",
            "880/880 [==============================] - 0s 31us/step - loss: 290956676.6545 - mae: 12560.6680 - val_loss: 799609503.4182 - val_mae: 19763.6895\n",
            "Epoch 707/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 341886705.4545 - mae: 13758.0928 - val_loss: 700039048.1455 - val_mae: 17343.2383\n",
            "Epoch 708/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 338986858.4727 - mae: 13827.6963 - val_loss: 695739892.3636 - val_mae: 17193.5547\n",
            "Epoch 709/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 299985787.9273 - mae: 12742.2373 - val_loss: 726493698.3273 - val_mae: 18208.0801\n",
            "Epoch 710/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 270980796.8000 - mae: 12036.4570 - val_loss: 709499442.0364 - val_mae: 17492.5801\n",
            "Epoch 711/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 276949857.7455 - mae: 12099.5566 - val_loss: 779500705.7455 - val_mae: 19253.1758\n",
            "Epoch 712/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 276659755.9273 - mae: 11982.5459 - val_loss: 700249779.2000 - val_mae: 17404.1777\n",
            "Epoch 713/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 273271451.0545 - mae: 12045.2793 - val_loss: 732301789.0909 - val_mae: 18435.6934\n",
            "Epoch 714/1000\n",
            "880/880 [==============================] - 0s 42us/step - loss: 278063487.4182 - mae: 12163.4521 - val_loss: 802645634.3273 - val_mae: 19936.7637\n",
            "Epoch 715/1000\n",
            "880/880 [==============================] - 0s 42us/step - loss: 280076922.7636 - mae: 12435.6250 - val_loss: 690824258.3273 - val_mae: 17310.6660\n",
            "Epoch 716/1000\n",
            "880/880 [==============================] - 0s 43us/step - loss: 265336977.1636 - mae: 11945.0684 - val_loss: 727734446.5455 - val_mae: 17990.5273\n",
            "Epoch 717/1000\n",
            "880/880 [==============================] - 0s 41us/step - loss: 257019861.5273 - mae: 11668.9248 - val_loss: 773356560.2909 - val_mae: 19195.1660\n",
            "Epoch 718/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 279050255.4182 - mae: 12203.2207 - val_loss: 697787634.0364 - val_mae: 17290.3281\n",
            "Epoch 719/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 289247273.8909 - mae: 12466.7246 - val_loss: 853086586.1818 - val_mae: 20814.8340\n",
            "Epoch 720/1000\n",
            "880/880 [==============================] - 0s 41us/step - loss: 277907798.6909 - mae: 12282.2617 - val_loss: 695567037.6727 - val_mae: 17297.5195\n",
            "Epoch 721/1000\n",
            "880/880 [==============================] - 0s 41us/step - loss: 255120084.6545 - mae: 11608.8223 - val_loss: 701251760.8727 - val_mae: 17203.3008\n",
            "Epoch 722/1000\n",
            "880/880 [==============================] - 0s 46us/step - loss: 257040148.3636 - mae: 11674.6133 - val_loss: 690564348.5091 - val_mae: 17165.5820\n",
            "Epoch 723/1000\n",
            "880/880 [==============================] - 0s 40us/step - loss: 259116433.7455 - mae: 11571.5430 - val_loss: 697346668.2182 - val_mae: 17385.6816\n",
            "Epoch 724/1000\n",
            "880/880 [==============================] - 0s 44us/step - loss: 259010534.4000 - mae: 11747.2090 - val_loss: 701986253.9636 - val_mae: 17350.1582\n",
            "Epoch 725/1000\n",
            "880/880 [==============================] - 0s 43us/step - loss: 271477396.9455 - mae: 12025.6338 - val_loss: 756831072.5818 - val_mae: 18882.5586\n",
            "Epoch 726/1000\n",
            "880/880 [==============================] - 0s 41us/step - loss: 271489911.2727 - mae: 12180.2129 - val_loss: 690747547.9273 - val_mae: 17051.0176\n",
            "Epoch 727/1000\n",
            "880/880 [==============================] - 0s 53us/step - loss: 246783650.9091 - mae: 11535.3154 - val_loss: 730325288.7273 - val_mae: 18254.0098\n",
            "Epoch 728/1000\n",
            "880/880 [==============================] - 0s 51us/step - loss: 247628795.0545 - mae: 11343.4727 - val_loss: 706641390.5455 - val_mae: 17520.6426\n",
            "Epoch 729/1000\n",
            "880/880 [==============================] - 0s 45us/step - loss: 251159315.2000 - mae: 11557.2246 - val_loss: 706917625.0182 - val_mae: 17581.2598\n",
            "Epoch 730/1000\n",
            "880/880 [==============================] - 0s 43us/step - loss: 241255736.4364 - mae: 11297.2686 - val_loss: 715886042.7636 - val_mae: 17556.9336\n",
            "Epoch 731/1000\n",
            "880/880 [==============================] - 0s 42us/step - loss: 323582165.5273 - mae: 13318.0752 - val_loss: 706296548.0727 - val_mae: 17990.6367\n",
            "Epoch 732/1000\n",
            "880/880 [==============================] - 0s 42us/step - loss: 334074535.5636 - mae: 13531.3213 - val_loss: 723210079.4182 - val_mae: 17923.2773\n",
            "Epoch 733/1000\n",
            "880/880 [==============================] - 0s 42us/step - loss: 325199550.2545 - mae: 13079.2754 - val_loss: 752249203.2000 - val_mae: 18492.1797\n",
            "Epoch 734/1000\n",
            "880/880 [==============================] - 0s 46us/step - loss: 297435840.5818 - mae: 12922.3584 - val_loss: 735692802.3273 - val_mae: 18342.0410\n",
            "Epoch 735/1000\n",
            "880/880 [==============================] - 0s 37us/step - loss: 313554405.8182 - mae: 13020.8457 - val_loss: 840919939.4909 - val_mae: 19057.0742\n",
            "Epoch 736/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 318201220.0727 - mae: 13405.1611 - val_loss: 749124257.7455 - val_mae: 18694.5723\n",
            "Epoch 737/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 289803579.0545 - mae: 12528.4473 - val_loss: 725152386.3273 - val_mae: 17513.9492\n",
            "Epoch 738/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 328799625.8909 - mae: 13162.9707 - val_loss: 694838095.1273 - val_mae: 17144.1914\n",
            "Epoch 739/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 310389638.9818 - mae: 12969.2217 - val_loss: 722132036.6545 - val_mae: 18252.1289\n",
            "Epoch 740/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 273507467.6364 - mae: 12164.7178 - val_loss: 716999991.8545 - val_mae: 17541.7754\n",
            "Epoch 741/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 253323449.6000 - mae: 11690.6230 - val_loss: 692683421.0909 - val_mae: 17301.2402\n",
            "Epoch 742/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 243596886.6909 - mae: 11265.8848 - val_loss: 736132697.6000 - val_mae: 18374.9570\n",
            "Epoch 743/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 275190964.3636 - mae: 12339.3721 - val_loss: 707129184.5818 - val_mae: 17448.8340\n",
            "Epoch 744/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 263969884.2182 - mae: 11893.3008 - val_loss: 709794164.3636 - val_mae: 17604.6973\n",
            "Epoch 745/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 239586261.8182 - mae: 11143.4033 - val_loss: 742192397.9636 - val_mae: 18506.4746\n",
            "Epoch 746/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 239861206.9818 - mae: 11441.9229 - val_loss: 704882316.8000 - val_mae: 17489.5000\n",
            "Epoch 747/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 260246102.4000 - mae: 11732.4980 - val_loss: 702684038.9818 - val_mae: 17809.5234\n",
            "Epoch 748/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 248274296.7273 - mae: 11477.1348 - val_loss: 691365130.4727 - val_mae: 17352.4824\n",
            "Epoch 749/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 242928486.6909 - mae: 11346.9863 - val_loss: 689945277.6727 - val_mae: 17419.9277\n",
            "Epoch 750/1000\n",
            "880/880 [==============================] - 0s 37us/step - loss: 243503559.8545 - mae: 11425.2100 - val_loss: 731437421.3818 - val_mae: 18290.1816\n",
            "Epoch 751/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 233317518.8364 - mae: 11024.8701 - val_loss: 694396740.6545 - val_mae: 17375.6113\n",
            "Epoch 752/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 228468769.4545 - mae: 10980.0850 - val_loss: 708602295.8545 - val_mae: 17709.5723\n",
            "Epoch 753/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 264428222.8364 - mae: 12120.6738 - val_loss: 701542132.3636 - val_mae: 17428.3379\n",
            "Epoch 754/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 238361553.4545 - mae: 11224.6650 - val_loss: 741001142.6909 - val_mae: 18438.2539\n",
            "Epoch 755/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 288713830.1091 - mae: 12610.3330 - val_loss: 705376740.0727 - val_mae: 17586.4570\n",
            "Epoch 756/1000\n",
            "880/880 [==============================] - 0s 41us/step - loss: 283659507.7818 - mae: 12465.5010 - val_loss: 684480584.1455 - val_mae: 17440.0840\n",
            "Epoch 757/1000\n",
            "880/880 [==============================] - 0s 44us/step - loss: 284570455.2727 - mae: 12265.4717 - val_loss: 697830494.2545 - val_mae: 17162.4883\n",
            "Epoch 758/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 351191858.6182 - mae: 14068.7217 - val_loss: 687782976.0000 - val_mae: 17052.8613\n",
            "Epoch 759/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 373294537.3091 - mae: 14333.9121 - val_loss: 956080124.5091 - val_mae: 22705.9121\n",
            "Epoch 760/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 398378124.5091 - mae: 14870.9111 - val_loss: 814447080.7273 - val_mae: 18397.8027\n",
            "Epoch 761/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 419977073.4545 - mae: 15307.7012 - val_loss: 845764469.5273 - val_mae: 20477.1973\n",
            "Epoch 762/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 327841099.0545 - mae: 13384.3213 - val_loss: 714457800.1455 - val_mae: 17012.2988\n",
            "Epoch 763/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 295857918.8364 - mae: 12712.3848 - val_loss: 831731649.1636 - val_mae: 19974.8281\n",
            "Epoch 764/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 254421424.2909 - mae: 11919.0557 - val_loss: 714893875.2000 - val_mae: 17569.7500\n",
            "Epoch 765/1000\n",
            "880/880 [==============================] - 0s 39us/step - loss: 267782508.8000 - mae: 12021.2021 - val_loss: 808445312.0000 - val_mae: 19840.3223\n",
            "Epoch 766/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 278462691.4909 - mae: 12317.3955 - val_loss: 707049105.4545 - val_mae: 16982.3223\n",
            "Epoch 767/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 272504672.5818 - mae: 12355.2305 - val_loss: 847379696.8727 - val_mae: 20712.7344\n",
            "Epoch 768/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 274998545.7455 - mae: 12234.9834 - val_loss: 704492044.8000 - val_mae: 17086.7344\n",
            "Epoch 769/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 259481007.1273 - mae: 11753.2773 - val_loss: 757140424.1455 - val_mae: 18943.1055\n",
            "Epoch 770/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 259212898.3273 - mae: 11713.8291 - val_loss: 701958917.8182 - val_mae: 17542.0879\n",
            "Epoch 771/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 254600528.8727 - mae: 11803.3389 - val_loss: 758495527.5636 - val_mae: 18849.3574\n",
            "Epoch 772/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 261894022.4000 - mae: 11910.7002 - val_loss: 691896143.1273 - val_mae: 17098.9199\n",
            "Epoch 773/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 280506786.3273 - mae: 12242.2363 - val_loss: 800087629.9636 - val_mae: 19614.0781\n",
            "Epoch 774/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 363598559.4182 - mae: 14262.5977 - val_loss: 710668740.6545 - val_mae: 17191.5156\n",
            "Epoch 775/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 253560584.7273 - mae: 11713.0654 - val_loss: 727018287.7091 - val_mae: 18222.5117\n",
            "Epoch 776/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 250675471.7091 - mae: 11552.7529 - val_loss: 703747873.7455 - val_mae: 17342.2402\n",
            "Epoch 777/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 260521437.6727 - mae: 11949.0332 - val_loss: 808358287.1273 - val_mae: 19864.0547\n",
            "Epoch 778/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 247398505.8909 - mae: 11453.8340 - val_loss: 700393444.0727 - val_mae: 17474.5195\n",
            "Epoch 779/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 228800311.2727 - mae: 11042.1270 - val_loss: 691496622.5455 - val_mae: 17506.9473\n",
            "Epoch 780/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 222236700.8000 - mae: 10783.2070 - val_loss: 764176786.6182 - val_mae: 18992.0430\n",
            "Epoch 781/1000\n",
            "880/880 [==============================] - 0s 41us/step - loss: 225553295.4182 - mae: 10926.5146 - val_loss: 694759057.4545 - val_mae: 17209.4785\n",
            "Epoch 782/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 226660692.3636 - mae: 10947.0205 - val_loss: 709444282.1818 - val_mae: 17792.3945\n",
            "Epoch 783/1000\n",
            "880/880 [==============================] - 0s 37us/step - loss: 217365718.4000 - mae: 10694.6387 - val_loss: 715140230.9818 - val_mae: 18027.8867\n",
            "Epoch 784/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 219735208.7273 - mae: 10779.6025 - val_loss: 703321845.5273 - val_mae: 17391.2832\n",
            "Epoch 785/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 236796126.8364 - mae: 11438.6855 - val_loss: 737842166.6909 - val_mae: 18340.6445\n",
            "Epoch 786/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 281688827.3455 - mae: 12474.7109 - val_loss: 709159582.2545 - val_mae: 17777.4082\n",
            "Epoch 787/1000\n",
            "880/880 [==============================] - 0s 44us/step - loss: 232804029.6727 - mae: 11111.4385 - val_loss: 714793580.2182 - val_mae: 17710.1523\n",
            "Epoch 788/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 233245102.5455 - mae: 11222.4004 - val_loss: 710525346.9091 - val_mae: 17934.1738\n",
            "Epoch 789/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 234491936.8727 - mae: 11282.7734 - val_loss: 701545417.3091 - val_mae: 17320.1719\n",
            "Epoch 790/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 222793639.5636 - mae: 10905.5625 - val_loss: 696052154.1818 - val_mae: 17423.5605\n",
            "Epoch 791/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 226643932.2182 - mae: 10841.8359 - val_loss: 756232673.7455 - val_mae: 18798.4727\n",
            "Epoch 792/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 219826562.3273 - mae: 10840.2861 - val_loss: 713018487.8545 - val_mae: 17925.0449\n",
            "Epoch 793/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 224664483.4909 - mae: 10964.8105 - val_loss: 766971718.9818 - val_mae: 19076.6074\n",
            "Epoch 794/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 229933772.8000 - mae: 10990.3408 - val_loss: 713194452.9455 - val_mae: 17457.1621\n",
            "Epoch 795/1000\n",
            "880/880 [==============================] - 0s 39us/step - loss: 256172184.1455 - mae: 12013.0615 - val_loss: 811206465.1636 - val_mae: 19990.0234\n",
            "Epoch 796/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 298216857.0182 - mae: 12892.5762 - val_loss: 701220539.3455 - val_mae: 17731.2617\n",
            "Epoch 797/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 270241279.4182 - mae: 12014.0117 - val_loss: 726780574.2545 - val_mae: 17956.9941\n",
            "Epoch 798/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 281138259.4909 - mae: 12143.2031 - val_loss: 739309490.0364 - val_mae: 18696.7461\n",
            "Epoch 799/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 229504667.6364 - mae: 10961.0684 - val_loss: 697214936.4364 - val_mae: 17346.3789\n",
            "Epoch 800/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 232978101.8182 - mae: 11343.2305 - val_loss: 739344468.9455 - val_mae: 18603.2656\n",
            "Epoch 801/1000\n",
            "880/880 [==============================] - 0s 31us/step - loss: 226108946.3273 - mae: 10828.8262 - val_loss: 766016968.1455 - val_mae: 18831.4180\n",
            "Epoch 802/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 234061932.2182 - mae: 11161.3672 - val_loss: 748529099.6364 - val_mae: 18595.2852\n",
            "Epoch 803/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 225140094.2545 - mae: 11090.0850 - val_loss: 715876139.0545 - val_mae: 17714.1367\n",
            "Epoch 804/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 213195765.5273 - mae: 10526.5566 - val_loss: 722474155.0545 - val_mae: 18146.3457\n",
            "Epoch 805/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 211435624.4364 - mae: 10518.4258 - val_loss: 723652917.5273 - val_mae: 18054.2734\n",
            "Epoch 806/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 220618874.4727 - mae: 10803.3760 - val_loss: 743047640.4364 - val_mae: 18458.7480\n",
            "Epoch 807/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 230989164.8000 - mae: 11199.9600 - val_loss: 721978843.9273 - val_mae: 17489.2324\n",
            "Epoch 808/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 251505038.5455 - mae: 11598.2930 - val_loss: 698519675.3455 - val_mae: 17459.8438\n",
            "Epoch 809/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 227018054.1091 - mae: 11165.6582 - val_loss: 707561107.7818 - val_mae: 17696.6406\n",
            "Epoch 810/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 209364612.0727 - mae: 10450.5293 - val_loss: 726728074.4727 - val_mae: 18172.3457\n",
            "Epoch 811/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 211872640.0000 - mae: 10615.9443 - val_loss: 747412388.0727 - val_mae: 18428.6855\n",
            "Epoch 812/1000\n",
            "880/880 [==============================] - 0s 39us/step - loss: 212597888.2909 - mae: 10639.4375 - val_loss: 790310503.5636 - val_mae: 19239.6914\n",
            "Epoch 813/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 227963172.6545 - mae: 11164.0547 - val_loss: 699634253.9636 - val_mae: 17436.3164\n",
            "Epoch 814/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 248137487.4182 - mae: 11750.4639 - val_loss: 696688310.6909 - val_mae: 17363.2441\n",
            "Epoch 815/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 220934921.6000 - mae: 10818.7070 - val_loss: 777678099.7818 - val_mae: 19117.5000\n",
            "Epoch 816/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 222985506.3273 - mae: 10970.4795 - val_loss: 723799097.0182 - val_mae: 17466.0273\n",
            "Epoch 817/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 279415360.2909 - mae: 12382.6260 - val_loss: 740243012.6545 - val_mae: 18264.9980\n",
            "Epoch 818/1000\n",
            "880/880 [==============================] - 0s 40us/step - loss: 246426830.5455 - mae: 11373.4707 - val_loss: 848709299.2000 - val_mae: 20507.8145\n",
            "Epoch 819/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 274245021.6727 - mae: 12149.9092 - val_loss: 707032079.1273 - val_mae: 17305.1289\n",
            "Epoch 820/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 259052191.4182 - mae: 11761.0498 - val_loss: 706573806.5455 - val_mae: 17480.0371\n",
            "Epoch 821/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 223955351.8545 - mae: 11106.9375 - val_loss: 716473428.9455 - val_mae: 17720.1680\n",
            "Epoch 822/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 222907010.0364 - mae: 10930.7979 - val_loss: 741708639.4182 - val_mae: 18121.6973\n",
            "Epoch 823/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 229679066.4727 - mae: 11063.6865 - val_loss: 786784750.5455 - val_mae: 19488.6719\n",
            "Epoch 824/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 224545576.1455 - mae: 11190.2861 - val_loss: 730390887.5636 - val_mae: 17612.9238\n",
            "Epoch 825/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 221453437.9636 - mae: 11062.3037 - val_loss: 712554493.6727 - val_mae: 17805.9336\n",
            "Epoch 826/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 202012541.6727 - mae: 10251.0254 - val_loss: 725759142.4000 - val_mae: 17980.5586\n",
            "Epoch 827/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 208448484.0727 - mae: 10564.5703 - val_loss: 716376132.6545 - val_mae: 17503.3164\n",
            "Epoch 828/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 251761616.8727 - mae: 11500.8584 - val_loss: 700676256.5818 - val_mae: 17458.2480\n",
            "Epoch 829/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 236353499.0545 - mae: 11337.0498 - val_loss: 735271314.6182 - val_mae: 18441.3320\n",
            "Epoch 830/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 214382475.9273 - mae: 10601.6152 - val_loss: 700232496.8727 - val_mae: 17684.7539\n",
            "Epoch 831/1000\n",
            "880/880 [==============================] - 0s 37us/step - loss: 201224166.9818 - mae: 10390.5254 - val_loss: 731882035.2000 - val_mae: 18205.7051\n",
            "Epoch 832/1000\n",
            "880/880 [==============================] - 0s 37us/step - loss: 212613534.8364 - mae: 10759.1416 - val_loss: 703183212.2182 - val_mae: 17518.5645\n",
            "Epoch 833/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 222641411.7818 - mae: 11081.9746 - val_loss: 836830942.2545 - val_mae: 20211.8242\n",
            "Epoch 834/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 214896281.3091 - mae: 10794.3721 - val_loss: 699944173.3818 - val_mae: 17513.9570\n",
            "Epoch 835/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 220169105.7455 - mae: 11007.1963 - val_loss: 793768370.0364 - val_mae: 19465.0430\n",
            "Epoch 836/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 214472064.0000 - mae: 10645.4443 - val_loss: 702970255.1273 - val_mae: 17667.9805\n",
            "Epoch 837/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 206751674.1818 - mae: 10493.5713 - val_loss: 724674081.7455 - val_mae: 18017.2188\n",
            "Epoch 838/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 228701561.8909 - mae: 11047.9141 - val_loss: 730628306.6182 - val_mae: 18148.5352\n",
            "Epoch 839/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 213303542.6909 - mae: 10682.4004 - val_loss: 739027870.2545 - val_mae: 18356.6426\n",
            "Epoch 840/1000\n",
            "880/880 [==============================] - 0s 37us/step - loss: 203584540.5091 - mae: 10437.4404 - val_loss: 713384356.0727 - val_mae: 17740.1914\n",
            "Epoch 841/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 282260986.7636 - mae: 12725.7773 - val_loss: 773922828.8000 - val_mae: 18097.9941\n",
            "Epoch 842/1000\n",
            "880/880 [==============================] - 0s 41us/step - loss: 331215502.2545 - mae: 13867.4092 - val_loss: 755904406.1091 - val_mae: 18971.5840\n",
            "Epoch 843/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 242272642.9091 - mae: 11528.8115 - val_loss: 708205188.6545 - val_mae: 17769.6152\n",
            "Epoch 844/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 219565328.8727 - mae: 10817.4980 - val_loss: 745614985.3091 - val_mae: 17775.1191\n",
            "Epoch 845/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 302755357.0909 - mae: 13105.6182 - val_loss: 933428948.9455 - val_mae: 21784.2051\n",
            "Epoch 846/1000\n",
            "880/880 [==============================] - 0s 37us/step - loss: 311013399.8545 - mae: 12849.8799 - val_loss: 713800077.9636 - val_mae: 17756.2656\n",
            "Epoch 847/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 258777788.5091 - mae: 11800.8916 - val_loss: 751214973.6727 - val_mae: 17673.1953\n",
            "Epoch 848/1000\n",
            "880/880 [==============================] - 0s 38us/step - loss: 273190705.7455 - mae: 12355.5605 - val_loss: 852157756.5091 - val_mae: 20200.2363\n",
            "Epoch 849/1000\n",
            "880/880 [==============================] - 0s 40us/step - loss: 293741267.7818 - mae: 12421.7891 - val_loss: 717382326.6909 - val_mae: 17409.1816\n",
            "Epoch 850/1000\n",
            "880/880 [==============================] - 0s 37us/step - loss: 268109621.5273 - mae: 12061.7100 - val_loss: 700357490.0364 - val_mae: 17253.0449\n",
            "Epoch 851/1000\n",
            "880/880 [==============================] - 0s 38us/step - loss: 255776752.0000 - mae: 11531.9580 - val_loss: 807448640.0000 - val_mae: 19391.2539\n",
            "Epoch 852/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 240001898.7636 - mae: 11503.6865 - val_loss: 710473725.6727 - val_mae: 17628.0508\n",
            "Epoch 853/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 214895450.7636 - mae: 10649.4971 - val_loss: 726525327.1273 - val_mae: 17942.1973\n",
            "Epoch 854/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 204223982.8364 - mae: 10448.8984 - val_loss: 754874374.9818 - val_mae: 17817.5820\n",
            "Epoch 855/1000\n",
            "880/880 [==============================] - 0s 42us/step - loss: 237951570.0364 - mae: 11402.5146 - val_loss: 749510010.1818 - val_mae: 18313.6504\n",
            "Epoch 856/1000\n",
            "880/880 [==============================] - 0s 39us/step - loss: 197311746.0364 - mae: 10364.0957 - val_loss: 733947566.5455 - val_mae: 18397.3730\n",
            "Epoch 857/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 189130328.4364 - mae: 9968.3818 - val_loss: 744426321.4545 - val_mae: 18342.9102\n",
            "Epoch 858/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 194043545.0182 - mae: 10082.7891 - val_loss: 716770558.8364 - val_mae: 17914.7656\n",
            "Epoch 859/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 192806338.9091 - mae: 10102.1670 - val_loss: 713652143.7091 - val_mae: 17379.0605\n",
            "Epoch 860/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 221594433.1636 - mae: 10768.1377 - val_loss: 711528375.8545 - val_mae: 17684.8516\n",
            "Epoch 861/1000\n",
            "880/880 [==============================] - 0s 40us/step - loss: 186518070.1091 - mae: 9946.8887 - val_loss: 778714398.2545 - val_mae: 19089.9902\n",
            "Epoch 862/1000\n",
            "880/880 [==============================] - 0s 39us/step - loss: 220062308.3636 - mae: 10830.9473 - val_loss: 703554876.5091 - val_mae: 17537.7773\n",
            "Epoch 863/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 202492401.4545 - mae: 10520.9502 - val_loss: 707737476.6545 - val_mae: 17357.6797\n",
            "Epoch 864/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 232660685.6727 - mae: 11325.0947 - val_loss: 793714160.8727 - val_mae: 19210.7676\n",
            "Epoch 865/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 303690282.4727 - mae: 13278.0117 - val_loss: 771133248.0000 - val_mae: 18434.8066\n",
            "Epoch 866/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 273923757.6727 - mae: 12107.8779 - val_loss: 731274434.3273 - val_mae: 17883.2715\n",
            "Epoch 867/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 264128586.7636 - mae: 12145.3125 - val_loss: 741133632.0000 - val_mae: 18631.5586\n",
            "Epoch 868/1000\n",
            "880/880 [==============================] - 0s 37us/step - loss: 209534521.8909 - mae: 10599.8027 - val_loss: 710174932.9455 - val_mae: 17498.3164\n",
            "Epoch 869/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 197523021.6727 - mae: 10119.7246 - val_loss: 727524853.5273 - val_mae: 17936.6523\n",
            "Epoch 870/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 228460991.1273 - mae: 11378.0684 - val_loss: 827757878.6909 - val_mae: 20211.3281\n",
            "Epoch 871/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 223615637.5273 - mae: 10992.4570 - val_loss: 704682103.8545 - val_mae: 17403.1230\n",
            "Epoch 872/1000\n",
            "880/880 [==============================] - 0s 41us/step - loss: 201338199.2727 - mae: 10468.8555 - val_loss: 713826445.9636 - val_mae: 17557.7969\n",
            "Epoch 873/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 188220045.0909 - mae: 9952.9170 - val_loss: 717710804.9455 - val_mae: 17652.5234\n",
            "Epoch 874/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 187696000.0000 - mae: 9968.9971 - val_loss: 725766297.6000 - val_mae: 17893.6699\n",
            "Epoch 875/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 178786898.6182 - mae: 9694.6133 - val_loss: 714154992.8727 - val_mae: 17612.4629\n",
            "Epoch 876/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 180864778.1818 - mae: 9597.9434 - val_loss: 713366074.1818 - val_mae: 17853.0996\n",
            "Epoch 877/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 208835890.3273 - mae: 10660.6152 - val_loss: 715914105.0182 - val_mae: 17432.2441\n",
            "Epoch 878/1000\n",
            "880/880 [==============================] - 0s 39us/step - loss: 204902494.8364 - mae: 10503.3271 - val_loss: 748172311.2727 - val_mae: 18595.3613\n",
            "Epoch 879/1000\n",
            "880/880 [==============================] - 0s 40us/step - loss: 211269572.0727 - mae: 10687.5898 - val_loss: 740714240.0000 - val_mae: 18273.5312\n",
            "Epoch 880/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 189599793.4545 - mae: 10058.2412 - val_loss: 720454706.0364 - val_mae: 17698.0312\n",
            "Epoch 881/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 184023815.2727 - mae: 9854.6738 - val_loss: 732003635.2000 - val_mae: 17953.0957\n",
            "Epoch 882/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 187586730.4727 - mae: 10086.0068 - val_loss: 736563300.0727 - val_mae: 18371.2812\n",
            "Epoch 883/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 177717801.4545 - mae: 9631.4492 - val_loss: 738022038.1091 - val_mae: 18200.5879\n",
            "Epoch 884/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 177274003.7818 - mae: 9638.7129 - val_loss: 724642970.7636 - val_mae: 17478.0117\n",
            "Epoch 885/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 175575180.5091 - mae: 9568.8496 - val_loss: 730843507.2000 - val_mae: 18215.9961\n",
            "Epoch 886/1000\n",
            "880/880 [==============================] - 0s 41us/step - loss: 175280829.9636 - mae: 9537.1084 - val_loss: 754806743.2727 - val_mae: 18583.5605\n",
            "Epoch 887/1000\n",
            "880/880 [==============================] - 0s 45us/step - loss: 180705750.4000 - mae: 9910.3730 - val_loss: 747573473.7455 - val_mae: 18585.3555\n",
            "Epoch 888/1000\n",
            "880/880 [==============================] - 0s 41us/step - loss: 236838166.1091 - mae: 11557.4600 - val_loss: 726578490.1818 - val_mae: 17972.1680\n",
            "Epoch 889/1000\n",
            "880/880 [==============================] - 0s 41us/step - loss: 202204756.9455 - mae: 10429.7451 - val_loss: 731095264.5818 - val_mae: 17622.4004\n",
            "Epoch 890/1000\n",
            "880/880 [==============================] - 0s 38us/step - loss: 194625210.7636 - mae: 10217.6064 - val_loss: 716717755.3455 - val_mae: 17964.7754\n",
            "Epoch 891/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 174957017.6000 - mae: 9609.0703 - val_loss: 780678823.5636 - val_mae: 19472.3457\n",
            "Epoch 892/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 187597030.9818 - mae: 10052.8545 - val_loss: 782168589.9636 - val_mae: 19194.7266\n",
            "Epoch 893/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 211780155.9273 - mae: 10778.6846 - val_loss: 770733821.6727 - val_mae: 18227.6719\n",
            "Epoch 894/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 223456436.6545 - mae: 11187.5117 - val_loss: 730594549.5273 - val_mae: 17924.1191\n",
            "Epoch 895/1000\n",
            "880/880 [==============================] - 0s 31us/step - loss: 197894754.3273 - mae: 10223.6826 - val_loss: 730558322.0364 - val_mae: 17772.4980\n",
            "Epoch 896/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 266118634.4727 - mae: 12099.0908 - val_loss: 838556392.7273 - val_mae: 20296.7480\n",
            "Epoch 897/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 256981497.6000 - mae: 12198.4873 - val_loss: 770546142.2545 - val_mae: 19018.8984\n",
            "Epoch 898/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 236844360.4364 - mae: 11306.5137 - val_loss: 751524875.6364 - val_mae: 18519.3379\n",
            "Epoch 899/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 226024484.3636 - mae: 10958.5127 - val_loss: 808021419.0545 - val_mae: 19653.3887\n",
            "Epoch 900/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 189534505.8909 - mae: 10044.9648 - val_loss: 809407654.4000 - val_mae: 19689.0977\n",
            "Epoch 901/1000\n",
            "880/880 [==============================] - 0s 31us/step - loss: 269469497.6000 - mae: 12435.3398 - val_loss: 715045395.7818 - val_mae: 17573.0039\n",
            "Epoch 902/1000\n",
            "880/880 [==============================] - 0s 37us/step - loss: 213135696.5818 - mae: 10981.3350 - val_loss: 716430341.8182 - val_mae: 17665.6719\n",
            "Epoch 903/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 184621328.0000 - mae: 9861.1523 - val_loss: 723544872.7273 - val_mae: 18122.6895\n",
            "Epoch 904/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 176720656.5818 - mae: 9667.2100 - val_loss: 737997613.3818 - val_mae: 18159.3945\n",
            "Epoch 905/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 190144242.6182 - mae: 10141.6064 - val_loss: 708496060.5091 - val_mae: 17725.9883\n",
            "Epoch 906/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 217343796.9455 - mae: 11042.7705 - val_loss: 833318993.4545 - val_mae: 20426.9883\n",
            "Epoch 907/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 251144409.0182 - mae: 11934.8096 - val_loss: 918587119.7091 - val_mae: 21551.8770\n",
            "Epoch 908/1000\n",
            "880/880 [==============================] - 0s 39us/step - loss: 359305928.4364 - mae: 14519.8613 - val_loss: 894199808.0000 - val_mae: 19619.0684\n",
            "Epoch 909/1000\n",
            "880/880 [==============================] - 0s 41us/step - loss: 430467554.9091 - mae: 15165.3193 - val_loss: 773691831.8545 - val_mae: 18822.5312\n",
            "Epoch 910/1000\n",
            "880/880 [==============================] - 0s 32us/step - loss: 349862746.7636 - mae: 13062.3555 - val_loss: 885311090.0364 - val_mae: 20891.9316\n",
            "Epoch 911/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 318216437.5273 - mae: 12850.2041 - val_loss: 726831511.2727 - val_mae: 17453.9023\n",
            "Epoch 912/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 294292439.5636 - mae: 12476.9189 - val_loss: 750118827.0545 - val_mae: 18746.9336\n",
            "Epoch 913/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 210298770.0364 - mae: 10533.7559 - val_loss: 790786278.4000 - val_mae: 19146.4453\n",
            "Epoch 914/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 207216073.0182 - mae: 10447.2803 - val_loss: 707201239.2727 - val_mae: 17373.6309\n",
            "Epoch 915/1000\n",
            "880/880 [==============================] - 0s 42us/step - loss: 228880573.0909 - mae: 10956.1670 - val_loss: 721374931.7818 - val_mae: 17569.4180\n",
            "Epoch 916/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 206956918.1091 - mae: 10623.5322 - val_loss: 771410415.7091 - val_mae: 18795.3848\n",
            "Epoch 917/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 189521577.8909 - mae: 10039.0566 - val_loss: 718307244.2182 - val_mae: 17525.7871\n",
            "Epoch 918/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 192316420.9455 - mae: 10185.7178 - val_loss: 707584475.9273 - val_mae: 17542.2832\n",
            "Epoch 919/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 173182928.5818 - mae: 9468.1191 - val_loss: 744563210.4727 - val_mae: 18099.1543\n",
            "Epoch 920/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 172010736.2909 - mae: 9430.7031 - val_loss: 750057403.3455 - val_mae: 18385.3633\n",
            "Epoch 921/1000\n",
            "880/880 [==============================] - 0s 46us/step - loss: 171627313.4545 - mae: 9527.8643 - val_loss: 727612805.8182 - val_mae: 17936.2168\n",
            "Epoch 922/1000\n",
            "880/880 [==============================] - 0s 44us/step - loss: 177827551.4182 - mae: 9758.2227 - val_loss: 735894447.7091 - val_mae: 18196.3457\n",
            "Epoch 923/1000\n",
            "880/880 [==============================] - 0s 44us/step - loss: 179950573.0909 - mae: 9858.9502 - val_loss: 738643751.5636 - val_mae: 18346.7793\n",
            "Epoch 924/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 236116784.5818 - mae: 11504.0293 - val_loss: 826410331.9273 - val_mae: 19469.7305\n",
            "Epoch 925/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 362995119.1273 - mae: 14902.9727 - val_loss: 977034373.8182 - val_mae: 23313.1191\n",
            "Epoch 926/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 260097361.4545 - mae: 12397.8125 - val_loss: 801869220.0727 - val_mae: 18712.5293\n",
            "Epoch 927/1000\n",
            "880/880 [==============================] - 0s 37us/step - loss: 350517821.6727 - mae: 14112.4561 - val_loss: 806923163.9273 - val_mae: 20084.7598\n",
            "Epoch 928/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 355209212.5091 - mae: 14269.1387 - val_loss: 714660889.6000 - val_mae: 17672.9531\n",
            "Epoch 929/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 268583219.4909 - mae: 12025.8828 - val_loss: 971949083.9273 - val_mae: 23138.1816\n",
            "Epoch 930/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 269047973.8182 - mae: 12286.0654 - val_loss: 690001296.2909 - val_mae: 17608.8809\n",
            "Epoch 931/1000\n",
            "880/880 [==============================] - 0s 40us/step - loss: 196455185.7455 - mae: 10152.8906 - val_loss: 715770048.0000 - val_mae: 17659.5879\n",
            "Epoch 932/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 186672365.6727 - mae: 9940.0000 - val_loss: 722275607.2727 - val_mae: 17821.3496\n",
            "Epoch 933/1000\n",
            "880/880 [==============================] - 0s 37us/step - loss: 177184594.0364 - mae: 9599.4844 - val_loss: 715467322.1818 - val_mae: 17818.2949\n",
            "Epoch 934/1000\n",
            "880/880 [==============================] - 0s 38us/step - loss: 168938069.5273 - mae: 9276.8945 - val_loss: 707735986.0364 - val_mae: 17712.0508\n",
            "Epoch 935/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 167969489.4545 - mae: 9428.5059 - val_loss: 742379532.8000 - val_mae: 18535.5293\n",
            "Epoch 936/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 177063227.6364 - mae: 9617.7725 - val_loss: 739429965.9636 - val_mae: 17782.9414\n",
            "Epoch 937/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 200792138.4727 - mae: 10771.8447 - val_loss: 820849684.9455 - val_mae: 20050.1445\n",
            "Epoch 938/1000\n",
            "880/880 [==============================] - 0s 42us/step - loss: 199114812.2182 - mae: 10428.0029 - val_loss: 740258539.0545 - val_mae: 17843.8613\n",
            "Epoch 939/1000\n",
            "880/880 [==============================] - 0s 38us/step - loss: 224750109.9636 - mae: 11001.5918 - val_loss: 945219698.0364 - val_mae: 22214.8086\n",
            "Epoch 940/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 237699439.7091 - mae: 11492.5566 - val_loss: 718378909.0909 - val_mae: 17808.4336\n",
            "Epoch 941/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 208723426.6182 - mae: 10767.4795 - val_loss: 743850058.4727 - val_mae: 18478.4160\n",
            "Epoch 942/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 216899220.3636 - mae: 10914.5957 - val_loss: 741275266.3273 - val_mae: 18600.5273\n",
            "Epoch 943/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 232812068.3636 - mae: 11332.5723 - val_loss: 733332301.9636 - val_mae: 17473.1797\n",
            "Epoch 944/1000\n",
            "880/880 [==============================] - 0s 41us/step - loss: 227498759.8545 - mae: 10807.2227 - val_loss: 775312555.0545 - val_mae: 18988.5762\n",
            "Epoch 945/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 214989470.8364 - mae: 10581.2617 - val_loss: 737193252.0727 - val_mae: 17821.5840\n",
            "Epoch 946/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 193272043.9273 - mae: 10051.3975 - val_loss: 724001145.0182 - val_mae: 18169.6113\n",
            "Epoch 947/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 192270340.9455 - mae: 10215.4941 - val_loss: 815610340.0727 - val_mae: 19689.0234\n",
            "Epoch 948/1000\n",
            "880/880 [==============================] - 0s 37us/step - loss: 211933737.3091 - mae: 10569.7227 - val_loss: 691732745.3091 - val_mae: 17639.6934\n",
            "Epoch 949/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 249672269.0909 - mae: 11845.5332 - val_loss: 696274621.6727 - val_mae: 17359.0645\n",
            "Epoch 950/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 183228483.0545 - mae: 9812.4775 - val_loss: 739934317.3818 - val_mae: 18470.4824\n",
            "Epoch 951/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 171613110.9818 - mae: 9529.4346 - val_loss: 717702716.5091 - val_mae: 17453.4824\n",
            "Epoch 952/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 179748710.4000 - mae: 9831.0723 - val_loss: 742433729.1636 - val_mae: 18475.9648\n",
            "Epoch 953/1000\n",
            "880/880 [==============================] - 0s 37us/step - loss: 187772524.2182 - mae: 9985.0391 - val_loss: 824724601.0182 - val_mae: 20148.5410\n",
            "Epoch 954/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 182237943.5636 - mae: 9968.4629 - val_loss: 716443462.9818 - val_mae: 17509.9551\n",
            "Epoch 955/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 181320580.0727 - mae: 9977.3730 - val_loss: 768822688.5818 - val_mae: 18820.8320\n",
            "Epoch 956/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 177855004.9455 - mae: 9852.5713 - val_loss: 727252925.6727 - val_mae: 17831.5371\n",
            "Epoch 957/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 189238465.7455 - mae: 10181.9404 - val_loss: 776377475.4909 - val_mae: 19342.8906\n",
            "Epoch 958/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 223148617.8909 - mae: 11094.0391 - val_loss: 713549272.4364 - val_mae: 17453.2949\n",
            "Epoch 959/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 247379792.8727 - mae: 11623.4150 - val_loss: 806630227.7818 - val_mae: 18309.9355\n",
            "Epoch 960/1000\n",
            "880/880 [==============================] - 0s 37us/step - loss: 257991696.8727 - mae: 12168.4717 - val_loss: 909034109.6727 - val_mae: 21348.7832\n",
            "Epoch 961/1000\n",
            "880/880 [==============================] - 0s 38us/step - loss: 229412734.5455 - mae: 11465.4521 - val_loss: 766610087.5636 - val_mae: 17823.4941\n",
            "Epoch 962/1000\n",
            "880/880 [==============================] - 0s 40us/step - loss: 236281977.7455 - mae: 11469.3457 - val_loss: 829546732.2182 - val_mae: 20295.5234\n",
            "Epoch 963/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 217410408.7273 - mae: 11026.5635 - val_loss: 732594800.8727 - val_mae: 17479.9180\n",
            "Epoch 964/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 222584333.6727 - mae: 10972.7705 - val_loss: 810704847.1273 - val_mae: 19696.0391\n",
            "Epoch 965/1000\n",
            "880/880 [==============================] - 0s 42us/step - loss: 194658807.5636 - mae: 10175.6182 - val_loss: 713307815.5636 - val_mae: 17564.4121\n",
            "Epoch 966/1000\n",
            "880/880 [==============================] - 0s 42us/step - loss: 192821590.1091 - mae: 10253.5742 - val_loss: 696804447.4182 - val_mae: 17473.5059\n",
            "Epoch 967/1000\n",
            "880/880 [==============================] - 0s 42us/step - loss: 189678594.0364 - mae: 10118.4873 - val_loss: 720476953.6000 - val_mae: 17440.7676\n",
            "Epoch 968/1000\n",
            "880/880 [==============================] - 0s 53us/step - loss: 214067825.1636 - mae: 10820.8223 - val_loss: 713823405.3818 - val_mae: 18041.7637\n",
            "Epoch 969/1000\n",
            "880/880 [==============================] - 0s 45us/step - loss: 177750464.8727 - mae: 9765.9873 - val_loss: 803265743.1273 - val_mae: 20021.5371\n",
            "Epoch 970/1000\n",
            "880/880 [==============================] - 0s 44us/step - loss: 174102348.2182 - mae: 9661.9395 - val_loss: 696505475.4909 - val_mae: 17880.9688\n",
            "Epoch 971/1000\n",
            "880/880 [==============================] - 0s 44us/step - loss: 170964706.6182 - mae: 9785.2910 - val_loss: 732255557.8182 - val_mae: 17862.9434\n",
            "Epoch 972/1000\n",
            "880/880 [==============================] - 0s 43us/step - loss: 172010696.1455 - mae: 9685.4639 - val_loss: 721201744.2909 - val_mae: 17995.7930\n",
            "Epoch 973/1000\n",
            "880/880 [==============================] - 0s 42us/step - loss: 162789702.6909 - mae: 9185.8789 - val_loss: 805480744.7273 - val_mae: 19641.0039\n",
            "Epoch 974/1000\n",
            "880/880 [==============================] - 0s 44us/step - loss: 171075314.0364 - mae: 9731.9297 - val_loss: 756588839.5636 - val_mae: 17938.8750\n",
            "Epoch 975/1000\n",
            "880/880 [==============================] - 0s 42us/step - loss: 212176043.6364 - mae: 10803.1338 - val_loss: 729635973.8182 - val_mae: 18122.9551\n",
            "Epoch 976/1000\n",
            "880/880 [==============================] - 0s 43us/step - loss: 166497296.8727 - mae: 9445.3965 - val_loss: 793694050.9091 - val_mae: 19441.3750\n",
            "Epoch 977/1000\n",
            "880/880 [==============================] - 0s 43us/step - loss: 184511369.0182 - mae: 10005.2178 - val_loss: 724478327.8545 - val_mae: 17680.2305\n",
            "Epoch 978/1000\n",
            "880/880 [==============================] - 0s 38us/step - loss: 190678668.2182 - mae: 10415.3867 - val_loss: 713316864.0000 - val_mae: 17408.9824\n",
            "Epoch 979/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 180199694.2545 - mae: 9830.6387 - val_loss: 776076820.9455 - val_mae: 19158.1973\n",
            "Epoch 980/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 181453037.9636 - mae: 9817.6504 - val_loss: 717038299.9273 - val_mae: 17730.0273\n",
            "Epoch 981/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 162654046.2545 - mae: 9338.6436 - val_loss: 758988914.0364 - val_mae: 18860.2402\n",
            "Epoch 982/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 153343014.4000 - mae: 8981.4707 - val_loss: 754193362.6182 - val_mae: 18652.6309\n",
            "Epoch 983/1000\n",
            "880/880 [==============================] - 0s 39us/step - loss: 154097817.6000 - mae: 8946.6035 - val_loss: 728512485.2364 - val_mae: 18024.2188\n",
            "Epoch 984/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 156970638.5455 - mae: 9061.1572 - val_loss: 742147266.3273 - val_mae: 18430.2031\n",
            "Epoch 985/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 155919906.6182 - mae: 9113.5166 - val_loss: 753591882.4727 - val_mae: 18683.3945\n",
            "Epoch 986/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 160902070.9818 - mae: 9266.9395 - val_loss: 726819440.8727 - val_mae: 17719.0020\n",
            "Epoch 987/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 155742000.0000 - mae: 9117.5371 - val_loss: 711550503.5636 - val_mae: 17826.2363\n",
            "Epoch 988/1000\n",
            "880/880 [==============================] - 0s 41us/step - loss: 157179470.2545 - mae: 9130.2549 - val_loss: 733710818.9091 - val_mae: 18212.6230\n",
            "Epoch 989/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 148537092.5091 - mae: 8792.7451 - val_loss: 734755702.6909 - val_mae: 18293.6895\n",
            "Epoch 990/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 167106095.1273 - mae: 9500.5371 - val_loss: 783891319.8545 - val_mae: 19270.2344\n",
            "Epoch 991/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 175183538.3273 - mae: 10033.5996 - val_loss: 708763585.1636 - val_mae: 17383.7051\n",
            "Epoch 992/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 210559294.2545 - mae: 10920.6162 - val_loss: 729059563.0545 - val_mae: 17672.4766\n",
            "Epoch 993/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 227951371.6364 - mae: 11216.2373 - val_loss: 841756008.7273 - val_mae: 20224.5684\n",
            "Epoch 994/1000\n",
            "880/880 [==============================] - 0s 36us/step - loss: 258098309.2364 - mae: 12100.8428 - val_loss: 833675144.1455 - val_mae: 20452.4453\n",
            "Epoch 995/1000\n",
            "880/880 [==============================] - 0s 35us/step - loss: 224486396.8000 - mae: 11183.9092 - val_loss: 757416651.6364 - val_mae: 18586.6211\n",
            "Epoch 996/1000\n",
            "880/880 [==============================] - 0s 43us/step - loss: 215826431.1273 - mae: 10801.5498 - val_loss: 787998786.3273 - val_mae: 19328.1270\n",
            "Epoch 997/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 193873189.5273 - mae: 10126.4209 - val_loss: 694437402.7636 - val_mae: 17690.5820\n",
            "Epoch 998/1000\n",
            "880/880 [==============================] - 0s 34us/step - loss: 182010179.7818 - mae: 9950.7549 - val_loss: 840487958.1091 - val_mae: 20479.6016\n",
            "Epoch 999/1000\n",
            "880/880 [==============================] - 0s 33us/step - loss: 185492967.1273 - mae: 10102.7656 - val_loss: 704393213.6727 - val_mae: 17742.8145\n",
            "Epoch 1000/1000\n",
            "880/880 [==============================] - 0s 37us/step - loss: 205381596.8000 - mae: 10616.1680 - val_loss: 694682492.5091 - val_mae: 17465.4570\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TUFBn7BBUjb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "outputId": "01bad65c-61a5-4471-f100-82be8b273a47"
      },
      "source": [
        "h=hist.history\n",
        "plt.plot(h['val_loss'],label=\"validation loss\")\n",
        "plt.plot(h['loss'],label=\"Training loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAERCAYAAAB2CKBkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZxU5Z33/c+vqvcFaJpma0AwEtlElhYxRMU1uCY6GjVm1GhidDK3RpNJNHmiJjO57+S5fYzBmMyQRU1iXEZHownRuGDQxKhgAGVRUFGatdl6obdafs8f53TTdDfQNBRNc77v16teXXXqLNepA/Wt67rOuY65OyIiEl2xni6AiIj0LAWBiEjEKQhERCJOQSAiEnEKAhGRiFMQiIhEXK8MAjP7lZltMrO3uzDvSWb2ppklzeyidu9daWYrw8eVmSuxiMihq1cGAXA/MKuL834EXAX8ru1EM+sP3A4cD0wDbjezkgNXRBGR3qFXBoG7zwe2tp1mZh8zs2fMbKGZvWxmY8J5V7v7EiDdbjWfAp5z963uvg14jq6Hi4jIYSOrpwtwAM0BrnP3lWZ2PPBT4NQ9zF8OrGnzujKcJiISKYdFEJhZEfAJ4L/NrGVybs+VSESk9zgsgoCgiWu7u0/ah2XWAjPbvB4GvHQAyyQi0iv0yj6C9ty9BvjAzC4GsMCxe1nsWeBMMysJO4nPDKeJiERKrwwCM3sIeBU42swqzewa4HLgGjNbDCwFPh3Oe5yZVQIXA/9lZksB3H0r8O/AG+Hje+E0EZFIMQ1DLSISbb2yRiAiIgdOr+ssHjBggI8cObKniyEi0qssXLhws7uXdfZerwuCkSNHsmDBgp4uhohIr2JmH+7uPTUNiYhEnIJARCTiFAQiIhHX6/oIROTgSyQSVFZW0tjY2NNFkb3Iy8tj2LBhZGdnd3kZBYGI7FVlZSXFxcWMHDmSNuN5ySHG3dmyZQuVlZWMGjWqy8tlvGnIzOJm9g8z+0Mn7+Wa2SNmtsrMXjOzkZkuj4jsu8bGRkpLSxUChzgzo7S0dJ9rbgejj+BGYPlu3rsG2ObuRwE/An54EMojIt2gEOgdunOcMhoEZjYMOAf4xW5m+TTwQPj8MeA0y9S/to3L4IV/hx2bM7J6EZHeKtM1gruBb9Dx7mAtWm8O4+5JoBoobT+TmV1rZgvMbEFVVVX3SrJlJbx8J9Ru6N7yItKrFBUVAbBu3TouuuiiTueZOXPmXi9Qvfvuu6mvr299ffbZZ7N9+/b9Lt8dd9zBnXfeud/rORAyFgRmdi6wyd0X7u+63H2Ou1e4e0VZWadXSO9dTmHwt3nH/hZHRHqRoUOH8thjj3V7+fZBMHfuXPr163cginbIyGSNYAZwvpmtBh4GTjWz37abZy0wHMDMsoC+wJaMlCanOPjbXJeR1YtI5txyyy3ce++9ra9bfk3X1dVx2mmnMWXKFI455hh+//vfd1h29erVTJgwAYCGhgYuvfRSxo4dywUXXEBDQ0PrfNdffz0VFRWMHz+e22+/HYDZs2ezbt06TjnlFE455RQgGOZm8+agifmuu+5iwoQJTJgwgbvvvrt1e2PHjuVLX/oS48eP58wzz9xlO51ZtGgR06dPZ+LEiVxwwQVs27atdfvjxo1j4sSJXHrppQD85S9/YdKkSUyaNInJkydTW1vbrc+0rYydPurutwK3ApjZTODr7v75drM9BVxJcG+Bi4AXPVPjYrfWCBQEIvvju08vZdm6mgO6znFD+3D7eeN3+/4ll1zCV7/6Vb7yla8A8Oijj/Lss8+Sl5fHE088QZ8+fdi8eTPTp0/n/PPP322H6c9+9jMKCgpYvnw5S5YsYcqUKa3vff/736d///6kUilOO+00lixZwg033MBdd93FvHnzGDBgwC7rWrhwIffddx+vvfYa7s7xxx/PySefTElJCStXruShhx7i5z//OZ/97Gd5/PHH+fzn23/97XTFFVdwzz33cPLJJ3Pbbbfx3e9+l7vvvpsf/OAHfPDBB+Tm5rY2R915553ce++9zJgxg7q6OvLy8rr8Oe/OQb+y2My+Z2bnhy9/CZSa2SrgZuCWjG1YTUMivdbkyZPZtGkT69atY/HixZSUlDB8+HDcnW9961tMnDiR008/nbVr17Jx48bdrmf+/PmtX8gTJ05k4sSJre89+uijTJkyhcmTJ7N06VKWLVu2xzK98sorXHDBBRQWFlJUVMSFF17Iyy+/DMCoUaOYNCm4c+7UqVNZvXr1btdTXV3N9u3bOfnkkwG48sormT9/fmsZL7/8cn7729+SlRX8bp8xYwY333wzs2fPZvv27a3T98dBuaDM3V8ivB+wu9/WZnojwZ3DMi8n6DhSEIjsnz39cs+kiy++mMcee4wNGzZwySWXAPDggw9SVVXFwoULyc7OZuTIkd26+vmDDz7gzjvv5I033qCkpISrrrpqv66izs3NbX0ej8f32jS0O3/84x+ZP38+Tz/9NN///vd56623uOWWWzjnnHOYO3cuM2bM4Nlnn2XMmDHdLitEaayhnILgr5qGRHqlSy65hIcffpjHHnuMiy8Ofj9WV1czcOBAsrOzmTdvHh9+uNuRlgE46aST+N3vfgfA22+/zZIlSwCoqamhsLCQvn37snHjRv70pz+1LlNcXNxpO/yJJ57Ik08+SX19PTt27OCJJ57gxBNP3Of96tu3LyUlJa21id/85jecfPLJpNNp1qxZwymnnMIPf/hDqqurqaur47333uOYY47hm9/8JscddxwrVqzY5222F50hJmLhuBvpZM+WQ0S6Zfz48dTW1lJeXs6QIUMAuPzyyznvvPM45phjqKio2Osv4+uvv54vfOELjB07lrFjxzJ16lQAjj32WCZPnsyYMWMYPnw4M2bMaF3m2muvZdasWQwdOpR58+a1Tp8yZQpXXXUV06ZNA+CLX/wikydP3mMz0O488MADXHfdddTX13PkkUdy3333kUql+PznP091dTXuzg033EC/fv34zne+w7x584jFYowfP56zzjprn7fXXq+7Z3FFRYV368Y06RR8rz/M/BbM/OaBL5jIYWz58uWMHTu2p4shXdTZ8TKzhe5e0dn80WkasnBXfXfXtomIRFOEgsAAA0/1dElERA4p0QkCgFg8aCISEZFW0QoCi6tGICLSTsSCIKY+AhGRdqIVBLE4pBUEIiJtRSsI1DQk0itt2bKldaC1wYMHU15e3vq6ubl5j8suWLCAG264Ya/b+MQnPnFAyvrSSy9x7rnnHpB1HSzRuaAMgjOH1DQk0uuUlpayaNEiIBh5tKioiK9//eut7yeTyd2OuVNRUUFFRaenz+/ib3/724EpbC8UrRqBzhoSOWxcddVVXHfddRx//PF84xvf4PXXX+eEE05g8uTJfOITn+Cdd94Bdv2Ffscdd3D11Vczc+ZMjjzySGbPnt26vpYb2bz00kvMnDmTiy66iDFjxnD55ZfTcuHt3LlzGTNmDFOnTuWGG27Y6y//rVu38pnPfIaJEycyffr01iEtOhtKev369Zx00klMmjSJCRMmtA45cTBErEagpiGR/fanW2DDWwd2nYOPgbN+sM+LVVZW8re//Y14PE5NTQ0vv/wyWVlZPP/883zrW9/i8ccf77DMihUrmDdvHrW1tRx99NFcf/31ZGdn7zLPP/7xD5YuXcrQoUOZMWMGf/3rX6moqODLX/4y8+fPZ9SoUVx22WV7Ld/tt9/O5MmTefLJJ3nxxRe54oorWLRoUadDSc+ZM4dPfepTfPvb3yaVSu1yM5xMi1gQ6KwhkcPJxRdfTDweB4IB6K688kpWrlyJmZFIJDpd5pxzziE3N5fc3FwGDhzIxo0bGTZs2C7zTJs2rXXapEmTWL16NUVFRRx55JGMGjUKgMsuu4w5c+bssXyvvPJKaxideuqpbNmyhZqamtahpC+//HIuvPBChg0bxnHHHcfVV19NIpHgM5/5TOsw1gdDtIJAZw2J7L9u/HLPlMLCwtbn3/nOdzjllFN44oknWL16NTNnzux0mfZDRCeTHQei7Mo8+6OzoaRPOukk5s+fzx//+Eeuuuoqbr75Zq644ooDut3diVYfgZqGRA5b1dXVlJeXA3D//fcf8PUfffTRvP/++62jiz7yyCN7XebEE0/kwQcfBIK+hwEDBtCnT59Oh5L+8MMPGTRoEF/60pf44he/yJtvvnnA92F3Mnnz+jwze93MFpvZUjP7bifzXGVmVWa2KHx8MVPlASCmpiGRw9U3vvENbr31ViZPnnzAf8ED5Ofn89Of/pRZs2YxdepUiouL6du37x6XueOOO1i4cCETJ07klltu4YEHHgDg7rvvZsKECUycOJHs7GzOOussXnrppdbhsB955BFuvPHGA74Pu5OxYagtuGloobvXmVk28Apwo7v/vc08VwEV7v6vXV1vt4ehBpg9GYZOgYt+2b3lRSJKw1AH6urqKCoqwt35yle+wujRo7npppt6ulgdHDLDUHug5XZg2eGjx25+8MLyjXy4rYm6xqaeKoKI9HI///nPmTRpEuPHj6e6upovf/nLPV2kAyKjncVmFgcWAkcB97r7a53M9k9mdhLwLnCTu6/pZD3XAtcCjBgxoltlSaTSNKUgnVLTkIh0z0033XRI1gD2V0Y7i9095e6TgGHANDOb0G6Wp4GR7j4ReA54YDfrmePuFe5eUVZW1q2yZMdjpImR1q0qRbqlt93NMKq6c5wOyllD7r4dmAfMajd9i7u3tNX8ApiaqTLkZAVB4LqyWGSf5eXlsWXLFoXBIc7d2bJlC3l5efu0XMaahsysDEi4+3YzywfOAH7Ybp4h7r4+fHk+sDxT5cmOx0hhuK4jENlnw4YNo7Kykqqqqp4uiuxFXl5ehwvk9iaTfQRDgAfCfoIY8Ki7/8HMvgcscPengBvM7HwgCWwFrspUYVQjEOm+7Ozs1itq5fCTsSBw9yXA5E6m39bm+a3ArZkqQ1s58RgJBYGISAeRubI4JytGihiuC8pERHYRmSAIzhoy0FlDIiK7iEwQ7OwjUI1ARKStyARBdtxIeQzXoHMiIruITBDkxuNh05CCQESkrcgEQXaW4eiexSIi7UUmCOKxliDQlZEiIm1FJgiMMAh6bgBUEZFDUmSCIGZhBCgHRER2EZkgMFONQESkM5EJgqBGoD4CEZH2IhMEQY0AVCMQEdlVZIIgEHQZi4jITpEKAjUNiYh0FKkgwNRZLCLSXqSCQBEgItJRxoLAzPLM7HUzW2xmS83su53Mk2tmj5jZKjN7zcxGZqo84RbVNCQi0k4mawRNwKnufiwwCZhlZtPbzXMNsM3djwJ+RLt7Gh9ors5iEZEOMhYEHqgLX2aHj/bfwp8GHgifPwacZmaWqTKpj0BEpKOM9hGYWdzMFgGbgOfc/bV2s5QDawDcPQlUA6WdrOdaM1tgZguqqqr2r1BqGhIR2UVGg8DdU+4+CRgGTDOzCd1czxx3r3D3irKysu6XR01DIiIdHJSzhtx9OzAPmNXurbXAcAAzywL6AlsyVxJ1FouItJfJs4bKzKxf+DwfOANY0W62p4Arw+cXAS+6Z+6b2jPY/SAi0ltlZXDdQ4AHzCxOEDiPuvsfzOx7wAJ3fwr4JfAbM1sFbAUuzWB5QKOPioh0kLEgcPclwOROpt/W5nkjcHGmytAZ9RGIiOwqWlcWm/oIRETai1QQqGlIRKSjyAWBmoZERHYVqSAIhqHu6VKIiBxaIhUEmGoEIiLtRSsI1EcgItJBxIIAFAQiIruKVBC4GabTR0VEdhGpIAiahkREpK0IBoFqBCIibUUrCHTWkIhIB5EKAgcNMSEi0k6kggBiqhGIiLQTqSBw9RWLiHQQqSAwjTUkItJBpILAdatKEZEOMnmryuFmNs/MlpnZUjO7sZN5ZppZtZktCh+3dbauA1go1QhERNrJ5K0qk8DX3P1NMysGFprZc+6+rN18L7v7uRksRxu6jkBEpL2M1Qjcfb27vxk+rwWWA+WZ2l6XmOnaYhGRdg5KH4GZjSS4f/Frnbx9gpktNrM/mdn43Sx/rZktMLMFVVVV3S6Hq0YgItJBxoPAzIqAx4GvuntNu7ffBI5w92OBe4AnO1uHu89x9wp3rygrK9uPsqBB50RE2sloEJhZNkEIPOju/9P+fXevcfe68PlcINvMBmSqPE4M1QhERHaVybOGDPglsNzd79rNPIPD+TCzaWF5tmSqTKDxR0VE2svkWUMzgH8G3jKzReG0bwEjANz9P4GLgOvNLAk0AJe6Z7DtxtRHICLSXsaCwN1fYS8/wN39J8BPMlWGjnQdgYhIe5G6slhBICLSUbSCwNRDICLSXuSCQKePiojsKlpBoAvKREQ6iFQQOBpiQkSkvUgFAYY6i0VE2olUEJiahkREOohUELjuRyAi0kGkgsB0+qiISAeRCgLXBWUiIh1EKgjAiCkIRER2EakgcJ08KiLSQZeCwMxuNLM+Fvilmb1pZmdmunAHXhgEurpYRKRVV2sEV4d3FzsTKCEYXvoHGStVppiCQESkva4GQUubytnAb9x9Kb36Hi8KAhGRFl0NgoVm9meCIHjWzIqB9J4WMLPhZjbPzJaZ2VIzu7GTeczMZpvZKjNbYmZT9n0X9oGFu6sagYhIq67emOYaYBLwvrvXm1l/4At7WSYJfM3d3wyDY6GZPefuy9rMcxYwOnwcD/ws/JthCgIRkRZdrRGcALzj7tvN7PPA/wNU72kBd1/v7m+Gz2uB5UB5u9k+DfzaA38H+pnZkH3ag32hPgIRkQ66GgQ/A+rN7Fjga8B7wK+7uhEzGwlMBl5r91Y5sKbN60o6hgVmdq2ZLTCzBVVVVV3dbAc7Tx9VEIiItOhqECTDm8p/GviJu98LFHdlQTMrAh4HvhqeebTP3H2Ou1e4e0VZWVl3VtFSmpYV7sc6REQOL13tI6g1s1sJThs90cxiQPbeFjKzbIIQeNDd/6eTWdYCw9u8HhZOywg31QhERNrrao3gEqCJ4HqCDQRf2P93TwtYMMLbL4Hl7n7XbmZ7CrgiPHtoOlDt7uu7WKbuU41ARKRVl2oE7r7BzB4EjjOzc4HX3X1vfQQzCGoQb5nZonDat4AR4Tr/E5hLcErqKqCevZ+JtJ9UIxARaa9LQWBmnyWoAbxE8G16j5n9m7s/trtl3P0V9nLRWdjv8JUul3a/qY9ARKS9rvYRfBs4zt03AZhZGfA8sNsgOCS1nj66x2vhREQipat9BLGWEAht2YdlDx3qLBYR6aCrNYJnzOxZ4KHw9SUE7fu9jJqGRETa62pn8b+Z2T8RdAADzHH3JzJXrMzwlrGGVCMQEWnV1RoB7v44wTUBvZ9qBCIirfYYBGZWS+c/n43gpJ8+GSlVpljv69YQEcm0PQaBu3dpGInewtVHICLSQUR/IisIRERaRCoIUrGc4EmyqWcLIiJyCIlUEDTH8sMnO3q2ICIih5BIBUFTrCB40lzXswURETmERCoIdtYIFAQiIi0iFQRNcTUNiYi0F6kgSLQ2DSkIRERaRCwI8sIn9T1bEBGRQ0ikgiDdcmWxhqEWEWmVsSAws1+Z2SYze3s37880s2ozWxQ+bstUWdpsNfijIBARadXlQee64X7gJ8Cebmn5srufm8Ey7CqmGoGISHsZqxG4+3xga6bW3z0tQaAhJkREWvR0H8EJZrbYzP5kZuN3N5OZXWtmC8xsQVVVVfe31tJHkE51fx0iIoeZngyCN4Ej3P1Y4B7gyd3N6O5z3L3C3SvKysq6vUFXZ7GISAc9FgTuXuPudeHzuUC2mQ3I6DYtHj5REIiItOixIDCzwWbB3eTNbFpYli0Z3mjwV0EgItIqY2cNmdlDwExggJlVArcD2QDu/p/ARcD1ZpYEGoBL3TPci6umIRGRDjIWBO5+2V7e/wnB6aUHjes6AhGRDnr6rKGDSzUCEZEOIhoEuo5ARKRFRINANQIRkRbRCgL1EYiIdBCpILBYjDSmIBARaSNSQQCEQaAhJkREWkQqCMzAXTUCEZG2ohUEGCliCgIRkTaiFQQGaQWBiMguIhUEEF5drOsIRERaRSoIDHTWkIhIO9EKAjUNiYh0ELEgsLBpSEEgItIiWkGAmoZERNqLVBCgpiERkQ4iFQSGqUYgItJOxoLAzH5lZpvM7O3dvG9mNtvMVpnZEjObkqmy7Nxm2DSU1hATIiItMlkjuB+YtYf3zwJGh49rgZ9lsCxASx9BTNcRiIi0kbEgcPf5wNY9zPJp4Nce+DvQz8yGZKo8LdQ0JCKyq57sIygH1rR5XRlO68DMrjWzBWa2oKqqqtsb1HUEIiId9YrOYnef4+4V7l5RVlbW7fWos1hEpKOeDIK1wPA2r4eF0zJGw1CLiHTUk0HwFHBFePbQdKDa3ddncoO6oExEpKOsTK3YzB4CZgIDzKwSuB3IBnD3/wTmAmcDq4B64AuZKkubQqmPQESknYwFgbtftpf3HfhKprbfmZYagXu65Tb2IiKR1ys6iw+U1gvKVCMQEWkVrSAgbBpKJ3u6KCIih4xoBYFBA7mQaOjpooiIHDIiFQQA9Z4LzTt6uhgiIoeMSAWBAfXkKQhERNqIVhAY7EA1AhGRtiIWBEaD50KivqeLIiJyyIhUEEDYNKQgEBFpFakgMIN6crFEPaR1LYGICEQtCLDgrCFQrUBEJBStILCwaQjUYSwiEopWEECbGoGCQEQEIhYEADtUIxAR2UWkgqB1iAmAZvURiIhA1IIAY4e31AjqerYwIiKHiGgFQdsagc4aEhEBMhwEZjbLzN4xs1Vmdksn719lZlVmtih8fDGT5QH1EYiItJfJW1XGgXuBM4BK4A0ze8rdl7Wb9RF3/9dMlaNdmXaeNaQgEBEBMlsjmAascvf33b0ZeBj4dAa3t1eGmoZERNrLZBCUA2vavK4Mp7X3T2a2xMweM7Phna3IzK41swVmtqCqqqrbBdIFZSIiHfV0Z/HTwEh3nwg8BzzQ2UzuPsfdK9y9oqysrNsbC25eH6PRsxUEIiKhTAbBWqDtL/xh4bRW7r7F3ZvCl78ApmawPDQkgoHmdpCn00dFREKZDII3gNFmNsrMcoBLgafazmBmQ9q8PB9YnsHycERpAQDrvBS2vp/JTYmI9BoZO2vI3ZNm9q/As0Ac+JW7LzWz7wEL3P0p4AYzOx9IAluBqzJVHoCzJgymvF8+7zYeyTEbFmdyUyIivUbGggDA3ecCc9tNu63N81uBWzNZhrbMjNPHDmT1P8qh/kVo2Ab5JQdr8yIih6Se7iw+6PJy4ryTGhy8WL+kZwsjInIIiFwQDCzO4+XEWNLZRbDkkZ4ujohIj4tcEJw7cQgN5PFww3Gklz4BjTU9XSQRkR4VuSAY1CePQX1yeSh1GrFEPfzjtz1dJBGRHhW5IAD46zdPZXOfcSxkLMlX74VUsqeLJCLSYyIZBFnxGI9cewK/SJ1DVk0lLH9q7wuJiBymIhkEACNKCxhxwoV8kB5E/V9+DO49XSQRkR4R2SAA+JdTPs5D8fMoqFpEzbuvHPTtp9PO/X/9gLomNU2JSM+JdBD0zc9m1KnXsM2L2PKn/w3pYCyiZ5duoHJb5oepfundTdzx9DL+7zMrMr6tnvbBZg3yJ3KoyuiVxb3BZSeO4+GFn+PS7XN4/sdfomrSv/DbP79KnDRTTjiNJZXbufqTo3CHjw8qJi87xkdb6ykpyOGHz6zgo631fPKoAfQryOaqT4zi8TcrOaqsiFFlhdzzwkqG9svnuFH9mfnxMsyMbzy2mOElBfyv00azdUcCgAde/ZBhJQVc88lRvL56K+X98hnePxgXqbYxQX1zikF98va4H5tqGxlYvHOemsYE9/91Nded/DFysno273/x8vv8xx+X8+iXT2DaqP49WhYR6ci8l7WNV1RU+IIFCw7oOusaE7z6/32WMxIv7jJ9eXoETWSRIIt1PoCtXkwuzTSQRx92sMYHcmzsPdZ7f5LE2ej9+VhsHdNjy3gi9Uk2eT+GWRW/S51GjRdQXFRMzo61pImR7n8Um7ds5u7se3nHhzM7eSFN5ABOFilmjh1KbnacPy5ZD8CRZYVMGtaPjw0s4uE3PqKhOc13zh1LKu3Mmf8+KzbUMmZwMecdOxR3584/vwvAhPI+fGZSOVW1TZwzcQgNzSmeWbqBm8/4OIvXVFO5rZ412+oZ2i+fz00bQW1TkrysOAAfbd3BUQOLaUykyMuOd+mzbEykyM2KYWa4O2bGyFv+CMD/ufAYLps2gpZ/c2Z2IA6fiHSBmS1094pO31MQhNzZvnweqXVLqK/6ALZ/RKy5Dk81k5VuJrt+I8XUk5VuJkaqdbE0Rox9/ww3U8IAtu0yrdIH0JcdGM5SH8lH6YHkWxOTY6v4e3os272Yjd6PGbGl1JPLsvQRbKUPCeIcaRsYYltYlj6C5T6CbV7MFfE/844Pp4583k8PYbUPpoFczou/yj/SR7HChzOYbYywTbzhR1Ocn0tWw2a20JeCnDj1zal2pXYG9ckjlXbAKC/Jp6E5Sd/8bLbXJziyrJBnl27k1DED+dy0EXzx1ws4cfQAXl65GXC+MGMUn59+BP/8i9dYV93IF2aM5PbzxreuvTGRYnNdE8NKCvb58zyQahsTzH93M+dMHLL3mUV6CQXBgeQOTTUQy4LGasgpgmQjYLD9IygZCTs2wfrFUFAKVe9AsgHiuVBdCWsXQOFAKOgPRYNg1IlQsz44hXXTcigoxRu3Y1vfh7y+wTYAj+eAp7H0getYThInKwy1hMfZljWAgamNbKeYpGVTnK7l+fRkpseWs92LyLcmqr2IdV7Kuz6MbV5ERexdYqRZkD6aJHHWeSkbvYRaChhsWxlrH5FHM9dlPc3s5IWcEFvKCh/B6+kxvJw+htK+fWhIpBhRWsjiNdsBOH3sQDbVNrGkspqxQ/qQEze+dfZYnly0lqcWreO288bx2YrgVhd1TUl+99pH3P+31fzuS9Mp75fPqk113PzoIv7rn6cypG8+OVkxFn64je31zRTlZjH7xZV8c9YYJg7rB8CqTXXUNCaYMiIYgPBfHlzI3Lc28PzNJ3PUwCIAfvPqasqK85g1YXDr55dKO2l3suO7Nk1zgDgAABFYSURBVL29vbaat9ZWc9m0Ea3T0mnnpy+t4tOTylub/UQOJgVBb5dohOy84G9zXRBGWbmwowoSDZBbBJ4O3rcYbFgS/I1nQ1Y+FA6ANa/D5ncgKy9YJpYFOYWwbTVsWgblU4P7OC9/GkZ/CqqWQ3N9sN3tH2Vs16rig1liH2ecr2JJ81AcY0H646z3Ulb7YIw0/5F9H19qvpkaChlo2yigiS2Fo0mm0zTX12I4O8gHICceozmVbl3/sJJ8hvTN443VO2tfI209q30w/QtzGdQnj+Xrg2FGvn32WIb3L+C63y4E4MgBhdxy1hh+9PzK1nnuOG8cRXnZ7GhKcvtTSwG4esYoZh5dRjKd5u7nV7KkMgjv5d+bRX5O0KQ2+4WV3PXcu5xydBmXHDeCU8aUkZsVp7ohQTKVJisW4+111RwzrC998rI7fE71zUly4jFiZrywYhNTjyihT14Wf3m3imseWMAZ4wbx8ysqWLqummfeDpr+WpreNtc10dCcon9hDoW5WTzz9gau++1CTh87iJ98bjLPL98IwLghfYjHjCNKC2lKpsjNiu/SLJhMpcmKd+xvakykgrLFjFTaqW1MsLmuiaMGFrfOU9uYIJFy+hfmdFj+rcpqvvbfi7j9vPEMKMqlvCSfguw4KXeyYtahCbGlbG25O4mU8+7GWiaU922dvqm2kbzsOH3ysqltTPDdp5dx6piBnDFuUIcAT6WduqaghtuZHU1J6pqSFOVmsaMpyf+eu5wRpYXcdPro1jLe9Mginl+2kZljBnLPZZN5avE63vxwG3ecP771s6yuT5CbHeOeF1cya/wQJpT3Ie3B9rPjHfd32boa+hfmkEyn96u2rCCQAyOdhlQTZOdD/dbgkWwMQiXZCHWbgvk2LYWmOuhbDv2OgDWvwVGnw6s/gT7lULs+uFVoqjkImW7cJGhTznBeyprBZ+sfBmAxo5mbqKA2bwg3JO9jsG3jzz6N5fGjeb7haP49+1cA3JecxY9zfsrPkufxw+RlreuLkSYdnkSXRZJL4/N4NlVBFUEtYbRVcnJsMb9KndU6X1cU5ARfQhtqGjHSeLhsTlaMvvnZVNU2dbrc8aP6k0w7yVSa5pS3BlFXDe6Tx5ghxWyobmTFhtrW6UcNLGLVpj3fna8lTIf3z2fN1gZGlhZQmJvFe1V1fPKoAeRmx6ltTJITN3Y0pXj1/S0A5GbFaEruDOETRw9g1aY6po3qz+8XrQPgjHGDiBkU5GTR0JyiIZHiL+/u+T7kx4/qT2lRDjuads47tG8effKzGdG/gFTaeWHFptb5C3LiTCjvS352vHX+QX1y2Viz62d91MAiinKzeGttNam0t5b/9LGDqGlIkPLgizmVdlZsqKW2MaiN52TFGNG/YJfPcXj/fApzsnb5rMcO6dN63LJiRjL8ok+kdv3Obf/jBWBkaQF987N5d2MdDYmdTbQ/v6KCM8YN2uPntTs9FgRmNgv4McGNaX7h7j9o934u8GuCW1RuAS5x99V7WqeC4DCUTgdBYhY0oa35O2xfA9VrwsDZDH2GBs+3fwjbPgxqNXUboRv9My08txgnTjqnkKzatVSXn0R1/ggK6j5iwIb5NOeU8OGICyhO11C2+mni6Sa2FH6MFUUnkFMylPI1f6DBs0hnF/OqjyftRmFunPG1rzCuaQn/PeRrrCw+nkQ6xsTal7hg40+YX3Amj8TOpv/Acuo9h7dWvkdjyvjkpHE8t2QNDSm4qO8KFhd+ktzcXEinqWl2loVfKOX98jl+WA7LNyVYvqmeiyeW8Opb77LJ+zGgbzHptFNfu5WBAwfRlExRVdtEYyINOGdmv8X2wiN4PzmQuroaUsQppIGPDe5HbbOxcmszMZw+BXlsq09QlJtFXVOS4rwsmhJpmlNpCnPimBlZcaMpkaYwN4vNdZ2HWYvh/fPZviNBbVOSPnlZNCRSxGNGYyJNeb98qmqbyEvVkCCLBjqeHZcTj1GQGyeZ8tZrbkoKsvlYWRHVDQl2NCVZV93YOv+AolwKcuJsq29u/fI+sqyQmoYEm+uaW+erOKKE2sYk72yspbxfPmu3NwBBQORmxehXkE0i6STSabJjMarqmqhtTNInP4vmZJopg3N4aflaaigiO26MG9qXotw4Cz/cRmMizYj+BXy0NTgN/djh/VqbPlvEwxpUZ04bM5CUOy+9U0VpYQ5bdgTl/urpo/nq6R/f4+e9Oz0SBGYWB94FzgAqCW5deZm7L2szz78AE939OjO7FLjA3S/Z03oVBNIqnYbG7ZDXD9IJ2Pxu0N/SbwTk9wuCoupdqP5oZ3AkGuDErwd9MusXQzoJtRuCprTaDZDYAakEjDo56OtZ94+gr6dwYFDTaa9kVNBct2PPv2r3WXZB0FQHwfbzS4IaVP3WnffbtljQJAiQUwxDJ0HN2qCGVTYmCM/GaqhZB7nFweeTXRA0A374N/D2JwOE2x0xPfhMC0qDmls6GfRvARxxAjTVBv1X+f2D/q+qd4LgHnJs0AwZzwk+5z5DgvV9+Nfgs00loOQI6H9ksGxucVAjXP0KrHwWSkfD1CuD5d9/Kah5jjkneL39o2B/Uolg/wpKYdCEoHkz2RD8Htj8LtRUBvtePATqt0Dx4KDGWrcJFvwq+ExLRkJ5RfC35IjgM136BJQdDYMnBtPrNwfNqDmFsPUDKCyDjW9Bw/bghlajToaHPxd83p/6Phx9DhSVwUOXwTtzYcaNcMq3g5rxllVBM208J6hRl0+FHZth9ctBOUtGQV4fiGUH//6yCyEentmfTsFHrwbv9R9FMu1k9elFNQIzOwG4w90/Fb6+FcDd/0+beZ4N53nVzLKADUCZ76FQCgI5qNIpiLVpj3YPvpDrNgVfRjkFwX/2bR8E/6lj8eDLr34LrP5r8MWTbILCUhh5UnCyQGNN8GWebAyeF5QGQZJOBP0y+f2CL/B0Mgg2CJ7nFAR9Pn2GBNPTieALYvAxsHZhUIPKKYTSo6BqRfAlnhX0nWAWfMltWx18eeX3C77ct6yC0+8ITlT46NXgBIaadUG50sngyzo7P/jyTzUHX/AWC7bdyoIA2FMY5vUNvgh3BGeQdTBwXPAFn2zs+F5vEcsKPrPuagl2i0HR4CAMGqtbTxgB4MSvwWm37X4de1r9HoIgkxeUlQNr2ryuBI7f3TzhPY6rgVJgcwbLJdJ1sXbXT5gFHfX9hu+cllsUfBm31WcoTLy44/qOPuvAl/FgSiWDzyCVCL60k01BCMTiO0OisTr44q/bGARbPBtKPxYs31QX1LQSDcHyDdthxAk7AzXREHyZZucHYZpoCH5FJxqDIMkpDH6db30/OHuvqTb45Z5OBl/EpUcF02rW7vwF7mlINkPfYUGwlR4VnCDx4V/DUEvB8GnB9mvXBSGf1xewILDrNgZ9W9n5wXFdvzjY5qiTglrEO38KttewDfoOh0mXw6rnYf2i4KzCkiOCslSvDebLygtOwhg6JajRbnkv2JdEQ/AoGhjUoDwNFoePnRJ8dnUbYeQnM3JYe8WVxWZ2LXAtwIgRI/Yyt4hkTEuTRSwefJm1lR3WPooGBn/7dfJ/NbcoeHSm/Xv5/XZfjqKyvRR06p7fHlYRPLpjzDm7vp742Y7zjDs/ePQSmRx7YC3Q5mcTw8Jpnc4TNg31Jeg03oW7z3H3CnevKCvb2z8AERHZF5kMgjeA0WY2ysxygEuB9gP/PwVcGT6/CHhxT/0DIiJy4GWsaShs8/9X4FmC00d/5e5Lzex7wAJ3fwr4JfAbM1sFbCUICxEROYgy2kfg7nOBue2m3dbmeSPQSY+aiIgcLJG+H4GIiCgIREQiT0EgIhJxCgIRkYjrdaOPmlkV8GE3Fx9A9K5a1j5Hg/Y5GvZnn49w904vxOp1QbA/zGzB7sbaOFxpn6NB+xwNmdpnNQ2JiEScgkBEJOKiFgRzeroAPUD7HA3a52jIyD5Hqo9AREQ6ilqNQERE2lEQiIhEXGSCwMxmmdk7ZrbKzG7p6fIcKGY23MzmmdkyM1tqZjeG0/ub2XNmtjL8WxJONzObHX4OS8xsSs/uQfeYWdzM/mFmfwhfjzKz18L9eiQc+hwzyw1frwrfH9mT5d4fZtbPzB4zsxVmttzMTjicj7OZ3RT+m37bzB4ys7zD8Tib2a/MbJOZvd1m2j4fVzO7Mpx/pZld2dm2dicSQWBmceBe4CxgHHCZmY3r2VIdMEnga+4+DpgOfCXct1uAF9x9NPBC+BqCz2B0+LgW+NnBL/IBcSOwvM3rHwI/cvejgG3ANeH0a4Bt4fQfhfP1Vj8GnnH3McCxBPt/WB5nMysHbgAq3H0CwVD2l3J4Huf7gVntpu3TcTWz/sDtBLcDngbc3hIeXeLuh/0DOAF4ts3rW4Fbe7pcGdrX3wNnAO8AQ8JpQ4B3wuf/BVzWZv7W+XrLg+Budy8ApwJ/AIzgasus9seb4H4YJ4TPs8L5rKf3oRv73Bf4oH3ZD9fjzM77mfcPj9sfgE8drscZGAm83d3jClwG/Feb6bvMt7dHJGoE7PxH1aIynHZYCavDk4HXgEHuvj58awMwKHx+OHwWdwPfANLh61Jgu7snw9dt96l1f8P3q8P5e5tRQBVwX9gk9gszK+QwPc7uvha4E/gIWE9w3BZy+B/nFvt6XPfreEclCA57ZlYEPA581d1r2r7nwU+Ew+I8YTM7F9jk7gt7uiwHWRYwBfiZu08GdrCzuQA47I5zCfBpggAcChTSsfkkEg7GcY1KEKwFhrd5PSycdlgws2yCEHjQ3f8nnLzRzIaE7w8BNoXTe/tnMQM438xWAw8TNA/9GOhnZi133Gu7T637G77fF9hyMAt8gFQCle7+Wvj6MYJgOFyP8+nAB+5e5e4J4H8Ijv3hfpxb7Otx3a/jHZUgeAMYHZ5xkEPQ6fRUD5fpgDAzI7j383J3v6vNW08BLWcOXEnQd9Ay/Yrw7IPpQHWbKughz91vdfdh7j6S4Di+6O6XA/OAi8LZ2u9vy+dwUTh/r/vV7O4bgDVmdnQ46TRgGYfpcSZoEppuZgXhv/GW/T2sj3Mb+3pcnwXONLOSsDZ1Zjita3q6k+QgdsacDbwLvAd8u6fLcwD365ME1cYlwKLwcTZB++gLwErgeaB/OL8RnEH1HvAWwVkZPb4f3dz3mcAfwudHAq8Dq4D/BnLD6Xnh61Xh+0f2dLn3Y38nAQvCY/0kUHI4H2fgu8AK4G3gN0Du4XicgYcI+kESBDW/a7pzXIGrw/1fBXxhX8qgISZERCIuKk1DIiKyGwoCEZGIUxCIiEScgkBEJOIUBCIiEacgEAmZWcrMFrV5HLBRas1sZNvRJUUOJVl7n0UkMhrcfVJPF0LkYFONQGQvzGy1mf2/ZvaWmb1uZkeF00ea2YvhuPAvmNmIcPogM3vCzBaHj0+Eq4qb2c/DMfb/bGb54fw3WHA/iSVm9nAP7aZEmIJAZKf8dk1Dl7R5r9rdjwF+QjD6KcA9wAPuPhF4EJgdTp8N/MXdjyUYD2hpOH00cK+7jwe2A/8UTr8FmByu57pM7ZzI7ujKYpGQmdW5e1En01cDp7r7++EAfxvcvdTMNhOMGZ8Ip6939wFmVgUMc/emNusYCTznwY1GMLNvAtnu/h9m9gxQRzBsxJPuXpfhXRXZhWoEIl3ju3m+L5raPE+xs4/uHILxY6YAb7QZXVPkoFAQiHTNJW3+vho+/xvBCKgAlwMvh89fAK6H1nsr993dSs0sBgx393nANwmGT+5QKxHJJP3yENkp38wWtXn9jLu3nEJaYmZLCH7VXxZO+18Edwz7N4K7h30hnH4jMMfMriH45X89weiSnYkDvw3DwoDZ7r79gO2RSBeoj0BkL8I+ggp339zTZRHJBDUNiYhEnGoEIiIRpxqBiEjEKQhERCJOQSAiEnEKAhGRiFMQiIhE3P8PYEMuN0AlyUUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6-cfLLTC4yi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "e4587f19-e3ff-4613-9fca-99425d7a204d"
      },
      "source": [
        "plt.plot(h['mae'])\n",
        "plt.plot(h['val_mae'])\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "it0NPDTSDAAP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_predicted=model.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkOJh_1hDGBV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a19df537-92bf-4504-8937-d3d4907ec0ac"
      },
      "source": [
        "y_predicted.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(360, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9I8UtVcGDKZP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "834a79ab-b9a7-47b3-84e4-564ea3d5bb9d"
      },
      "source": [
        "y_predicted"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 61378.508],\n",
              "       [114593.53 ],\n",
              "       [130358.44 ],\n",
              "       [144274.62 ],\n",
              "       [120534.92 ],\n",
              "       [350625.94 ],\n",
              "       [210035.25 ],\n",
              "       [193488.17 ],\n",
              "       [163949.53 ],\n",
              "       [312939.22 ],\n",
              "       [175837.5  ],\n",
              "       [172689.52 ],\n",
              "       [112401.69 ],\n",
              "       [136392.16 ],\n",
              "       [114523.64 ],\n",
              "       [301136.03 ],\n",
              "       [173899.36 ],\n",
              "       [144831.78 ],\n",
              "       [135688.86 ],\n",
              "       [112748.625],\n",
              "       [ 89647.945],\n",
              "       [215287.14 ],\n",
              "       [ 96987.266],\n",
              "       [ 97413.09 ],\n",
              "       [158235.86 ],\n",
              "       [107999.03 ],\n",
              "       [179121.56 ],\n",
              "       [263156.97 ],\n",
              "       [217649.7  ],\n",
              "       [134638.14 ],\n",
              "       [134607.17 ],\n",
              "       [105231.195],\n",
              "       [169876.58 ],\n",
              "       [249507.86 ],\n",
              "       [173930.77 ],\n",
              "       [100930.47 ],\n",
              "       [101692.22 ],\n",
              "       [ 89401.5  ],\n",
              "       [226423.39 ],\n",
              "       [109105.94 ],\n",
              "       [127912.05 ],\n",
              "       [175465.05 ],\n",
              "       [357147.6  ],\n",
              "       [103007.34 ],\n",
              "       [ 95438.95 ],\n",
              "       [144165.94 ],\n",
              "       [154214.83 ],\n",
              "       [161296.25 ],\n",
              "       [ 96861.05 ],\n",
              "       [153791.39 ],\n",
              "       [111868.95 ],\n",
              "       [214333.22 ],\n",
              "       [227168.95 ],\n",
              "       [120994.78 ],\n",
              "       [204865.33 ],\n",
              "       [205473.17 ],\n",
              "       [172495.23 ],\n",
              "       [201778.45 ],\n",
              "       [241663.66 ],\n",
              "       [179527.95 ],\n",
              "       [146245.75 ],\n",
              "       [199612.52 ],\n",
              "       [138700.4  ],\n",
              "       [153953.4  ],\n",
              "       [182851.8  ],\n",
              "       [209085.36 ],\n",
              "       [219681.17 ],\n",
              "       [192344.95 ],\n",
              "       [219706.02 ],\n",
              "       [502875.25 ],\n",
              "       [160652.27 ],\n",
              "       [204645.67 ],\n",
              "       [163210.36 ],\n",
              "       [163534.14 ],\n",
              "       [200429.08 ],\n",
              "       [317568.66 ],\n",
              "       [117119.625],\n",
              "       [107344.95 ],\n",
              "       [120136.56 ],\n",
              "       [ 98905.97 ],\n",
              "       [298526.8  ],\n",
              "       [276588.   ],\n",
              "       [342482.56 ],\n",
              "       [142619.73 ],\n",
              "       [310463.16 ],\n",
              "       [114135.65 ],\n",
              "       [134589.89 ],\n",
              "       [282984.4  ],\n",
              "       [179218.11 ],\n",
              "       [181661.52 ],\n",
              "       [211296.73 ],\n",
              "       [163570.11 ],\n",
              "       [125939.85 ],\n",
              "       [148276.42 ],\n",
              "       [154461.47 ],\n",
              "       [166897.5  ],\n",
              "       [216723.73 ],\n",
              "       [148548.05 ],\n",
              "       [163344.25 ],\n",
              "       [144297.48 ],\n",
              "       [ 87130.23 ],\n",
              "       [191074.12 ],\n",
              "       [113764.41 ],\n",
              "       [194506.23 ],\n",
              "       [154044.5  ],\n",
              "       [288587.9  ],\n",
              "       [120669.03 ],\n",
              "       [206745.72 ],\n",
              "       [129131.984],\n",
              "       [278427.28 ],\n",
              "       [188448.67 ],\n",
              "       [188335.52 ],\n",
              "       [ 88554.54 ],\n",
              "       [141509.86 ],\n",
              "       [130233.84 ],\n",
              "       [108389.5  ],\n",
              "       [140079.2  ],\n",
              "       [231021.78 ],\n",
              "       [ 66606.766],\n",
              "       [ 96786.234],\n",
              "       [104253.42 ],\n",
              "       [138007.8  ],\n",
              "       [169712.62 ],\n",
              "       [146003.11 ],\n",
              "       [216221.7  ],\n",
              "       [139348.56 ],\n",
              "       [228239.03 ],\n",
              "       [152209.42 ],\n",
              "       [310950.3  ],\n",
              "       [137789.73 ],\n",
              "       [ 71049.27 ],\n",
              "       [144629.   ],\n",
              "       [101482.09 ],\n",
              "       [129898.26 ],\n",
              "       [150645.95 ],\n",
              "       [141875.17 ],\n",
              "       [156611.23 ],\n",
              "       [209200.42 ],\n",
              "       [134351.78 ],\n",
              "       [241943.77 ],\n",
              "       [206864.45 ],\n",
              "       [209267.27 ],\n",
              "       [159620.75 ],\n",
              "       [456921.4  ],\n",
              "       [158645.53 ],\n",
              "       [175028.17 ],\n",
              "       [189521.44 ],\n",
              "       [148903.48 ],\n",
              "       [159668.03 ],\n",
              "       [118890.2  ],\n",
              "       [286838.8  ],\n",
              "       [197034.77 ],\n",
              "       [116092.734],\n",
              "       [185089.08 ],\n",
              "       [179598.88 ],\n",
              "       [134929.39 ],\n",
              "       [312986.2  ],\n",
              "       [103201.21 ],\n",
              "       [171956.27 ],\n",
              "       [154203.55 ],\n",
              "       [169925.3  ],\n",
              "       [124521.16 ],\n",
              "       [148833.2  ],\n",
              "       [155458.2  ],\n",
              "       [167291.58 ],\n",
              "       [175368.81 ],\n",
              "       [132442.77 ],\n",
              "       [371417.22 ],\n",
              "       [304511.03 ],\n",
              "       [134003.77 ],\n",
              "       [166955.48 ],\n",
              "       [154609.81 ],\n",
              "       [137694.69 ],\n",
              "       [177028.52 ],\n",
              "       [126189.22 ],\n",
              "       [152688.47 ],\n",
              "       [158080.5  ],\n",
              "       [221039.8  ],\n",
              "       [243537.95 ],\n",
              "       [ 80622.76 ],\n",
              "       [202626.19 ],\n",
              "       [167348.8  ],\n",
              "       [138542.27 ],\n",
              "       [159581.89 ],\n",
              "       [189490.8  ],\n",
              "       [123612.03 ],\n",
              "       [149876.47 ],\n",
              "       [250822.03 ],\n",
              "       [272837.25 ],\n",
              "       [261674.36 ],\n",
              "       [157860.83 ],\n",
              "       [126376.125],\n",
              "       [119169.31 ],\n",
              "       [175439.5  ],\n",
              "       [108456.836],\n",
              "       [135569.45 ],\n",
              "       [140851.64 ],\n",
              "       [133926.19 ],\n",
              "       [117550.55 ],\n",
              "       [161042.45 ],\n",
              "       [232490.86 ],\n",
              "       [159923.86 ],\n",
              "       [332570.47 ],\n",
              "       [209232.8  ],\n",
              "       [146443.61 ],\n",
              "       [373790.84 ],\n",
              "       [189727.17 ],\n",
              "       [140697.92 ],\n",
              "       [150900.17 ],\n",
              "       [172783.77 ],\n",
              "       [275455.78 ],\n",
              "       [183134.92 ],\n",
              "       [340856.16 ],\n",
              "       [296420.3  ],\n",
              "       [122870.7  ],\n",
              "       [184339.92 ],\n",
              "       [248373.05 ],\n",
              "       [185793.02 ],\n",
              "       [267886.4  ],\n",
              "       [122393.28 ],\n",
              "       [166482.62 ],\n",
              "       [ 68336.06 ],\n",
              "       [196985.78 ],\n",
              "       [ 88699.97 ],\n",
              "       [232639.36 ],\n",
              "       [ 61967.926],\n",
              "       [ 77755.484],\n",
              "       [136545.17 ],\n",
              "       [310838.75 ],\n",
              "       [171666.05 ],\n",
              "       [245547.48 ],\n",
              "       [128169.84 ],\n",
              "       [121763.44 ],\n",
              "       [124288.97 ],\n",
              "       [124255.7  ],\n",
              "       [154664.61 ],\n",
              "       [126908.31 ],\n",
              "       [ 71354.99 ],\n",
              "       [215942.02 ],\n",
              "       [122548.83 ],\n",
              "       [ 99481.625],\n",
              "       [166480.14 ],\n",
              "       [241543.47 ],\n",
              "       [154349.56 ],\n",
              "       [173604.19 ],\n",
              "       [104359.375],\n",
              "       [192957.53 ],\n",
              "       [302751.3  ],\n",
              "       [236808.77 ],\n",
              "       [128935.98 ],\n",
              "       [256151.92 ],\n",
              "       [164310.75 ],\n",
              "       [116279.28 ],\n",
              "       [465721.84 ],\n",
              "       [254129.06 ],\n",
              "       [165725.25 ],\n",
              "       [108560.72 ],\n",
              "       [158897.98 ],\n",
              "       [154854.33 ],\n",
              "       [376899.97 ],\n",
              "       [162430.92 ],\n",
              "       [264833.7  ],\n",
              "       [137478.31 ],\n",
              "       [168049.77 ],\n",
              "       [139760.98 ],\n",
              "       [220761.95 ],\n",
              "       [195964.27 ],\n",
              "       [157543.14 ],\n",
              "       [141594.58 ],\n",
              "       [229323.14 ],\n",
              "       [123252.9  ],\n",
              "       [156769.17 ],\n",
              "       [237327.73 ],\n",
              "       [433955.34 ],\n",
              "       [263521.94 ],\n",
              "       [254596.98 ],\n",
              "       [ 99129.95 ],\n",
              "       [147968.47 ],\n",
              "       [ 90546.5  ],\n",
              "       [149305.33 ],\n",
              "       [ 72400.38 ],\n",
              "       [254652.44 ],\n",
              "       [148199.4  ],\n",
              "       [161612.5  ],\n",
              "       [109720.625],\n",
              "       [110092.17 ],\n",
              "       [229047.11 ],\n",
              "       [173871.38 ],\n",
              "       [334564.34 ],\n",
              "       [124617.58 ],\n",
              "       [222182.08 ],\n",
              "       [ 79661.43 ],\n",
              "       [125863.07 ],\n",
              "       [143387.92 ],\n",
              "       [236981.61 ],\n",
              "       [278988.1  ],\n",
              "       [247545.73 ],\n",
              "       [116318.52 ],\n",
              "       [138995.16 ],\n",
              "       [170777.83 ],\n",
              "       [101028.72 ],\n",
              "       [177059.66 ],\n",
              "       [178213.3  ],\n",
              "       [260414.31 ],\n",
              "       [113303.98 ],\n",
              "       [242028.31 ],\n",
              "       [128950.68 ],\n",
              "       [119725.42 ],\n",
              "       [143034.8  ],\n",
              "       [190261.67 ],\n",
              "       [208166.98 ],\n",
              "       [155065.42 ],\n",
              "       [ 96352.97 ],\n",
              "       [262271.84 ],\n",
              "       [167075.52 ],\n",
              "       [208737.48 ],\n",
              "       [127269.97 ],\n",
              "       [353800.3  ],\n",
              "       [130420.77 ],\n",
              "       [264396.6  ],\n",
              "       [169740.4  ],\n",
              "       [151140.69 ],\n",
              "       [140091.03 ],\n",
              "       [139378.45 ],\n",
              "       [134784.48 ],\n",
              "       [155898.83 ],\n",
              "       [248082.64 ],\n",
              "       [139368.02 ],\n",
              "       [112168.17 ],\n",
              "       [194547.7  ],\n",
              "       [165431.77 ],\n",
              "       [129589.53 ],\n",
              "       [ 91251.12 ],\n",
              "       [190634.5  ],\n",
              "       [150889.06 ],\n",
              "       [153771.5  ],\n",
              "       [120873.95 ],\n",
              "       [350301.84 ],\n",
              "       [142337.98 ],\n",
              "       [161260.52 ],\n",
              "       [177273.81 ],\n",
              "       [138846.95 ],\n",
              "       [339118.6  ],\n",
              "       [105605.64 ],\n",
              "       [187150.39 ],\n",
              "       [ 98549.016],\n",
              "       [160105.89 ],\n",
              "       [256071.92 ],\n",
              "       [125398.81 ],\n",
              "       [ 83098.2  ],\n",
              "       [156819.83 ],\n",
              "       [221657.02 ],\n",
              "       [129333.984],\n",
              "       [138052.3  ],\n",
              "       [180453.39 ],\n",
              "       [171936.28 ],\n",
              "       [175894.55 ],\n",
              "       [119094.87 ],\n",
              "       [142078.06 ],\n",
              "       [143760.94 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLdZNP0nDOFR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_predicted=y_predicted.reshape((360,))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoxkmkeODTpF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels=np.arange(1101,1461)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viYFt3FlDdKa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=pd.DataFrame({'Id':labels,'SalePrice':y_predicted})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhXgNtyWDgBx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "28bbdf1a-1470-4297-a432-ff04617944d8"
      },
      "source": [
        "df.head(7)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1101</td>\n",
              "      <td>61378.507812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1102</td>\n",
              "      <td>114593.531250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1103</td>\n",
              "      <td>130358.437500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1104</td>\n",
              "      <td>144274.625000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1105</td>\n",
              "      <td>120534.921875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1106</td>\n",
              "      <td>350625.937500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1107</td>\n",
              "      <td>210035.250000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Id      SalePrice\n",
              "0  1101   61378.507812\n",
              "1  1102  114593.531250\n",
              "2  1103  130358.437500\n",
              "3  1104  144274.625000\n",
              "4  1105  120534.921875\n",
              "5  1106  350625.937500\n",
              "6  1107  210035.250000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0p4-dezDjL7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.to_csv('y_predicted_800-300-200-100-50-20-1_neuron_sckit_learn.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjPuw8j5Dmwb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}